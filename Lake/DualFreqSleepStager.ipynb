{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1306768",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine Final Project - Deep Learning Methods for Wearable Sleep Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94600e31",
   "metadata": {},
   "source": [
    "# Imports and Defintions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59be11",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf64d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, roc_auc_score\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8184e68",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada5da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(x): # Helper to safely convert strings to floats\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def forward_fill(x: torch.Tensor): # Forward‑fill NaNs in each channel\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f35c3",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58038a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 high_freq: int = 32,\n",
    "                 low_freq: int = 8,\n",
    "                 hf_features: list = None,\n",
    "                 lf_features: list = None,\n",
    "                 debug: bool = False):\n",
    "        self.hf_downsample = int(64 // high_freq) # downsample factor for high frequency data\n",
    "        self.lf_downsample = int(64 // low_freq) # downsample factor for low frequency data\n",
    "\n",
    "        SLEEP_STAGE_MAPPING = {\n",
    "            \"W\": 0,    # Wake\n",
    "            \"N1\": 1,   # non-REM stage 1 (light sleep_)\n",
    "            \"N2\": 1,   # non-REM stage 2 (light sleep)\n",
    "            \"N3\": 2,   # non-REM stage 3 (deep sleep)\n",
    "            \"R\": 3,    # REM\n",
    "            \"Missing\": -1  # Missing label → ignore\n",
    "        }\n",
    "        numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "        converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File {path} does not exist.\")\n",
    "            # Load data for subject\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            \n",
    "            # drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # combine ACC_X, ACC_Y, ACC_Z into a single feature\n",
    "            df['ACC'] = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "            # separate high and low frequency data\n",
    "            df_high = df[hf_features].copy()\n",
    "            df_low = df[lf_features].copy()\n",
    "            # downsample data and labels\n",
    "            df_high = df_high.iloc[::self.hf_downsample, :].reset_index(drop=True)\n",
    "            df_low = df_low.iloc[::self.lf_downsample, :].reset_index(drop=True)\n",
    "            labels_arr = labels_arr[::self.lf_downsample]\n",
    "            # normalize data\n",
    "            df_high = (df_high - df_high.mean()) / (df_high.std().replace(0, 1e-6))\n",
    "            df_low = (df_low - df_low.mean()) / (df_low.std().replace(0, 1e-6))\n",
    "            # create chunks\n",
    "            total_time = int(len(df_high) / high_freq)\n",
    "            n_chunks = int((total_time - chunk_duration) // chunk_stride) + 1\n",
    "            for i in range(n_chunks):\n",
    "                start_time = i * chunk_stride\n",
    "                end_time = start_time + chunk_duration\n",
    "                \n",
    "                start_low = int(start_time * low_freq)\n",
    "                end_low = int(end_time * low_freq)\n",
    "                start_high = int(start_time * high_freq)\n",
    "                end_high = int(end_time * high_freq)\n",
    "\n",
    "                lf_chunk = df_low .iloc[start_low: end_low ].values.astype(np.float32)\n",
    "                hf_chunk = df_high.iloc[start_high:end_high].values.astype(np.float32)\n",
    "                labels_chunk = labels_arr[start_low: end_low]\n",
    "\n",
    "                lf_chunk = forward_fill(torch.tensor(lf_chunk, dtype=torch.float32))\n",
    "                hf_chunk = forward_fill(torch.tensor(hf_chunk, dtype=torch.float32))\n",
    "                labels_chunk = torch.tensor(labels_chunk, dtype=torch.long)\n",
    "                \n",
    "                if (labels_chunk != -1).any():\n",
    "                    self.chunks.append({\n",
    "                        'high': hf_chunk,\n",
    "                        'low': lf_chunk,\n",
    "                        'labels': labels_chunk,\n",
    "                    })\n",
    "        if debug:\n",
    "            print(f\"Loaded {len(self.chunks)} chunks from {len(subjects_list)} subjects.\")\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        hf = chunk['high']\n",
    "        lf = chunk['low']\n",
    "        labels = chunk['labels']\n",
    "        return hf, lf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d09d",
   "metadata": {},
   "source": [
    "## Optuna objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f1d69",
   "metadata": {},
   "source": [
    "### LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f037c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"lstm_num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992759c",
   "metadata": {},
   "source": [
    "### TCN Only Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0912214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "    num_tcn_blocks = trial.suggest_int(\"num_tcn_blocks\", 3, 8)\n",
    "    tcn_kernel_size = trial.suggest_categorical(\"tcn_kernel_size\", [3, 5, 7])\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/TCN/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e844a",
   "metadata": {},
   "source": [
    "### TCN-LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d1a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"lstm_num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "    num_tcn_blocks = trial.suggest_int(\"num_tcn_blocks\", 3, 8)\n",
    "    tcn_kernel_size = trial.suggest_categorical(\"tcn_kernel_size\", [3, 5, 7])\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/TCN-LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e25929",
   "metadata": {},
   "source": [
    "### CNN-LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e4c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/CNN-LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cea6ec",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12f4d2",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=2,\n",
    "                 lf_input_channels=5,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size= hf_input_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in high freq input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in low freq input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        hf_output_length = hf.shape[1]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf length {hf_output_length} > lf length {lf_output_length}, downsampling\")\n",
    "        hf = F.interpolate(\n",
    "                hf.permute(0, 2, 1), # (batch_size, hf_input_channels, sequence_length)\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        hf = hf.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = hf.permute(1,0,2) # (sequence_length, batch_size, hf_input_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029235b",
   "metadata": {},
   "source": [
    "### TCN\n",
    "As defined in Bai et al https://arxiv.org/pdf/1803.01271, TCN blocks are residual blocks, each containing two dilated convolutions with relu activation and batch normalization. Subsequent blocks have increasing dilations, allowing for the capture of patterns at increasing timescales. Often these are causally padded but for our use case, we decided to forego this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b9ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels, output_channels, kernel_size, dilation, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2 # preserve sequence length\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size,\n",
    "                               stride=stride, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm1d(output_channels)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size,\n",
    "                               stride=1, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(output_channels)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        # 1×1 conv to match channels/stride if needed\n",
    "        self.downsample = (nn.Conv1d(input_channels, output_channels, 1, stride=stride)\n",
    "                           if (stride!=1 or input_channels!=output_channels) else None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x arrives as (batch, channels, seq_len)\n",
    "        identity = x                     # save the original for the skip path\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)          \n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.dropout(out)\n",
    "        # downsampled if needed\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # add & activate\n",
    "        return self.relu(out + identity)\n",
    "\n",
    "class HFFeatureExtractorTCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=5,\n",
    "                 kernel_size=3,\n",
    "                 base_channels=16,\n",
    "                 final_down=64,     # match CNN’s total downsample factor (~64)\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch = in_channels\n",
    "        # build dilated residual blocks (no downsampling here)\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                TemporalBlock(ch, base_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=2**i,\n",
    "                              stride=1,\n",
    "                              dropout=dropout)\n",
    "            )\n",
    "            ch = base_channels\n",
    "        # final 1×1 conv with stride=final_down to downsample by 64\n",
    "        layers.append(nn.Conv1d(ch, out_channels,\n",
    "                                kernel_size=1,\n",
    "                                stride=final_down,\n",
    "                                padding=0))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, in_channels)\n",
    "        x = x.permute(0,2,1)  # to (batch, channels, seq_len)\n",
    "        y = self.tcn(x)       # returns (batch, out_channels, seq_len/64)\n",
    "        return y             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1eb51",
   "metadata": {},
   "source": [
    "### CNN\n",
    "As laid out in DeepActiNet paper - using a 1d CNN to extract features from acceleration and in this case BVP as well, this is done with a series of convolutions with very large kernels and no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd029142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels,\n",
    "     output_channels,\n",
    "     dropout=0.1):\n",
    "        super(HFFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff37f4",
   "metadata": {},
   "source": [
    "### Convolution Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31019482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 num_tcn_blocks=5,\n",
    "                 tcn_kernel_size=3,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels + lf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels + lf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=num_tcn_blocks,\n",
    "                                            kernel_size=tcn_kernel_size,\n",
    "                                            base_channels=cnn_output_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "        self.classifier = nn.Linear(cnn_output_channels, num_sleep_stages)\n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # upsample shorter sequence\n",
    "        hf_output_length = hf.shape[1]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf output length {hf_output_length} < lf output length {lf_output_length}, upsampling\")\n",
    "        lf = F.interpolate(\n",
    "                lf.permute(0, 2, 1), # (batch_size, hf_input_channels, sequence_length)\n",
    "                size=hf_output_length,\n",
    "            )\n",
    "        hf = hf.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        x = torch.cat((hf, lf), dim=1)\n",
    "        x = x.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels + lf_input_channels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] conv input shape: {x.shape}\")\n",
    "\n",
    "        # pass through cnn\n",
    "        x = self.cnn(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] conv output shape: {x.shape}\")\n",
    "\n",
    "        # downsample to match original sequence length\n",
    "        x = F.interpolate(\n",
    "            x,\n",
    "            size=lf_output_length,\n",
    "        )\n",
    "\n",
    "        # pass through classifier\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = x.permute(1, 0, 2) # (batch_size, num_classes, sequence_length)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b678a",
   "metadata": {},
   "source": [
    "### Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70393b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 num_tcn_blocks=5,\n",
    "                 tcn_kernel_size=3,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=num_tcn_blocks,\n",
    "                                            kernel_size=tcn_kernel_size,\n",
    "                                            base_channels=cnn_output_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=cnn_output_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # pass high frequency data through CNN    \n",
    "        cnn_features = self.cnn(hf)\n",
    "        if self.debug:\n",
    "            print(f\"cnn output shape: {cnn_features.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        cnn_output_length = cnn_features.shape[2]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        if cnn_output_length > lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} > lf output length {lf_output_length}, downsampling\")\n",
    "            cnn_features = F.interpolate(\n",
    "                cnn_features,\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        elif cnn_output_length < lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} < lf output length {lf_output_length}, downsampling\")\n",
    "            lf = F.interpolate(\n",
    "                lf,\n",
    "                size=cnn_output_length,\n",
    "            )\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {cnn_features.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = cnn_features.permute(2,0,1) # (sequence_length, batch_size, cnn_output_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea401",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    # figure out where the model lives (cpu or cuda)\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    all_probs  = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lf, hf, labels in dataloader:\n",
    "            # move inputs to model's device\n",
    "            lf = lf.to(device)\n",
    "            hf = hf.to(device)\n",
    "\n",
    "            # forward\n",
    "            y_hat = model(lf, hf)           # (seq_len, batch, C)\n",
    "            y_hat = y_hat.permute(1, 0, 2)        # (batch, seq_len, C)\n",
    "            B, T, C = y_hat.shape\n",
    "\n",
    "            # flatten\n",
    "            logits = y_hat.reshape(B*T, C)\n",
    "            probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds  = probs.argmax(axis=1)\n",
    "            labs   = labels.reshape(-1).numpy()\n",
    "\n",
    "            # filter out padding (-1)\n",
    "            mask = (labs != -1)\n",
    "            all_labels.extend(labs[mask])\n",
    "            all_preds.extend(preds[mask])\n",
    "            all_probs.append(probs[mask])\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    acc   = accuracy_score(all_labels, all_preds)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    auroc = roc_auc_score(all_labels, all_probs, multi_class='ovo', average='macro')\n",
    "    cm    = confusion_matrix(all_labels, all_preds,normalize='true')\n",
    "    return acc, kappa, auroc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, classes: list[str]):\n",
    "    \"\"\"\n",
    "    cm:          square confusion matrix of counts or floats\n",
    "    classes:     list of class‐label strings, length == cm.shape[0]\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)           # default colormap, channels-last format\n",
    "    fig.colorbar(im, ax=ax)      # add a colorbar\n",
    "\n",
    "    # Tick labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Annotate each cell with its value\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f\"{val:.4f}\", ha='center', va='center')\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_with_metrics(cm, class_mapping):\n",
    "    class_vals = [i for i in class_mapping.keys()]\n",
    "    class_names = [class_mapping[i] for i in range(len(class_vals))]\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100  # row-wise percentage (sensitivity)\n",
    "\n",
    "    # Calculate Sensitivity (Recall) and PPV (Precision)\n",
    "    sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    ppv = np.diag(cm) / np.sum(cm, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=False, fmt='g', cmap='Blues', cbar=False, ax=ax)\n",
    "\n",
    "    # Labels inside the boxes\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count = cm[i, j]\n",
    "            perc = cm_perc[i, j]\n",
    "            ax.text(j + 0.5, i + 0.3, f\"{count:.4f}\", \n",
    "                    ha='center', va='center', color='black', fontsize=10)\n",
    "            ax.text(j + 0.5, i + 0.7, f\"{perc:.0f}%\", \n",
    "                    ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "    # Set axis labels\n",
    "    ax.set_xlabel('Prediction', fontsize=12)\n",
    "    ax.set_ylabel('Reference', fontsize=12)\n",
    "\n",
    "    # Set ticks\n",
    "    ax.set_xticks(np.arange(len(class_vals)) + 0.5)\n",
    "    ax.set_yticks(np.arange(len(class_vals)) + 0.5)\n",
    "\n",
    "    ax.set_xticklabels(class_names, rotation=0, ha=\"center\")\n",
    "    ax.set_yticklabels(class_names, rotation=0)\n",
    "\n",
    "    # Plot PPV (precision) on top\n",
    "    for j, p in enumerate(ppv):\n",
    "        ax.text(j + 0.5, -0.2, f\"{int(p*100) if not np.isnan(p) else 0}%\", \n",
    "                ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Plot Sensitivity (recall) on right\n",
    "    for i, s in enumerate(sensitivity):\n",
    "        ax.text(len(class_names) + 0.1, i + 0.5, f\"{int(s*100) if not np.isnan(s) else 0}%\", \n",
    "                ha='left', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Center \"PPV\" label on top\n",
    "    ax.text(len(class_vals) / 2, -0.5, \"PPV\", fontsize=14, ha='center', va='center')\n",
    "\n",
    "    # Center \"Sensitivity\" label on the right\n",
    "    ax.text(len(class_vals) + 0.5, len(class_vals) / 2, \"Sensitivity\", fontsize=14, ha='center', va='center', rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286811",
   "metadata": {},
   "source": [
    "# Dataset creation / loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7387c",
   "metadata": {},
   "source": [
    "### Separate subjects into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d632ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "max_length = 2493810 # found experimentally, takes a while to compute\n",
    "\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a9d4",
   "metadata": {},
   "source": [
    "### Construct train, val, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 6000s = 100 minutes\n",
    "chunk_stride = 3000 # 3000s = 50 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=subjects_train,\n",
    "                                data_dir=datadir_64Hz,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "print(f\"number of chunks in train: {len(train_dataset)}\")\n",
    "val_dataset = DualFreqDataset(subjects_list=subjects_val,\n",
    "                              data_dir=datadir_64Hz,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "print(f\"number of chunks in val: {len(val_dataset)}\")\n",
    "test_dataset = DualFreqDataset(subjects_list=subjects_test,\n",
    "                               data_dir=datadir_64Hz,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "print(f\"number of chunks in test: {len(test_dataset)}\")\n",
    "train_dataset_small = DualFreqDataset(subjects_list=subjects_train_small,\n",
    "                                       data_dir=datadir_64Hz,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "print(f\"number of chunks in small train: {len(train_dataset_small)}\")\n",
    "val_dataset_small = DualFreqDataset(subjects_list=subjects_val_small,\n",
    "                                     data_dir=datadir_64Hz,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "print(f\"number of chunks in small val: {len(val_dataset_small)}\")\n",
    "test_dataset_small = DualFreqDataset(subjects_list=subjects_test_small,\n",
    "                                      data_dir=datadir_64Hz,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "print(f\"number of chunks in small test: {len(test_dataset_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ec509",
   "metadata": {},
   "source": [
    "### Save Dataset Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset chunks\n",
    "torch.save(train_dataset.chunks, 'DualFreqDatasets/train_dataset_chunks.pt')\n",
    "torch.save(val_dataset.chunks, 'DualFreqDatasets/val_dataset_chunks.pt')\n",
    "torch.save(test_dataset.chunks, 'DualFreqDatasets/test_dataset_chunks.pt')\n",
    "torch.save(train_dataset_small.chunks, 'DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "torch.save(val_dataset_small.chunks, 'DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "torch.save(test_dataset_small.chunks, 'DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e4c60",
   "metadata": {},
   "source": [
    "### Load Saved Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f596d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved datasets\n",
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 10 minutes\n",
    "chunk_stride = 3000 # 2.5 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=[],\n",
    "                                data_dir=None,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "train_dataset.chunks = torch.load('DualFreqDatasets/train_dataset_chunks.pt')\n",
    "val_dataset = DualFreqDataset(subjects_list=[],\n",
    "                              data_dir=None,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "val_dataset.chunks = torch.load('DualFreqDatasets/val_dataset_chunks.pt')\n",
    "test_dataset = DualFreqDataset(subjects_list=[],\n",
    "                               data_dir=None,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "test_dataset.chunks = torch.load('DualFreqDatasets/test_dataset_chunks.pt')\n",
    "train_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                       data_dir=None,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "train_dataset_small.chunks = torch.load('DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "val_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                     data_dir=None,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "val_dataset_small.chunks = torch.load('DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "test_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                      data_dir=None,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "test_dataset_small.chunks = torch.load('DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149adfa",
   "metadata": {},
   "source": [
    "# Model Demos (shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e842ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 2])\n",
      "temp_lf shape: torch.Size([1200, 5])\n",
      "temp_labels shape: torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "temp_hf = temp_hf.unsqueeze(0)\n",
    "temp_lf = temp_lf.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259a6ea",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e253126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] hf length 192000 > lf length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 1200, 2])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 7])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    label_smoothing=0.0,\n",
    "    weight_tensor=None,\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee45c8",
   "metadata": {},
   "source": [
    "### TCN Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35798002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] hf output length 192000 < lf output length 1200, upsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 2, 192000])\n",
      "[DEBUG] lf features shape: torch.Size([1, 5, 192000])\n",
      "[DEBUG] conv input shape: torch.Size([1, 192000, 7])\n",
      "[DEBUG] conv output shape: torch.Size([1, 16, 3000])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = ConvSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a56e3",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e30d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 2])\n",
      "temp_lf shape: torch.Size([1200, 5])\n",
      "temp_labels shape: torch.Size([1200])\n",
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 2929])\n",
      "[DEBUG] cnn output length 2929 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n",
      "output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "temp_hf = temp_hf.unsqueeze(0)\n",
    "temp_lf = temp_lf.unsqueeze(0)\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='CNN',\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)\n",
    "print(f\"output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fbdfa",
   "metadata": {},
   "source": [
    "### TCN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f783493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 3000])\n",
      "[DEBUG] cnn output length 3000 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n",
      "output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    num_tcn_blocks=5,\n",
    "    tcn_kernel_size=3,\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)\n",
    "print(f\"output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c12b",
   "metadata": {},
   "source": [
    "# Get Class Weights\n",
    "We use these for weighted loss, this is to deal with the natural class imbalance in sleep staging data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f80a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(1): 418966, np.int64(0): 144616, np.int64(3): 71508, np.int64(2): 24188})\n",
      "Class weights: [1.13970446 0.39339588 6.81410203 2.30490994]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(4)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24370f",
   "metadata": {},
   "source": [
    "# LSTM Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96fb26",
   "metadata": {},
   "source": [
    "## LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8198b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lstm_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb74de4",
   "metadata": {},
   "source": [
    "## Train LSTM only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38022d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous optuna run\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "dropout = 0.30852038514107194\n",
    "learning_rate = 0.006903453198555122\n",
    "weight_decay = 3.688273744980673e-05\n",
    "label_smoothing = 0.016709469700221313\n",
    "\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"LSTM-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/LSTM/',\n",
    "        filename=f'best-checkpoint-{runNo}',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = LSTMSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/LSTM/best_model_{runNo}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7637985",
   "metadata": {},
   "source": [
    "## Test LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce329211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.7058 +/- 0.0303\n",
      "Test Accuracy: 0.4165 +/- 0.0979\n",
      "Test Kappa: 0.1968 +/- 0.0548\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From previous optuna run\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "dropout = 0.30852038514107194\n",
    "learning_rate = 0.006903453198555122\n",
    "weight_decay = 3.688273744980673e-05\n",
    "label_smoothing = 0.016709469700221313\n",
    "\n",
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/LSTM/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "tcn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f5f67",
   "metadata": {},
   "source": [
    "# TCN Only Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ef141",
   "metadata": {},
   "source": [
    "## TCN Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce91a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 21:48:28,101] Trial 24 finished with value: 1.2368443012237549 and parameters: {'cnn_output_channels': 64, 'dropout': 0.19866418585334414, 'learning_rate': 0.00019700816849326218, 'weight_decay': 1.1606336549334584e-05, 'label_smoothing': 0.11783564587360429, 'num_tcn_blocks': 7, 'tcn_kernel_size': 5}. Best is trial 11 with value: 1.2068884372711182.\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20250429_214828-omhztd4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/omhztd4n' target=\"_blank\">optuna-25</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/omhztd4n' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/omhztd4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints/TCN/Optuna exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                  | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | cnn             | HFFeatureExtractorTCN | 1.3 M  | train\n",
      "1 | kappa           | MulticlassCohenKappa  | 0      | train\n",
      "2 | classifier      | Linear                | 516    | train\n",
      "3 | train_criterion | CrossEntropyLoss      | 0      | train\n",
      "4 | val_criterion   | CrossEntropyLoss      | 0      | train\n",
      "------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.030     Total estimated model params size (MB)\n",
      "64        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002886533737182617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cb113f870142659da4a6b2008ced4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002801656723022461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fc373f944d425283c44f7857c9162a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(tcn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbab3a",
   "metadata": {},
   "source": [
    "## Train TCN Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f29bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250430_115353-2q4mgpp3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/2q4mgpp3' target=\"_blank\">best-params-9</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/2q4mgpp3' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/TCN-Sleep-Stager/runs/2q4mgpp3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints/TCN exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                  | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | cnn             | HFFeatureExtractorTCN | 28.8 K | train\n",
      "1 | kappa           | MulticlassCohenKappa  | 0      | train\n",
      "2 | classifier      | Linear                | 68     | train\n",
      "3 | train_criterion | CrossEntropyLoss      | 0      | train\n",
      "4 | val_criterion   | CrossEntropyLoss      | 0      | train\n",
      "------------------------------------------------------------------\n",
      "28.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.9 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n",
      "64        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028095245361328125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2164d6f90e457998d3e21c663594f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002813100814819336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4e58d089334598ab0f7b99ff54ca0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002844572067260742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7b7b313943424b9621833484a60398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002830028533935547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016b7645267648b2aeea4c62e5ae4382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028328895568847656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f57cf3b79146d4a557b266ee2f17c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002811908721923828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c9c8e704e94abda6a3b4d6d40a229b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028243064880371094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3682662b1c413baa558ef18b6119f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002982616424560547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2489e2b0103d485f83e2bdf73023b5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.00286865234375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ee7986f26d42fdbd9964c5974a5c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003047466278076172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7866b98981be484cb37f0ee64439ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028734207153320312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72eb078cbb2b45cbb96597ae20e2d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028994083404541016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c913f3518ed347bcba555e8cecaaa5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028548240661621094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150847fdba334b5ab74e72de2823e5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028312206268310547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef68e251d58541b38fda2a7db2affc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002833127975463867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4c9d3d7dd4d39a6fd819b555352dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028743743896484375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e4cd0290f40a2b9d21c474d3453c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028171539306640625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e32d1458c5485599dc76e78a99ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028107166290283203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdcb42a2b794495b88235e1667f2e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028543472290039062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52194c1571d4418adf636f181989618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028176307678222656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afaa11f4b06645eca25286a62ec12064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032885074615478516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f786650ced2946f9ac01d457e3eff743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028510093688964844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcec259482b44038a2c5acaf5e01951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.3950198226987424\n",
    "learning_rate = 0.004189358822532961\n",
    "label_smoothing = 0.006173192017349373\n",
    "num_tcn_blocks = 8\n",
    "tcn_kernel_size = 7\n",
    "weight_decay = 5.955040205462087e-05\n",
    "\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/TCN/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = ConvSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/TCN/best_model_{runNo}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3ef7f",
   "metadata": {},
   "source": [
    "## Test TCN Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 2\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.3950198226987424\n",
    "learning_rate = 0.004189358822532961\n",
    "label_smoothing = 0.006173192017349373\n",
    "num_tcn_blocks = 8\n",
    "tcn_kernel_size = 7\n",
    "weight_decay = 5.955040205462087e-05\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/TCN/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e156b",
   "metadata": {},
   "source": [
    "# TCN-LSTM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c533efb",
   "metadata": {},
   "source": [
    "## TCN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(tcn_lstm_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f98ed",
   "metadata": {},
   "source": [
    "## Train TCN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-LSTM-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/TCN-LSTM/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/TCN-LSTM/best_model_{runNo}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f8f52",
   "metadata": {},
   "source": [
    "## Test TCN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa34158",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/TCN-LSTM/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "tcn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ee87e",
   "metadata": {},
   "source": [
    "# CNN-LSTM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a786f0",
   "metadata": {},
   "source": [
    "## CNN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(cnn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "clear_output()\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ebffe",
   "metadata": {},
   "source": [
    "## Train and Test CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97e0bb",
   "metadata": {},
   "source": [
    "### Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cnn_output_channels = best_trial.params['cnn_output_channels']\n",
    "lstm_hidden_size = best_trial.params['lstm_hidden_size']\n",
    "num_layers = best_trial.params['num_layers']\n",
    "dropout = best_trial.params['dropout']\n",
    "learning_rate = best_trial.params['learning_rate']\n",
    "weight_decay = best_trial.params['weight_decay']\n",
    "label_smoothing = best_trial.params['label_smoothing']\n",
    "'''\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-LSTM-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/CNN-LSTM/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "\n",
    "    # test the model\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(best_model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/CNN-LSTM/best_model_{runNo}.pth')\n",
    "\n",
    "\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "cnn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix(cnn_mean_confusion, classes=['W','N1','N2','N3','R'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc13189",
   "metadata": {},
   "source": [
    "### Test CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/CNN-LSTM/best_model_{runNo}.pth'))\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "cnn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display last confusion matrix\n",
    "#plot_confusion_matrix(test_confusions[-1,:,:], classes=['W','N1','N2','N3','R'])\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02516e4a",
   "metadata": {},
   "source": [
    "# Compare Inference Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bac86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "temp_hf = temp_hf.unsqueeze(0).to(device)\n",
    "temp_lf = temp_lf.unsqueeze(0).to(device)\n",
    "# LSTM Only\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "dropout = 0.21312\n",
    "learning_rate = 0.0048844\n",
    "weight_decay = 0.0000078942\n",
    "label_smoothing = 0.0050416\n",
    "lstm_model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "lstm_model.eval()\n",
    "lstm_model.to(device)\n",
    "\n",
    "# CNN-LSTM\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "cnn_model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "cnn_model.eval()\n",
    "cnn_model.to(device)\n",
    "\n",
    "# TCN-LSTM\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "tcn_model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "tcn_model.eval()\n",
    "tcn_model.to(device)\n",
    "\n",
    "lstm_times = []\n",
    "cnn_times = []\n",
    "tcn_times = []\n",
    "num_trials = 100\n",
    "with torch.no_grad():\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        cnn_model(temp_hf, temp_lf)\n",
    "        tcn_model(temp_hf, temp_lf)\n",
    "    torch.cuda.synchronize()\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        cnn_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    cnn_times.append((end - start) / 100)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        tcn_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    tcn_times.append((end - start) / 100)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        lstm_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    lstm_times.append((end - start) / 100)\n",
    "print(f\"cnn time: {np.mean(cnn_times):.4f} +/- {np.std(cnn_times):.4f}\")\n",
    "print(f\"tcn time: {np.mean(tcn_times):.4f} +/- {np.std(tcn_times):.4f}\")\n",
    "print(f\"lstm time: {np.mean(lstm_times):.4f} +/- {np.std(lstm_times):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
