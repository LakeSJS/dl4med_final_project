{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1306768",
   "metadata": {},
   "source": [
    "# Title and overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59be11",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf64d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, roc_auc_score\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8184e68",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada5da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(x): # Helper to safely convert strings to floats\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def forward_fill(x: torch.Tensor): # Forward‑fill NaNs in each channel\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f35c3",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58038a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 high_freq: int = 32,\n",
    "                 low_freq: int = 8,\n",
    "                 hf_features: list = None,\n",
    "                 lf_features: list = None,\n",
    "                 debug: bool = False):\n",
    "        self.hf_downsample = int(64 // high_freq) # downsample factor for high frequency data\n",
    "        self.lf_downsample = int(64 // low_freq) # downsample factor for low frequency data\n",
    "\n",
    "        SLEEP_STAGE_MAPPING = {\n",
    "            \"W\": 0,    # Wake\n",
    "            \"N1\": 1,   # non-REM stage 1\n",
    "            \"N2\": 2,   # non-REM stage 2\n",
    "            \"N3\": 3,   # non-REM stage 3\n",
    "            \"R\": 4,    # REM\n",
    "            \"Missing\": -1  # Missing label → ignore\n",
    "        }\n",
    "        numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "        converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File {path} does not exist.\")\n",
    "            # Load data for subject\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            \n",
    "            # drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # combine ACC_X, ACC_Y, ACC_Z into a single feature\n",
    "            df['ACC'] = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "            # separate high and low frequency data\n",
    "            df_high = df[hf_features].copy()\n",
    "            df_low = df[lf_features].copy()\n",
    "            # downsample data and labels\n",
    "            df_high = df_high.iloc[::self.hf_downsample, :].reset_index(drop=True)\n",
    "            df_low = df_low.iloc[::self.lf_downsample, :].reset_index(drop=True)\n",
    "            labels_arr = labels_arr[::self.lf_downsample]\n",
    "            # normalize data\n",
    "            df_high = (df_high - df_high.mean()) / (df_high.std().replace(0, 1e-6))\n",
    "            df_low = (df_low - df_low.mean()) / (df_low.std().replace(0, 1e-6))\n",
    "            # create chunks\n",
    "            total_time = int(len(df_high) / high_freq)\n",
    "            n_chunks = int((total_time - chunk_duration) // chunk_stride) + 1\n",
    "            for i in range(n_chunks):\n",
    "                start_time = i * chunk_stride\n",
    "                end_time = start_time + chunk_duration\n",
    "                \n",
    "                start_low = int(start_time * low_freq)\n",
    "                end_low = int(end_time * low_freq)\n",
    "                start_high = int(start_time * high_freq)\n",
    "                end_high = int(end_time * high_freq)\n",
    "\n",
    "                lf_chunk = df_low .iloc[start_low: end_low ].values.astype(np.float32)\n",
    "                hf_chunk = df_high.iloc[start_high:end_high].values.astype(np.float32)\n",
    "                labels_chunk = labels_arr[start_low: end_low]\n",
    "\n",
    "                lf_chunk = forward_fill(torch.tensor(lf_chunk, dtype=torch.float32))\n",
    "                hf_chunk = forward_fill(torch.tensor(hf_chunk, dtype=torch.float32))\n",
    "                labels_chunk = torch.tensor(labels_chunk, dtype=torch.long)\n",
    "                \n",
    "                if (labels_chunk != -1).any():\n",
    "                    self.chunks.append({\n",
    "                        'high': hf_chunk,\n",
    "                        'low': lf_chunk,\n",
    "                        'labels': labels_chunk,\n",
    "                    })\n",
    "        if debug:\n",
    "            print(f\"Loaded {len(self.chunks)} chunks from {len(subjects_list)} subjects.\")\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        hf = chunk['high']\n",
    "        lf = chunk['low']\n",
    "        labels = chunk['labels']\n",
    "        return hf, lf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d09d",
   "metadata": {},
   "source": [
    "## Optuna objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"lstm_num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 5\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "    num_tcn_blocks = trial.suggest_int(\"num_tcn_blocks\", 3, 8)\n",
    "    tcn_kernel_size = trial.suggest_categorical(\"tcn_kernel_size\", [3, 5, 7])\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "def cnn_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 5\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cea6ec",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029235b",
   "metadata": {},
   "source": [
    "### TCN\n",
    "As defined in Bai et al https://arxiv.org/pdf/1803.01271, TCN blocks are residual blocks, each containing two dilated convolutions with relu activation and batch normalization. Subsequent blocks have increasing dilations, allowing for the capture of patterns at increasing timescales. Often these are causally padded but for our use case, we decided to forego this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b9ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels, output_channels, kernel_size, dilation, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2 # preserve sequence length\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size,\n",
    "                               stride=stride, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm1d(output_channels)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size,\n",
    "                               stride=1, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(output_channels)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        # 1×1 conv to match channels/stride if needed\n",
    "        self.downsample = (nn.Conv1d(input_channels, output_channels, 1, stride=stride)\n",
    "                           if (stride!=1 or input_channels!=output_channels) else None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x arrives as (batch, channels, seq_len)\n",
    "        identity = x                     # save the original for the skip path\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)          \n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.dropout(out)\n",
    "        # downsampled if needed\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # add & activate\n",
    "        return self.relu(out + identity)\n",
    "\n",
    "class HFFeatureExtractorTCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=5,\n",
    "                 kernel_size=3,\n",
    "                 base_channels=16,\n",
    "                 final_down=64,     # match CNN’s total downsample factor\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch = in_channels\n",
    "        # build dilated residual blocks (no downsampling here)\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                TemporalBlock(ch, base_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=2**i,\n",
    "                              stride=1,\n",
    "                              dropout=dropout)\n",
    "            )\n",
    "            ch = base_channels\n",
    "        # final 1×1 conv with stride=final_down to downsample by 64\n",
    "        layers.append(nn.Conv1d(ch, out_channels,\n",
    "                                kernel_size=1,\n",
    "                                stride=final_down,\n",
    "                                padding=0))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, in_channels)\n",
    "        x = x.permute(0,2,1)  # → (batch, channels, seq_len)\n",
    "        y = self.tcn(x)       # → (batch, out_channels, seq_len/64)\n",
    "        return y             # leave it in (B, C, T’) form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1eb51",
   "metadata": {},
   "source": [
    "### CNN\n",
    "As laid out in DeepActiNet paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd029142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels,\n",
    "     output_channels,\n",
    "     dropout=0.1):\n",
    "        super(HFFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b678a",
   "metadata": {},
   "source": [
    "### Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70393b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 num_tcn_blocks=5,\n",
    "                 tcn_kernel_size=3,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=num_tcn_blocks,\n",
    "                                            kernel_size=tcn_kernel_size,\n",
    "                                            base_channels=cnn_output_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=cnn_output_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # pass high frequency data through CNN    \n",
    "        cnn_features = self.cnn(hf)\n",
    "        if self.debug:\n",
    "            print(f\"cnn output shape: {cnn_features.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        cnn_output_length = cnn_features.shape[2]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        if cnn_output_length > lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} > lf output length {lf_output_length}, downsampling\")\n",
    "            cnn_features = F.interpolate(\n",
    "                cnn_features,\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        elif cnn_output_length < lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} < lf output length {lf_output_length}, downsampling\")\n",
    "            lf = F.interpolate(\n",
    "                lf,\n",
    "                size=cnn_output_length,\n",
    "            )\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {cnn_features.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = cnn_features.permute(2,0,1) # (sequence_length, batch_size, cnn_output_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        '''\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea401",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4676a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    # figure out where the model lives (cpu or cuda)\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    all_probs  = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for non_acc, acc, labels in dataloader:\n",
    "            # move inputs to model's device\n",
    "            non_acc = non_acc.to(device)\n",
    "            acc     = acc.to(device)\n",
    "\n",
    "            # forward\n",
    "            y_hat = model(non_acc, acc)           # (seq_len, batch, C)\n",
    "            y_hat = y_hat.permute(1, 0, 2)        # (batch, seq_len, C)\n",
    "            B, T, C = y_hat.shape\n",
    "\n",
    "            # flatten\n",
    "            logits = y_hat.reshape(B*T, C)\n",
    "            probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds  = probs.argmax(axis=1)\n",
    "            labs   = labels.reshape(-1).numpy()\n",
    "\n",
    "            # filter out padding (-1)\n",
    "            mask = (labs != -1)\n",
    "            all_labels.extend(labs[mask])\n",
    "            all_preds.extend(preds[mask])\n",
    "            all_probs.append(probs[mask])\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    acc   = accuracy_score(all_labels, all_preds)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    auroc = roc_auc_score(all_labels, all_probs, multi_class='ovo', average='macro')\n",
    "    cm    = confusion_matrix(all_labels, all_preds,normalize='true')\n",
    "    return acc, kappa, auroc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, classes: list[str]):\n",
    "    \"\"\"\n",
    "    cm:          square confusion matrix of counts or floats\n",
    "    classes:     list of class‐label strings, length == cm.shape[0]\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)           # default colormap, channels-last format\n",
    "    fig.colorbar(im, ax=ax)      # add a colorbar\n",
    "\n",
    "    # Tick labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Annotate each cell with its value\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f\"{val}\", ha='center', va='center')\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286811",
   "metadata": {},
   "source": [
    "## Dataset creation / loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7387c",
   "metadata": {},
   "source": [
    "### Separate subjects into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d632ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects in train: 80\n",
      "number of subjects in val: 10\n",
      "number of subjects in test: 10\n",
      "number of subjects in small train: 24\n",
      "number of subjects in small val: 3\n",
      "number of subjects in small test: 3\n"
     ]
    }
   ],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "max_length = 2493810 # found experimentally, takes a while to compute\n",
    "\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a9d4",
   "metadata": {},
   "source": [
    "### Construct train, val, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 6000s = 100 minutes\n",
    "chunk_stride = 3000 # 3000s = 50 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=subjects_train,\n",
    "                                data_dir=datadir_64Hz,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "print(f\"number of chunks in train: {len(train_dataset)}\")\n",
    "val_dataset = DualFreqDataset(subjects_list=subjects_val,\n",
    "                              data_dir=datadir_64Hz,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "print(f\"number of chunks in val: {len(val_dataset)}\")\n",
    "test_dataset = DualFreqDataset(subjects_list=subjects_test,\n",
    "                               data_dir=datadir_64Hz,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "print(f\"number of chunks in test: {len(test_dataset)}\")\n",
    "train_dataset_small = DualFreqDataset(subjects_list=subjects_train_small,\n",
    "                                       data_dir=datadir_64Hz,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "print(f\"number of chunks in small train: {len(train_dataset_small)}\")\n",
    "val_dataset_small = DualFreqDataset(subjects_list=subjects_val_small,\n",
    "                                     data_dir=datadir_64Hz,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "print(f\"number of chunks in small val: {len(val_dataset_small)}\")\n",
    "test_dataset_small = DualFreqDataset(subjects_list=subjects_test_small,\n",
    "                                      data_dir=datadir_64Hz,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "print(f\"number of chunks in small test: {len(test_dataset_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ec509",
   "metadata": {},
   "source": [
    "### Save Dataset Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset chunks\n",
    "torch.save(train_dataset.chunks, 'DualFreqDatasets/train_dataset_chunks.pt')\n",
    "torch.save(val_dataset.chunks, 'DualFreqDatasets/val_dataset_chunks.pt')\n",
    "torch.save(test_dataset.chunks, 'DualFreqDatasets/test_dataset_chunks.pt')\n",
    "torch.save(train_dataset_small.chunks, 'DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "torch.save(val_dataset_small.chunks, 'DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "torch.save(test_dataset_small.chunks, 'DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e4c60",
   "metadata": {},
   "source": [
    "### Load Saved Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f596d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved datasets\n",
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 10 minutes\n",
    "chunk_stride = 3000 # 2.5 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=[],\n",
    "                                data_dir=None,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "train_dataset.chunks = torch.load('DualFreqDatasets/train_dataset_chunks.pt')\n",
    "val_dataset = DualFreqDataset(subjects_list=[],\n",
    "                              data_dir=None,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "val_dataset.chunks = torch.load('DualFreqDatasets/val_dataset_chunks.pt')\n",
    "test_dataset = DualFreqDataset(subjects_list=[],\n",
    "                               data_dir=None,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "test_dataset.chunks = torch.load('DualFreqDatasets/test_dataset_chunks.pt')\n",
    "train_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                       data_dir=None,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "train_dataset_small.chunks = torch.load('DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "val_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                     data_dir=None,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "val_dataset_small.chunks = torch.load('DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "test_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                      data_dir=None,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "test_dataset_small.chunks = torch.load('DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149adfa",
   "metadata": {},
   "source": [
    "## Model Demo (shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e30d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 2])\n",
      "temp_lf shape: torch.Size([1200, 5])\n",
      "temp_labels shape: torch.Size([1200])\n",
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 2929])\n",
      "[DEBUG] cnn output length 2929 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 5])\n",
      "output shape: torch.Size([1200, 1, 5])\n",
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 3000])\n",
      "[DEBUG] cnn output length 3000 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 5])\n",
      "output2 shape: torch.Size([1200, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='CNN',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "output = model(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output shape: {output.shape}\")\n",
    "\n",
    "model2 = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    num_tcn_blocks=5,\n",
    "    tcn_kernel_size=3,\n",
    "    debug=True\n",
    ")\n",
    "output2 = model2(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output2 shape: {output2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c12b",
   "metadata": {},
   "source": [
    "## Get Class Weights\n",
    "We use these for weighted loss, this is to deal with the natural class imbalance in sleep staging data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f80a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(2): 351422, np.int64(0): 144616, np.int64(4): 71508, np.int64(1): 67544, np.int64(3): 24188})\n",
      "Class weights: [0.91176357 1.95214379 0.37520588 5.45128163 1.84392795]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(5)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c533efb",
   "metadata": {},
   "source": [
    "## TCN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec3d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 23:11:12,827] Trial 0 finished with value: 1.5045766830444336 and parameters: {'cnn_output_channels': 32, 'lstm_hidden_size': 256, 'lstm_num_layers': 2, 'dropout': 0.3769399782512186, 'learning_rate': 4.4262497226261545e-05, 'weight_decay': 8.627782547652378e-05, 'label_smoothing': 0.29357380762919666, 'num_tcn_blocks': 4, 'tcn_kernel_size': 5}. Best is trial 0 with value: 1.5045766830444336.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0\n",
      "Best trial value: 1.5045766830444336\n",
      "Best trial params: {'cnn_output_channels': 32, 'lstm_hidden_size': 256, 'lstm_num_layers': 2, 'dropout': 0.3769399782512186, 'learning_rate': 4.4262497226261545e-05, 'weight_decay': 8.627782547652378e-05, 'label_smoothing': 0.29357380762919666, 'num_tcn_blocks': 4, 'tcn_kernel_size': 5}\n"
     ]
    }
   ],
   "source": [
    "num_optuna_trials = 500 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(tcn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f98ed",
   "metadata": {},
   "source": [
    "## Train and test TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.5016 +/- 0.0171\n",
      "Test Accuracy: 0.0098 +/- 0.0000\n",
      "Test Kappa: 0.0000 +/- 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_output_channels = best_trial.params['cnn_output_channels']\n",
    "lstm_hidden_size = best_trial.params['lstm_hidden_size']\n",
    "lstm_num_layers = best_trial.params['lstm_num_layers']\n",
    "dropout = best_trial.params['dropout']\n",
    "learning_rate = best_trial.params['learning_rate']\n",
    "weight_decay = best_trial.params['weight_decay']\n",
    "label_smoothing = best_trial.params['label_smoothing']\n",
    "num_tcn_blocks = best_trial.params['num_tcn_blocks']\n",
    "tcn_kernel_size = best_trial.params['tcn_kernel_size']\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/TCN-LSTM/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=15,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=5,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "\n",
    "    # test the model\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(best_model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# save last run\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "best_tcn_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "torch.save(best_tcn_model.state_dict(), 'best_tcn_model.pth')\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "tcn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix(tcn_mean_confusion, classes=['W','N1','N2','N3','R'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a786f0",
   "metadata": {},
   "source": [
    "## CNN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0\n",
      "Best trial value: 1.256678581237793\n",
      "Best trial params: {'cnn_output_channels': 8, 'lstm_hidden_size': 64, 'num_layers': 6, 'dropout': 0.11284288524075561, 'learning_rate': 0.0003567741435287624, 'weight_decay': 0.0003037286177605603, 'label_smoothing': 0.04836445753495515}\n"
     ]
    }
   ],
   "source": [
    "num_optuna_trials = 500 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(cnn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "clear_output()\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ebffe",
   "metadata": {},
   "source": [
    "## Train and Test CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a5edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250426_231653-16lu7pon</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager/runs/16lu7pon' target=\"_blank\">best-params-0</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager/runs/16lu7pon' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager/runs/16lu7pon</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints/mixed_freq_cnn_lstm exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                  | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | cnn             | HFFeatureExtractorCNN | 43.1 K | train\n",
      "1 | lstm            | LSTM                  | 537 K  | train\n",
      "2 | classifier      | Linear                | 645    | train\n",
      "3 | kappa           | MulticlassCohenKappa  | 0      | train\n",
      "4 | train_criterion | CrossEntropyLoss      | 0      | train\n",
      "5 | val_criterion   | CrossEntropyLoss      | 0      | train\n",
      "------------------------------------------------------------------\n",
      "580 K     Trainable params\n",
      "0         Non-trainable params\n",
      "580 K     Total params\n",
      "2.323     Total estimated model params size (MB)\n",
      "18        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029234886169433594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df37f92847ba48b2ad85cc218da4622a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0037889480590820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea33e08e71734be1a5839f0ebea9f455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028481483459472656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39631dbaf9784909addaad6d02021075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_epoch</td><td>▁</td></tr><tr><td>train_loss_step</td><td>▇▃▄▄▃▅▃▃▅▃▂▄█▂▅▃▂▆▅▅▆▄▁▄▆▃▃▇▃▂▆▃▅▆█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_cohen_kappa</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train_loss_epoch</td><td>1.6958</td></tr><tr><td>train_loss_step</td><td>1.74703</td></tr><tr><td>trainer/global_step</td><td>34</td></tr><tr><td>val_acc</td><td>0.06188</td></tr><tr><td>val_cohen_kappa</td><td>0</td></tr><tr><td>val_loss</td><td>1.59718</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">best-params-0</strong> at: <a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager/runs/16lu7pon' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager/runs/16lu7pon</a><br> View project at: <a href='https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/CNN-Dual-Freq-Sleep-Stager</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250426_231653-16lu7pon/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.6598 +/- 0.0000\n",
      "Test Accuracy: 0.0098 +/- 0.0000\n",
      "Test Kappa: 0.0000 +/- 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_output_channels = best_trial.params['cnn_output_channels']\n",
    "lstm_hidden_size = best_trial.params['lstm_hidden_size']\n",
    "num_layers = best_trial.params['num_layers']\n",
    "dropout = best_trial.params['dropout']\n",
    "learning_rate = best_trial.params['learning_rate']\n",
    "weight_decay = best_trial.params['weight_decay']\n",
    "label_smoothing = best_trial.params['label_smoothing']\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/mixed_freq_cnn_lstm/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=15,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=5,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "\n",
    "    # test the model\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(best_model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "cnn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix(cnn_mean_confusion, classes=['W','N1','N2','N3','R'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
