{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c59be11",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf64d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286811",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5de92c",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to safely convert strings to floats\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Mapping sleep-stage labels to integers\n",
    "# Forward‑fill NaNs in each channel\n",
    "def forward_fill(x: torch.Tensor) -> torch.Tensor:\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x\n",
    "\n",
    "class DualFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 high_freq: int = 32,\n",
    "                 low_freq: int = 8,\n",
    "                 hf_features: list = None,\n",
    "                 lf_features: list = None,\n",
    "                 debug: bool = False):\n",
    "        self.hf_downsample = int(64 // high_freq) # downsample factor for high frequency data\n",
    "        self.lf_downsample = int(64 // low_freq) # downsample factor for low frequency data\n",
    "\n",
    "        SLEEP_STAGE_MAPPING = {\n",
    "            \"W\": 0,    # Wake\n",
    "            \"N1\": 1,   # non-REM stage 1\n",
    "            \"N2\": 2,   # non-REM stage 2\n",
    "            \"N3\": 3,   # non-REM stage 3\n",
    "            \"R\": 4,    # REM\n",
    "            \"Missing\": -1  # Missing label → ignore\n",
    "        }\n",
    "        numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "        converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File {path} does not exist.\")\n",
    "            # Load data for subject\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            \n",
    "            # drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # combine ACC_X, ACC_Y, ACC_Z into a single feature\n",
    "            df['ACC'] = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "            # separate high and low frequency data\n",
    "            df_high = df[hf_features].copy()\n",
    "            df_low = df[lf_features].copy()\n",
    "            # downsample data and labels\n",
    "            df_high = df_high.iloc[::self.hf_downsample, :].reset_index(drop=True)\n",
    "            df_low = df_low.iloc[::self.lf_downsample, :].reset_index(drop=True)\n",
    "            labels_arr = labels_arr[::self.lf_downsample]\n",
    "            # normalize data\n",
    "            df_high = (df_high - df_high.mean()) / (df_high.std().replace(0, 1e-6))\n",
    "            df_low = (df_low - df_low.mean()) / (df_low.std().replace(0, 1e-6))\n",
    "            # create chunks\n",
    "            total_time = int(len(df_high) / high_freq)\n",
    "            n_chunks = int((total_time - chunk_duration) // chunk_stride) + 1\n",
    "            for i in range(n_chunks):\n",
    "                start_time = i * chunk_stride\n",
    "                end_time = start_time + chunk_duration\n",
    "                \n",
    "                start_low = int(start_time * low_freq)\n",
    "                end_low = int(end_time * low_freq)\n",
    "                start_high = int(start_time * high_freq)\n",
    "                end_high = int(end_time * high_freq)\n",
    "\n",
    "                lf_chunk = df_low .iloc[start_low: end_low ].values.astype(np.float32)\n",
    "                hf_chunk = df_high.iloc[start_high:end_high].values.astype(np.float32)\n",
    "                labels_chunk = labels_arr[start_low: end_low]\n",
    "\n",
    "                lf_chunk = forward_fill(torch.tensor(lf_chunk, dtype=torch.float32))\n",
    "                hf_chunk = forward_fill(torch.tensor(hf_chunk, dtype=torch.float32))\n",
    "                labels_chunk = forward_fill(torch.tensor(labels_chunk, dtype=torch.long))\n",
    "                \n",
    "                if (labels_chunk != -1).any():\n",
    "                    self.chunks.append({\n",
    "                        'high': hf_chunk,\n",
    "                        'low': lf_chunk,\n",
    "                        'labels': labels_chunk,\n",
    "                    })\n",
    "        if debug:\n",
    "            print(f\"Loaded {len(self.chunks)} chunks from {len(subjects_list)} subjects.\")\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        hf = chunk['high']\n",
    "        lf = chunk['low']\n",
    "        labels = chunk['labels']\n",
    "        return hf, lf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7387c",
   "metadata": {},
   "source": [
    "## Separate subjects into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d632ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects in train: 80\n",
      "number of subjects in val: 10\n",
      "number of subjects in test: 10\n",
      "number of subjects in small train: 24\n",
      "number of subjects in small val: 3\n",
      "number of subjects in small test: 3\n"
     ]
    }
   ],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "max_length = 2493810 # found experimentally, takes a while to compute\n",
    "\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a9d4",
   "metadata": {},
   "source": [
    "## Construct train, val, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 100 minutes\n",
    "chunk_stride = 3000 # 25 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=subjects_train,\n",
    "                                data_dir=datadir_64Hz,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "print(f\"number of chunks in train: {len(train_dataset)}\")\n",
    "val_dataset = DualFreqDataset(subjects_list=subjects_val,\n",
    "                              data_dir=datadir_64Hz,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "print(f\"number of chunks in val: {len(val_dataset)}\")\n",
    "test_dataset = DualFreqDataset(subjects_list=subjects_test,\n",
    "                               data_dir=datadir_64Hz,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "print(f\"number of chunks in test: {len(test_dataset)}\")\n",
    "train_dataset_small = DualFreqDataset(subjects_list=subjects_train_small,\n",
    "                                       data_dir=datadir_64Hz,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "print(f\"number of chunks in small train: {len(train_dataset_small)}\")\n",
    "val_dataset_small = DualFreqDataset(subjects_list=subjects_val_small,\n",
    "                                     data_dir=datadir_64Hz,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "print(f\"number of chunks in small val: {len(val_dataset_small)}\")\n",
    "test_dataset_small = DualFreqDataset(subjects_list=subjects_test_small,\n",
    "                                      data_dir=datadir_64Hz,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "print(f\"number of chunks in small test: {len(test_dataset_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ec509",
   "metadata": {},
   "source": [
    "### Save Dataset Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset chunks\n",
    "torch.save(train_dataset.chunks, 'DualFreqDatasets/train_dataset_chunks.pt')\n",
    "torch.save(val_dataset.chunks, 'DualFreqDatasets/val_dataset_chunks.pt')\n",
    "torch.save(test_dataset.chunks, 'DualFreqDatasets/test_dataset_chunks.pt')\n",
    "torch.save(train_dataset_small.chunks, 'DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "torch.save(val_dataset_small.chunks, 'DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "torch.save(test_dataset_small.chunks, 'DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e4c60",
   "metadata": {},
   "source": [
    "### Load Saved Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f596d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved datasets\n",
    "hf_features = ['BVP','ACC_X','ACC_Y','ACC_Z']\n",
    "lf_features = ['TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 600 # 10 minutes\n",
    "chunk_stride = 150 # 2.5 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=[],\n",
    "                                data_dir=None,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "train_dataset.chunks = torch.load('DualFreqDatasets/train_dataset_chunks.pt')\n",
    "val_dataset = DualFreqDataset(subjects_list=[],\n",
    "                              data_dir=None,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "val_dataset.chunks = torch.load('DualFreqDatasets/val_dataset_chunks.pt')\n",
    "test_dataset = DualFreqDataset(subjects_list=[],\n",
    "                               data_dir=None,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "test_dataset.chunks = torch.load('DualFreqDatasets/test_dataset_chunks.pt')\n",
    "train_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                       data_dir=None,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "train_dataset_small.chunks = torch.load('DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "val_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                     data_dir=None,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "val_dataset_small.chunks = torch.load('DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "test_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                      data_dir=None,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "test_dataset_small.chunks = torch.load('DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecffb27",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296405c6",
   "metadata": {},
   "source": [
    "## TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76bdd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels, output_channels, kernel_size, dilation, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size,\n",
    "                               stride=stride, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm1d(output_channels)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size,\n",
    "                               stride=1, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(output_channels)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        # 1×1 conv to match channels/stride if needed\n",
    "        self.downsample = (nn.Conv1d(input_channels, output_channels, 1, stride=stride)\n",
    "                           if (stride!=1 or input_channels!=output_channels) else None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels, seq_len)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.drop(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class HFFeatureExtractorTCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=5,\n",
    "                 kernel_size=3,\n",
    "                 base_channels=16,\n",
    "                 final_down=64,     # match CNN’s total downsample factor\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch = in_channels\n",
    "        # build dilated residual blocks (no downsampling here)\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                TemporalBlock(ch, base_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=2**i,\n",
    "                              stride=1,\n",
    "                              dropout=dropout)\n",
    "            )\n",
    "            ch = base_channels\n",
    "        # final 1×1 conv with stride=final_down to downsample by 64\n",
    "        layers.append(nn.Conv1d(ch, out_channels,\n",
    "                                kernel_size=1,\n",
    "                                stride=final_down,\n",
    "                                padding=0))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, in_channels)\n",
    "        x = x.permute(0,2,1)  # → (batch, channels, seq_len)\n",
    "        y = self.tcn(x)       # → (batch, out_channels, seq_len/64)\n",
    "        return y             # leave it in (B, C, T’) form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33b05c",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7742e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels=5,\n",
    "     output_channels=16,\n",
    "     dropout=0.1):\n",
    "        super(HFFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30702101",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=5,\n",
    "                                            kernel_size=3,\n",
    "                                            base_channels=cnn_hidden_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=cnn_output_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # pass high frequency data through CNN    \n",
    "        cnn_features = self.cnn(hf)\n",
    "        if self.debug:\n",
    "            print(f\"cnn output shape: {cnn_features.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        cnn_output_length = cnn_features.shape[2]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        if cnn_output_length > lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} > lf output length {lf_output_length}, downsampling\")\n",
    "            cnn_features = F.interpolate(\n",
    "                cnn_features,\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        elif cnn_output_length < lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} < lf output length {lf_output_length}, downsampling\")\n",
    "            lf = F.interpolate(\n",
    "                lf,\n",
    "                size=cnn_output_length,\n",
    "            )\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {cnn_features.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = cnn_features.permute(2,0,1) # (sequence_length, batch_size, cnn_output_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        '''\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149adfa",
   "metadata": {},
   "source": [
    "## Model Demo (shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e30d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 4])\n",
      "temp_lf shape: torch.Size([1200, 4])\n",
      "temp_labels shape: torch.Size([1200])\n",
      "HF input shape: torch.Size([1, 192000, 4])\n",
      "LF input shape: torch.Size([1, 1200, 4])\n",
      "cnn output shape: torch.Size([1, 16, 2929])\n",
      "[DEBUG] cnn output length 2929 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 4])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 20])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 5])\n",
      "output shape: torch.Size([1200, 1, 5])\n",
      "HF input shape: torch.Size([1, 192000, 4])\n",
      "LF input shape: torch.Size([1, 1200, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 4, 3], expected input[1, 192000, 4] to have 4 channels, but got 192000 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 42\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m model2 \u001b[38;5;241m=\u001b[39m DualFreqSleepStager(\n\u001b[1;32m     27\u001b[0m     hf_input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(hf_features),\n\u001b[1;32m     28\u001b[0m     lf_input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(lf_features),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m output2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_hf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_lf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput2 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput2\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[23], line 65\u001b[0m, in \u001b[0;36mDualFreqSleepStager.forward\u001b[0;34m(self, hf, lf)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLF input shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# pass high frequency data through CNN    \u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m cnn_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnn_features\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 61\u001b[0m, in \u001b[0;36mHFFeatureExtractorTCN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# x: (batch, seq_len, in_channels)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# → (batch, channels, seq_len)\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# → (batch, out_channels, seq_len/64)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch, channels, seq_len)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 4, 3], expected input[1, 192000, 4] to have 4 channels, but got 192000 channels instead"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='CNN',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "output = model(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output shape: {output.shape}\")\n",
    "\n",
    "model2 = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    debug=True\n",
    ")\n",
    "output2 = model2(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output2 shape: {output2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c12b",
   "metadata": {},
   "source": [
    "# Get Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f80a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(2): 676991, np.int64(0): 265097, np.int64(4): 140762, np.int64(1): 129752, np.int64(3): 45954})\n",
      "Class weights: [0.94950603 1.93994081 0.37180878 5.47746007 1.7882042 ]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(5)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f98ed",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8bf1e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250424_110112-o15zzjyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm/runs/o15zzjyz' target=\"_blank\">multiple-hf-channels</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm/runs/o15zzjyz' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm/runs/o15zzjyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints/mixed_freq_cnn_lstm exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                  | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | cnn        | HFFeatureExtractorCNN | 655 K  | train\n",
      "1 | lstm       | LSTM                  | 598 K  | train\n",
      "2 | classifier | Linear                | 1.3 K  | train\n",
      "3 | kappa      | MulticlassCohenKappa  | 0      | train\n",
      "4 | criterion  | CrossEntropyLoss      | 0      | train\n",
      "-------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.021     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031630992889404297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1850a79e11fe4bde96714f2c5267e5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029540061950683594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a95ff8fcd524a4fa8053aea54c3ca47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003050088882446289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8d994488784eb3b966767b5b626045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032546520233154297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4626784193084bb59033944ddb9b7e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003201723098754883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac685f2be595407da7fad3534c3a9103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030927658081054688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a19ec14ca347748a5be5aca5b3e43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032091140747070312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51982681b2242a0b3b7471bab16a24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031685829162597656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0deb034805407db6876dce2f85fdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032176971435546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92da9eb3c8784a2e9521ddf2f7613194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030019283294677734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c313d6d6567a4022872e30b5607c9ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003731250762939453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3958593e44d2495e89db98613c3dc0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030257701873779297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99091bc1b5664e49803a3df6b9e8a57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▅▄▅▃▂▁</td></tr><tr><td>train_loss_step</td><td>▆▅▅▆▆▆▄█▅▅▅▅▅▄▅▃▁▄▂▂▅▅▄▆▅▄▄▅▆▅▆▃▃▃▂▁▁▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇████████</td></tr><tr><td>val_acc</td><td>█▆▃▁▇▁▂▄▅▇</td></tr><tr><td>val_cohen_kappa</td><td>▂▄▁▂▇▃▄▇▇█</td></tr><tr><td>val_loss</td><td>▂▂▃▂▂▆▁▁█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_loss_epoch</td><td>1.4453</td></tr><tr><td>train_loss_step</td><td>1.70188</td></tr><tr><td>trainer/global_step</td><td>659</td></tr><tr><td>val_acc</td><td>0.31358</td></tr><tr><td>val_cohen_kappa</td><td>0.10808</td></tr><tr><td>val_loss</td><td>1.60294</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">multiple-hf-channels</strong> at: <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm/runs/o15zzjyz' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm/runs/o15zzjyz</a><br> View project at: <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_lstm</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250424_110112-o15zzjyz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 128\n",
    "lstm_num_layers = 2\n",
    "lstm_bidirectional = True\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"mixed_freq_cnn_lstm\",\n",
    "    name=\"multiple-hf-channels\"\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_cohen_kappa',\n",
    "    dirpath='checkpoints/mixed_freq_cnn_lstm/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_cohen_kappa',\n",
    "    patience=15,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "    callbacks=[checkpoint_callback] # not using early stopping for now\n",
    ")\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=cnn_output_channels,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=lstm_hidden_size,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=dropout,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "    convnet='CNN',\n",
    "    debug=False\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
