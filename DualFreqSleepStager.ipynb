{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c59be11",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286811",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5de92c",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to safely convert strings to floats\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Mapping sleep-stage labels to integers\n",
    "\n",
    "\n",
    "class DualFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 high_freq: int = 32,\n",
    "                 low_freq: int = 8,\n",
    "                 hf_features: list = None,\n",
    "                 lf_features: list = None,\n",
    "                 debug: bool = False):\n",
    "        self.hf_downsample = int(64 // high_freq) # downsample factor for high frequency data\n",
    "        self.lf_downsample = int(64 // low_freq) # downsample factor for low frequency data\n",
    "\n",
    "        SLEEP_STAGE_MAPPING = {\n",
    "            \"W\": 0,    # Wake\n",
    "            \"N1\": 1,   # non-REM stage 1\n",
    "            \"N2\": 2,   # non-REM stage 2\n",
    "            \"N3\": 3,   # non-REM stage 3\n",
    "            \"R\": 4,    # REM\n",
    "            \"Missing\": -1  # Missing label → ignore\n",
    "        }\n",
    "        numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "        converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File {path} does not exist.\")\n",
    "            # Load data for subject\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            \n",
    "            # drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # separate high and low frequency data\n",
    "            df_high = df[hf_features].copy()\n",
    "            df_low = df[lf_features].copy()\n",
    "            # downsample data and labels\n",
    "            df_high = df_high.iloc[::self.hf_downsample, :].reset_index(drop=True)\n",
    "            df_low = df_low.iloc[::self.lf_downsample, :].reset_index(drop=True)\n",
    "            labels_arr = labels_arr[::self.lf_downsample]\n",
    "            # forward fill features\n",
    "            df_high.ffill(inplace=True)\n",
    "            df_high.bfill(inplace=True)\n",
    "            df_low.ffill(inplace=True)\n",
    "            df_low.bfill(inplace=True)\n",
    "            # normalize data\n",
    "            df_high = (df_high - df_high.mean()) / (df_high.std().replace(0, 1e-6))\n",
    "            df_low = (df_low - df_low.mean()) / (df_low.std().replace(0, 1e-6))\n",
    "            # create chunks\n",
    "            total_time = int(len(df_high) / high_freq)\n",
    "            n_chunks = int((total_time - chunk_duration) // chunk_stride) + 1\n",
    "            for i in range(n_chunks):\n",
    "                start_time = i * chunk_stride\n",
    "                end_time = start_time + chunk_duration\n",
    "                \n",
    "                start_low = int(start_time * low_freq)\n",
    "                end_low = int(end_time * low_freq)\n",
    "                start_high = int(start_time * high_freq)\n",
    "                end_high = int(end_time * high_freq)\n",
    "\n",
    "                lf = df_low .iloc[start_low: end_low ].values.astype(np.float32)\n",
    "                hf = df_high.iloc[start_high:end_high].values.astype(np.float32)\n",
    "                labels = labels_arr[start_low: end_low]\n",
    "\n",
    "                self.chunks.append({\n",
    "                    'high': hf,\n",
    "                    'low': lf,\n",
    "                    'labels': labels,\n",
    "                })\n",
    "        if debug:\n",
    "            print(f\"Loaded {len(self.chunks)} chunks from {len(subjects_list)} subjects.\")\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        hf = torch.tensor(chunk['high'], dtype=torch.float32)\n",
    "        lf = torch.tensor(chunk['low'], dtype=torch.float32)\n",
    "        labels = torch.tensor(chunk['labels'], dtype=torch.long)\n",
    "        return hf, lf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7387c",
   "metadata": {},
   "source": [
    "## Separate subjects into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d632ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "max_length = 2493810 # found experimentally, takes a while to compute\n",
    "\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a9d4",
   "metadata": {},
   "source": [
    "## Construct train, val, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = ['TIMESTAMP','BVP','ACC_X','ACC_Y','ACC_Z']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 100 minutes\n",
    "chunk_stride = 1500 # 25 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=subjects_train,\n",
    "                                data_dir=datadir_64Hz,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "print(f\"number of chunks in train: {len(train_dataset)}\")\n",
    "val_dataset = DualFreqDataset(subjects_list=subjects_val,\n",
    "                              data_dir=datadir_64Hz,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "print(f\"number of chunks in val: {len(val_dataset)}\")\n",
    "test_dataset = DualFreqDataset(subjects_list=subjects_test,\n",
    "                               data_dir=datadir_64Hz,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "print(f\"number of chunks in test: {len(test_dataset)}\")\n",
    "train_dataset_small = DualFreqDataset(subjects_list=subjects_train_small,\n",
    "                                       data_dir=datadir_64Hz,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "print(f\"number of chunks in small train: {len(train_dataset_small)}\")\n",
    "val_dataset_small = DualFreqDataset(subjects_list=subjects_val_small,\n",
    "                                     data_dir=datadir_64Hz,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "print(f\"number of chunks in small val: {len(val_dataset_small)}\")\n",
    "test_dataset_small = DualFreqDataset(subjects_list=subjects_test_small,\n",
    "                                      data_dir=datadir_64Hz,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "print(f\"number of chunks in small test: {len(test_dataset_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecffb27",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296405c6",
   "metadata": {},
   "source": [
    "## TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels, output_channels, kernel_size, dilation, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size,\n",
    "                               stride=stride, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm1d(output_channels)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size,\n",
    "                               stride=1, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(output_channels)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        # 1×1 conv to match channels/stride if needed\n",
    "        self.downsample = (nn.Conv1d(input_channels, output_channels, 1, stride=stride)\n",
    "                           if (stride!=1 or input_channels!=output_channels) else None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels, seq_len)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.drop(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class HFFeatureExtractorTCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=5,\n",
    "                 kernel_size=3,\n",
    "                 base_channels=32,\n",
    "                 final_down=64,     # match CNN’s total downsample factor\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch = in_channels\n",
    "        # build dilated residual blocks (no downsampling here)\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                TemporalBlock(ch, base_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=2**i,\n",
    "                              stride=1,\n",
    "                              dropout=dropout)\n",
    "            )\n",
    "            ch = base_channels\n",
    "        # final 1×1 conv with stride=final_down to downsample by 64\n",
    "        layers.append(nn.Conv1d(ch, out_channels,\n",
    "                                kernel_size=1,\n",
    "                                stride=final_down,\n",
    "                                padding=0))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, in_channels)\n",
    "        x = x.permute(0,2,1)  # → (batch, channels, seq_len)\n",
    "        y = self.tcn(x)       # → (batch, out_channels, seq_len/64)\n",
    "        return y             # leave it in (B, C, T’) form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b33b05c",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7742e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels=5,\n",
    "     output_channels=16, \n",
    "     hidden_channels=32, \n",
    "     dropout=0.1):\n",
    "        super(HFFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=hidden_channels, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_channels, out_channels=hidden_channels, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=hidden_channels, out_channels=hidden_channels, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=hidden_channels, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30702101",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f74707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 cnn_hidden_channels=32,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        hidden_channels=cnn_hidden_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=5,\n",
    "                                            kernel_size=3,\n",
    "                                            base_channels=cnn_hidden_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=cnn_output_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        # pass high frequency data through CNN    \n",
    "        cnn_features = self.cnn(hf)\n",
    "        if self.debug:\n",
    "            print(f\"cnn output shape: {cnn_features.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        cnn_output_length = cnn_features.shape[2]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        if cnn_output_length > lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} > lf output length {lf_output_length}, downsampling\")\n",
    "            cnn_features = F.interpolate(\n",
    "                cnn_features,\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        elif cnn_output_length < lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} < lf output length {lf_output_length}, downsampling\")\n",
    "            lf = F.interpolate(\n",
    "                lf,\n",
    "                size=cnn_output_length,\n",
    "            )\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {cnn_features.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = cnn_features.permute(2,0,1) # (sequence_length, batch_size, cnn_output_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        '''\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149adfa",
   "metadata": {},
   "source": [
    "## Model Demo (shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='CNN',\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "output = model(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output shape: {output.shape}\")\n",
    "\n",
    "model2 = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    debug=True\n",
    ")\n",
    "output2 = model2(temp_hf.unsqueeze(0), temp_lf.unsqueeze(0))\n",
    "print(f\"output2 shape: {output2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c12b",
   "metadata": {},
   "source": [
    "# Get Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(5)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f98ed",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 128\n",
    "lstm_num_layers = 2\n",
    "lstm_bidirectional = True\n",
    "dropout = 0.2\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"mixed_freq_cnn_lstm\",\n",
    "    name=\"multiple-hf-channels\"\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_cohen_kappa',\n",
    "    dirpath='checkpoints/mixed_freq_cnn_lstm/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_cohen_kappa',\n",
    "    patience=15,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "    callbacks=[checkpoint_callback] # not using early stopping for now\n",
    ")\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=cnn_output_channels,\n",
    "    cnn_hidden_channels=32,\n",
    "    lstm_hidden_size=lstm_hidden_size,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=dropout,\n",
    "    num_sleep_stages=5,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "    convnet='CNN',\n",
    "    debug=False\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
