/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_25/final_project/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name              | Type                | Params | Mode
------------------------------------------------------------------
0 | feature_extractor | FeatureExtractorCNN | 37.8 K | train
1 | lstm_model        | SleepStageLSTM      | 58.7 K | train
2 | criterion         | CrossEntropyLoss    | 0      | train
------------------------------------------------------------------
96.5 K    Trainable params
0         Non-trainable params
96.5 K    Total params
0.386     Total estimated model params size (MB)
14        Modules in train mode
0         Modules in eval mode
EXECUTABLE/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/bin/pythonEXECUTABLE
/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_25/final_project/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name              | Type                | Params | Mode
------------------------------------------------------------------
0 | feature_extractor | FeatureExtractorCNN | 37.8 K | train
1 | lstm_model        | SleepStageLSTM      | 58.7 K | train
2 | criterion         | CrossEntropyLoss    | 0      | train
------------------------------------------------------------------
96.5 K    Trainable params
0         Non-trainable params
96.5 K    Total params
0.386     Total estimated model params size (MB)
14        Modules in train mode
0         Modules in eval mode
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name              | Type                | Params | Mode
------------------------------------------------------------------
0 | feature_extractor | FeatureExtractorCNN | 37.8 K | train
1 | lstm_model        | SleepStageLSTM      | 58.7 K | train
2 | criterion         | CrossEntropyLoss    | 0      | train
------------------------------------------------------------------
96.5 K    Trainable params
0         Non-trainable params
96.5 K    Total params
0.386     Total estimated model params size (MB)
14        Modules in train mode
0         Modules in eval mode
EXECUTABLE/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/bin/pythonEXECUTABLE
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name              | Type                | Params | Mode
------------------------------------------------------------------
0 | feature_extractor | FeatureExtractorCNN | 37.8 K | train
1 | lstm_model        | SleepStageLSTM      | 58.7 K | train
2 | criterion         | CrossEntropyLoss    | 0      | train
------------------------------------------------------------------
96.5 K    Trainable params
0         Non-trainable params
96.5 K    Total params
0.386     Total estimated model params size (MB)
14        Modules in train mode
0         Modules in eval mode
/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Monitored metric val_loss = nan is not finite. Previous best value was inf. Signaling Trainer to stop.
