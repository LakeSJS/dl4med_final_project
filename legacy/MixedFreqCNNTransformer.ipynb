{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fe9587",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f31669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd5343",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af42e91",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to safely convert strings to floats\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "# Forward‑fill NaNs in each channel\n",
    "def forward_fill(x: torch.Tensor) -> torch.Tensor:\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f91f51",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "\n",
    "dtype_dict = {\n",
    "    'TIMESTAMP': np.float32,\n",
    "    'BVP': np.float32,\n",
    "    'ACC_X': np.float32,\n",
    "    'ACC_Y': np.float32,\n",
    "    'ACC_Z': np.float32,\n",
    "    'TEMP': np.float32,\n",
    "    'EDA': np.float32,\n",
    "    'HR': np.float32,\n",
    "    'IBI': np.float32,\n",
    "    'Sleep_Stage': 'category',\n",
    "    'Obstructive_Apnea': 'Int64', \n",
    "    'Central_Apnea': 'Int64',\n",
    "    'Hypopnea': 'Int64',\n",
    "    'Multiple_Events': 'Int64'\n",
    "}\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "'''\n",
    "max_length = 0\n",
    "for file in os.listdir(datadir_64Hz):\n",
    "    if file.endswith('_whole_df.csv'):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(datadir_64Hz, file),\n",
    "            dtype={'Sleep_Stage': 'category'},\n",
    "            converters=converters,\n",
    "            low_memory=True\n",
    "        )\n",
    "        max_length = max(max_length, len(df))\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "'''\n",
    "max_length = 2493810 # hardcoded cause this takes a while and doesn't change between runs\n",
    "\n",
    "\n",
    "\n",
    "# Mapping sleep-stage labels to integers\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label → ignore\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Numeric columns for the CSV reader\n",
    "numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "\n",
    "class MixedFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 downsample_freq: int = 64,\n",
    "                 acc_freq: int = 64,\n",
    "                 feature_columns=None,\n",
    "                 debug: bool = False):\n",
    "        \"\"\"\n",
    "        Returns for each chunk:\n",
    "          - non-acceleration features at `downsample_freq`\n",
    "          - acceleration at `acc_freq`\n",
    "          - labels at `downsample_freq`\n",
    "        \"\"\"\n",
    "        # choose features (ACC will be computed)\n",
    "        if feature_columns is None:\n",
    "            self.feature_columns = ['ACC', 'TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI']\n",
    "        else:\n",
    "            self.feature_columns = feature_columns\n",
    "\n",
    "        # factors and lengths\n",
    "        self.downsample     = int(64 // downsample_freq)\n",
    "        self.downsample_acc = int(64 // acc_freq)\n",
    "        self.chunk_length      = int(chunk_duration * downsample_freq)\n",
    "        self.chunk_length_acc  = int(chunk_duration * acc_freq)\n",
    "        self.stride            = int(chunk_stride * downsample_freq)\n",
    "        # to align non‐acc → acc indices\n",
    "        self.ratio = acc_freq / downsample_freq\n",
    "        # which columns to keep *besides* ACC\n",
    "        self.non_acc_idxs = [\n",
    "            i for i, c in enumerate(self.feature_columns)\n",
    "            if c != 'ACC'\n",
    "        ]\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                if debug:\n",
    "                    print(f\"[WARN] Missing file for {SID}, skipping\")\n",
    "                continue\n",
    "\n",
    "            # 1) load\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            if debug:\n",
    "                print(f\"[INFO] {SID}: {len(df)} rows loaded\")\n",
    "\n",
    "            # 2) compute, normalize, & downsample ACC\n",
    "            df['ACC'] = np.sqrt(\n",
    "                df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2\n",
    "            )\n",
    "            if self.downsample_acc != 1:\n",
    "                df = df.iloc[::self.downsample_acc].reset_index(drop=True)\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] {SID}: ACC ↓ to {int(64/self.downsample_acc)} Hz → {len(df)} rows\")\n",
    "            acc_arr = df['ACC'].values.astype(np.float32)\n",
    "            acc_arr = (acc_arr - acc_arr.mean()) / acc_arr.std()\n",
    "\n",
    "\n",
    "\n",
    "            # 3) downsample *all* channels for non‐acc view\n",
    "            df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] {SID}: non-ACC ↓ to {int(64/self.downsample)} Hz → {len(df)} rows\")\n",
    "\n",
    "            # 4) drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # 5) normalize features\n",
    "            for c in self.feature_columns:\n",
    "                df[c] = (df[c] - df[c].mean()) / df[c].std() # normalizing per subject, should we do globally?\n",
    "\n",
    "            # 6) assemble feature matrix\n",
    "            data_arr = df[self.feature_columns].values.astype(np.float32)\n",
    "\n",
    "            # 7) pad short records\n",
    "            T = data_arr.shape[0]\n",
    "            if T < self.chunk_length:\n",
    "                pad = self.chunk_length - T\n",
    "                data_arr   = np.vstack([data_arr,\n",
    "                                        np.full((pad, data_arr.shape[1]), np.nan,\n",
    "                                                dtype=np.float32)])\n",
    "                labels_arr = np.concatenate(\n",
    "                    [labels_arr, np.full((pad,), -1, dtype=int)]\n",
    "                )\n",
    "                T = self.chunk_length\n",
    "\n",
    "            # 8) slice into overlapping chunks\n",
    "            for start in range(0, T - self.chunk_length + 1, self.stride):\n",
    "                end       = start + self.chunk_length\n",
    "                start_acc = int(start * self.ratio)\n",
    "                end_acc   = start_acc + self.chunk_length_acc\n",
    "\n",
    "                non_acc_chunk = data_arr[start:end, self.non_acc_idxs]\n",
    "                acc_chunk     = acc_arr[start_acc:end_acc]\n",
    "                label_chunk   = labels_arr[start:end]\n",
    "\n",
    "                self.chunks.append({\n",
    "                    'non_acc': non_acc_chunk,\n",
    "                    'acc':     acc_chunk,\n",
    "                    'labels':  label_chunk\n",
    "                })\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[INFO] Built {len(self.chunks)} total chunks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        c = self.chunks[idx]\n",
    "        non_acc = torch.tensor(c['non_acc'], dtype=torch.float32)\n",
    "        acc     = torch.tensor(c['acc'],     dtype=torch.float32)\n",
    "        labels  = torch.tensor(c['labels'],  dtype=torch.long)\n",
    "\n",
    "        # forward‑fill each\n",
    "        non_acc = forward_fill(non_acc)\n",
    "        acc     = forward_fill(acc.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        return non_acc, acc, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009766f0",
   "metadata": {},
   "source": [
    "## Split Subjects into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a37633",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "# overwrite with smaller dataset for development (20% of original)\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a592a2a",
   "metadata": {},
   "source": [
    "## Construct Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf88515",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_acc_freq = 0.2\n",
    "acc_freq = 32\n",
    "chunk_duration = 600\n",
    "chunk_stride = 300\n",
    "train_dataset_mixed = MixedFreqDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train dataset: {len(train_dataset_mixed)}\")\n",
    "val_dataset_mixed = MixedFreqDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val dataset: {len(val_dataset_mixed)}\")\n",
    "test_dataset_mixed = MixedFreqDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test dataset: {len(test_dataset_mixed)}\")\n",
    "\n",
    "train_dataset_mixed_small = MixedFreqDataset(subjects_list=subjects_train_small,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train dataset small: {len(train_dataset_mixed_small)}\")\n",
    "val_dataset_mixed_small = MixedFreqDataset(subjects_list=subjects_val_small,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val dataset small: {len(val_dataset_mixed_small)}\")\n",
    "test_dataset_mixed_small = MixedFreqDataset(subjects_list=subjects_test_small,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test dataset small: {len(test_dataset_mixed_small)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80034880",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50572a23",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACCFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, output_channels=16):\n",
    "        super(ACCFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931e606",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb55c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # shape: [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, T, d_model]\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class SleepStagingTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                    input_dim: int,\n",
    "                    num_classes: int = 5,\n",
    "                    num_heads: int = 4,\n",
    "                    num_layers: int = 4,\n",
    "                    d_model: int = 128,\n",
    "                    depth: int = 4,\n",
    "                    dropout: float = 0.1,\n",
    "                    max_len: int = 1024,\n",
    "                    debug: bool = False,):\n",
    "        super().__init__()\n",
    "        self.debug = debug\n",
    "        # 1) Project input to d_model\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        # 2) Create positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        # 3) Create encoder layers\n",
    "        self.encoder = Encoder(\n",
    "            dim=d_model,\n",
    "            depth=depth,\n",
    "            heads=num_heads,\n",
    "            ff_mult = 4,\n",
    "            ff_dropout = dropout,\n",
    "            attn_dropout = dropout,\n",
    "            attn_flash = True,\n",
    "            ff_glu = True,\n",
    "        )\n",
    "        # 4) Continuous transformer wrapper\n",
    "        self.continuous_wrapper = ContinuousTransformerWrapper(\n",
    "            dim_in = d_model,\n",
    "            attn_layers = self.encoder,\n",
    "            max_seq_len = max_len,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.debug:\n",
    "            print(f\"Transformer Input shape: {x.shape}\")\n",
    "        x = self.input_projection(x) \n",
    "        if self.debug:\n",
    "            print(f\"After input projection shape: {x.shape}\")\n",
    "        x = self.positional_encoding(x)\n",
    "        if self.debug:\n",
    "            print(f\"After positional encoding shape: {x.shape}\")\n",
    "        x = self.continuous_wrapper(x)\n",
    "        if self.debug:\n",
    "            print(f\"After continuous wrapper shape: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4f742",
   "metadata": {},
   "source": [
    "## Combined Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedFreqCNNTransformer(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                    non_acc_dim: int,\n",
    "                    cnn_output_channels: int,\n",
    "                    xformer_d_model: int,\n",
    "                    xformer_depth: int,\n",
    "                    xformer_heads: int,\n",
    "                    dropout: float,\n",
    "                    num_classes: int,\n",
    "                    downsampled_chunk_length: int,\n",
    "                    lr: float = 1e-3,\n",
    "                    weight_decay: float = 1e-5,\n",
    "                    weight_tensor: torch.Tensor = None,\n",
    "                    debug: bool = False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.debug = debug\n",
    "        self.cnn = ACCFeatureExtractorCNN(output_channels=cnn_output_channels)\n",
    "        self.transformer = SleepStagingTransformer(\n",
    "            input_dim=cnn_output_channels + non_acc_dim,\n",
    "            num_classes=num_classes,\n",
    "            num_heads=xformer_heads,\n",
    "            num_layers=xformer_depth,\n",
    "            d_model=xformer_d_model,\n",
    "            depth=xformer_depth,\n",
    "            dropout=dropout,\n",
    "            max_len = downsampled_chunk_length, # should be the length we downsample the CNN output to\n",
    "            debug=debug\n",
    "        )\n",
    "        self.classifier = nn.Linear(xformer_d_model, num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_classes)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, non_acc, acc):\n",
    "        # Ensure ACC has channel dim\n",
    "        if acc.dim() == 2:\n",
    "            acc = acc.unsqueeze(-1) # should be (batch, acc_length, 1)\n",
    "        \n",
    "        acc_feats = self.cnn(acc)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] ACC CNN output shape: {acc_feats.shape}\")\n",
    "            print(f\"[DEBUG] NON_ACC input shape: {non_acc.shape}\")\n",
    "\n",
    "        # 2) downsample whichever sequence is longer\n",
    "        cnn_output_length = acc_feats.shape[2]\n",
    "        non_acc_output_length = non_acc.shape[1]\n",
    "        if cnn_output_length > non_acc_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] Downsampling ACC features from {cnn_output_length} to {non_acc_output_length}\")\n",
    "            acc_feats = F.interpolate(\n",
    "                acc_feats,\n",
    "                size=non_acc_output_length)\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] Downsampling non-ACC features from {non_acc_output_length} to {cnn_output_length}\")\n",
    "            non_acc = F.interpolate(\n",
    "                non_acc.permute(0,2,1),  # (batch, non_acc_dim, non_acc_length) (for interpolate function syntax)\n",
    "                size=cnn_output_length)\n",
    "            non_acc = non_acc.permute(0,2,1)  # (batch, non_acc_length, non_acc_dim) (switching back)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] ACC features shape: {acc_feats.shape}\")\n",
    "            print(f\"[DEBUG] non-ACC features shape: {non_acc.shape}\")\n",
    "\n",
    "        # 3) build transformer input - concatenate along the feature dimension\n",
    "        acc_seq = acc_feats.permute(0, 2, 1)  # should be (batch, seq_len, cnn_output_dim)\n",
    "        \n",
    "        xformer_in = torch.cat([acc_seq, non_acc], dim=2)  # (batch, seq_len, cnn_output_dim + non_acc_dim)\n",
    "        # without batch_first = true, LSTM input shape is (seq_len, batch_size, features)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Transformer input shape: {xformer_in.shape}\")\n",
    "        # 4) pass through transformer\n",
    "        xformer_out = self.transformer(xformer_in)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Transformer output shape: {xformer_out.shape}\")\n",
    "        # 5) pass through classifier\n",
    "        xformer_out = xformer_out.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Transformer output after permute shape: {xformer_out.shape}\")\n",
    "        xformer_out = self.classifier(xformer_out)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Classifier output shape: {xformer_out.shape}\")\n",
    "        return xformer_out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        non_acc, acc, labels = batch\n",
    "        '''\n",
    "        non_acc: (batch, non_acc_length, non_acc_dim)\n",
    "        acc:     (batch, acc_length)  or  (batch, acc_length, 1)\n",
    "        labels:  (batch, non_acc_length)\n",
    "        '''\n",
    "        y_hat = self(non_acc, acc)\n",
    "        \n",
    "\n",
    "\n",
    "        # flatten\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        labels_flat  = labels.reshape(batch_size * output_length)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = self.criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        non_acc, acc, labels = batch\n",
    "        '''\n",
    "        non_acc: (batch, non_acc_length, non_acc_dim)\n",
    "        acc:     (batch, acc_length)  or  (batch, acc_length, 1)\n",
    "        labels:  (batch, non_acc_length)\n",
    "        '''\n",
    "        y_hat = self(non_acc, acc)\n",
    "\n",
    "        # flatten\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        labels_flat  = labels.reshape(batch_size * output_length)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = self.criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "        # calculate accuracy\n",
    "        predictions = torch.argmax(y_hat_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = predictions[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "\n",
    "        # calculate cohen's kappa\n",
    "        mask = labels_flat != -1\n",
    "        y_valid = labels_flat[mask]\n",
    "        preds_valid = predictions[mask]\n",
    "        if y_valid.numel() > 0:\n",
    "            self.kappa.update(preds_valid, y_valid)\n",
    "\n",
    "        # log metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\",  acc,  prog_bar=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        k = self.kappa.compute()\n",
    "        self.log(\"val_cohen_kappa\", torch.nan_to_num(k,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577374bc",
   "metadata": {},
   "source": [
    "## Demo Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_non_acc, temp_acc, temp_labels = train_dataset_mixed[0]\n",
    "print(f\"Non-acc shape: {temp_non_acc.shape}\")\n",
    "print(f\"ACC shape: {temp_acc.shape}\")\n",
    "print(f\"Labels shape: {temp_labels.shape}\")\n",
    "\n",
    "model = MixedFreqCNNTransformer(\n",
    "    non_acc_dim = temp_non_acc.shape[1],\n",
    "    cnn_output_channels = 16,\n",
    "    xformer_d_model = 128,\n",
    "    xformer_depth = 4,\n",
    "    xformer_heads = 4,\n",
    "    dropout = 0.1,\n",
    "    num_classes = 5,\n",
    "    downsampled_chunk_length = temp_non_acc.shape[0],\n",
    "    lr = 1e-3,\n",
    "    weight_decay = 1e-5,\n",
    "    weight_tensor = None,\n",
    "    debug = True)\n",
    "mdl_out = model(temp_non_acc.unsqueeze(0), temp_acc.unsqueeze(0).unsqueeze(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eedf09",
   "metadata": {},
   "source": [
    "## Get Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca458082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(2): 200438, np.int64(0): 88223, np.int64(4): 43309, np.int64(1): 40679, np.int64(3): 13025})\n",
      "Class weights: [0.87431622 1.89618231 0.38483122 5.92205758 1.78103397]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset_mixed, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(5)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edef330",
   "metadata": {},
   "source": [
    "# Tiny overfit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71232c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure model can overfit\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"mixed_freq_cnn_transformer\",\n",
    "    name=\"overfit_test\",\n",
    "    reinit=True\n",
    ")\n",
    "model = MixedFreqCNNTransformer(\n",
    "    non_acc_dim = temp_non_acc.shape[1],\n",
    "    cnn_output_channels = 16,\n",
    "    xformer_d_model = 128,\n",
    "    xformer_depth = 4,\n",
    "    xformer_heads = 4,\n",
    "    dropout = 0.1,\n",
    "    num_classes = 5,\n",
    "    downsampled_chunk_length = temp_non_acc.shape[0],\n",
    "    lr = 1e-3,\n",
    "    weight_decay = 1e-5,\n",
    "    weight_tensor = torch.tensor(class_weights, dtype=torch.float32),\n",
    "    debug = False)\n",
    "# grab 5 samples\n",
    "tiny_train_loader = DataLoader(train_dataset_mixed, batch_size=5, shuffle=True)\n",
    "tiny_val_loader = DataLoader(val_dataset_mixed, batch_size=5, shuffle=True)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20, \n",
    "    limit_train_batches=1, \n",
    "    limit_val_batches=1, \n",
    "    logger=wandb_logger,\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "trainer.fit(model, tiny_train_loader, tiny_val_loader)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa62ada",
   "metadata": {},
   "source": [
    "# Hyperparam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd406532",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4730cb0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09626fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250422_141936-p6ud1x87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer/runs/p6ud1x87' target=\"_blank\">dainty-firebrand-4</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer/runs/p6ud1x87' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/mixed_freq_cnn_transformer/runs/p6ud1x87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                    | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | cnn         | ACCFeatureExtractorCNN  | 172 K  | train\n",
      "1 | transformer | SleepStagingTransformer | 1.4 M  | train\n",
      "2 | classifier  | Linear                  | 645    | train\n",
      "3 | criterion   | CrossEntropyLoss        | 0      | train\n",
      "4 | kappa       | MulticlassCohenKappa    | 0      | train\n",
      "----------------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "6.121     Total estimated model params size (MB)\n",
      "145       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.005411863327026367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287567064d7e438fad86525f098242dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002852916717529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c5b73090d24ff595ff4a85d0ace913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032303333282470703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b777a90a5f14df1ad7491bf90fa0290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_cohen_kappa improved. New best score: 0.000\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032241344451904297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acdadd5396445c8afa3e0c2a171dc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031692981719970703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e395e2a82104f6f9b07345af0ffde64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029935836791992188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214d23e9a0324511ba26204308d547a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031785964965820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc269c8ec2fc4a8b88c666fa518e3da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029876232147216797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b5ab69d7c6483eb5d3736ef254c86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030105113983154297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0c9e2fafd94b1c86e9d59cf6e5bb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_cohen_kappa improved by 0.002 >= min_delta = 0.0. New best score: 0.002\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003004789352416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbcf16eca9f46eba7c709b9da8644ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030062198638916016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d733d0a28b84ce5bdaa39870c6ff121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030257701873779297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9e2b8b041c4485b33f288f8aab0333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030031204223632812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82dd79e9bf14aa3bf79e59997212bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_cohen_kappa improved by 0.009 >= min_delta = 0.0. New best score: 0.011\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002994060516357422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad786d94fff440d9bac9812644792f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030167102813720703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b283183a7e94a138aabe5140bc27322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002985715866088867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1200aed68c54bd8a0c4bc8f5da9d4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029821395874023438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975500bc082147e489a96593edbf76d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030188560485839844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d3ced9c02d48d9a05e786305bf4140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029954910278320312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab7a906d9db48178ad9fc7395de3062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003015279769897461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138b9704c48049f689b5f0f57a671b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003014802932739258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b75664056f048bc8a0cd3c7df93ca98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003004789352416992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9f94922a8947f398d044534f09135d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003014802932739258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea764d0f71dc478e8ce71684f8e39e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003023862838745117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0863cc83e6465c8ddeec423168f022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030210018157958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a582342be554b00a8029f1811bb6a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_cohen_kappa improved by 0.005 >= min_delta = 0.0. New best score: 0.016\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030624866485595703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371d33763ddd497fb3c9525ade50dfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_cnn_output_channels = 64\n",
    "best_xformer_d_model = 128\n",
    "best_xformer_depth = 4\n",
    "best_xformer_heads = 4\n",
    "best_lr = 1e-3\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"mixed_freq_cnn_transformer\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_cohen_kappa',\n",
    "    dirpath='checkpoints/mixed_freq_cnn_transformer',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_cohen_kappa',\n",
    "    patience=20,\n",
    "    verbose=True,\n",
    "    mode='max'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    precision=\"16-mixed\",\n",
    ")\n",
    "model = MixedFreqCNNTransformer(\n",
    "    non_acc_dim = 5,\n",
    "    cnn_output_channels = best_cnn_output_channels,\n",
    "    xformer_d_model = best_xformer_d_model,\n",
    "    xformer_depth = best_xformer_depth,\n",
    "    xformer_heads = best_xformer_heads,\n",
    "    dropout = 0.1,\n",
    "    num_classes = 5,\n",
    "    downsampled_chunk_length = temp_non_acc.shape[0],\n",
    "    lr = best_lr,\n",
    "    weight_decay = 1e-5,\n",
    "    weight_tensor = torch.tensor(class_weights, dtype=torch.float32),\n",
    "    debug = False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset_mixed, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_mixed, batch_size=32, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "# Load the model\n",
    "best_model = MixedFreqCNNTransformer.load_from_checkpoint(best_model_path)\n",
    "torch.save(best_model.state_dict(), 'best_CNN_xformer_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
