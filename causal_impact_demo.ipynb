{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b171763c",
   "metadata": {},
   "source": [
    "# Investigation of the impact of causality constraints on a CNN-LSTM sleep staging model\n",
    "\n",
    "### Project goals:\n",
    "##### Classify sleep stages using multi-modal sensor data (BVP, accelerometer, timestamps, temperature).\n",
    "##### Compare model performance and computation between non-causal versus causal architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402878f",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da426bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:39:30.314796Z",
     "iopub.status.busy": "2025-04-16T20:39:30.314553Z",
     "iopub.status.idle": "2025-04-16T20:41:36.200713Z",
     "shell.execute_reply": "2025-04-16T20:41:36.200235Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dc944f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:36.203188Z",
     "iopub.status.busy": "2025-04-16T20:41:36.202813Z",
     "iopub.status.idle": "2025-04-16T20:41:37.977573Z",
     "shell.execute_reply": "2025-04-16T20:41:37.977221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2959180/190206057.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  demo_df = pd.read_csv(demo_csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR',\n",
      "       'IBI', 'Sleep_Stage', 'Obstructive_Apnea', 'Central_Apnea', 'Hypopnea',\n",
      "       'Multiple_Events'],\n",
      "      dtype='object')\n",
      "TIMESTAMP            float64\n",
      "BVP                  float64\n",
      "ACC_X                float64\n",
      "ACC_Y                 object\n",
      "ACC_Z                float64\n",
      "TEMP                 float64\n",
      "EDA                  float64\n",
      "HR                   float64\n",
      "IBI                  float64\n",
      "Sleep_Stage           object\n",
      "Obstructive_Apnea    float64\n",
      "Central_Apnea        float64\n",
      "Hypopnea             float64\n",
      "Multiple_Events      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo csv, get columns\n",
    "demo_csv_path = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/S016_whole_df.csv'\n",
    "demo_df = pd.read_csv(demo_csv_path)\n",
    "print(demo_df.columns)\n",
    "col_dtypes = demo_df.dtypes\n",
    "print(col_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d51dae",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38a702b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:37.979049Z",
     "iopub.status.busy": "2025-04-16T20:41:37.978870Z",
     "iopub.status.idle": "2025-04-16T20:41:41.686216Z",
     "shell.execute_reply": "2025-04-16T20:41:41.685828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI', 'Sleep_Stage', 'Obstructive_Apnea', 'Central_Apnea', 'Hypopnea', 'Multiple_Events']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2959180/534420349.py:24: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(datadir_64Hz, file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP            float64\n",
      "BVP                  float64\n",
      "ACC_X                float64\n",
      "ACC_Y                 object\n",
      "ACC_Z                float64\n",
      "TEMP                 float64\n",
      "EDA                  float64\n",
      "HR                   float64\n",
      "IBI                  float64\n",
      "Sleep_Stage           object\n",
      "Obstructive_Apnea    float64\n",
      "Central_Apnea        float64\n",
      "Hypopnea             float64\n",
      "Multiple_Events      float64\n",
      "dtype: object\n",
      "❌ Column ACC_Y failed: Unable to parse string \"N1\" at position 2054657\n",
      "❌ Column Sleep_Stage failed: Unable to parse string \"P\" at position 0\n"
     ]
    }
   ],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "\n",
    "dtype_dict = {\n",
    "    'TIMESTAMP': np.float32,\n",
    "    'BVP': np.float32,\n",
    "    'ACC_X': np.float32,\n",
    "    'ACC_Y': np.float32,\n",
    "    'ACC_Z': np.float32,\n",
    "    'TEMP': np.float32,\n",
    "    'EDA': np.float32,\n",
    "    'HR': np.float32,\n",
    "    'IBI': np.float32,\n",
    "    'Sleep_Stage': 'category',\n",
    "    'Obstructive_Apnea': 'Int64', \n",
    "    'Central_Apnea': 'Int64',\n",
    "    'Hypopnea': 'Int64',\n",
    "    'Multiple_Events': 'Int64'\n",
    "}\n",
    "\n",
    "file = 'S016_whole_df.csv'\n",
    "df_head = pd.read_csv(os.path.join(datadir_64Hz, file), nrows=5)\n",
    "print(df_head.columns.tolist())\n",
    "\n",
    "df = pd.read_csv(os.path.join(datadir_64Hz, file))\n",
    "print(df.dtypes)\n",
    "\n",
    "df = pd.read_csv(os.path.join(datadir_64Hz, file), low_memory=False)\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        pd.to_numeric(df[col], errors='raise')\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Column {col} failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a23638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:41.687850Z",
     "iopub.status.busy": "2025-04-16T20:41:41.687643Z",
     "iopub.status.idle": "2025-04-16T20:41:41.690768Z",
     "shell.execute_reply": "2025-04-16T20:41:41.690409Z"
    }
   },
   "outputs": [],
   "source": [
    "# get max sequence length\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "'''\n",
    "max_length = 0\n",
    "for file in os.listdir(datadir_64Hz):\n",
    "    if file.endswith('_whole_df.csv'):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(datadir_64Hz, file),\n",
    "            dtype={'Sleep_Stage': 'category'},\n",
    "            converters=converters,\n",
    "            low_memory=True\n",
    "        )\n",
    "        max_length = max(max_length, len(df))\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "'''\n",
    "max_length = 2493810"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcf3ce",
   "metadata": {},
   "source": [
    "### Split subjects into train, val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a0a89c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:41.692203Z",
     "iopub.status.busy": "2025-04-16T20:41:41.692020Z",
     "iopub.status.idle": "2025-04-16T20:41:41.717403Z",
     "shell.execute_reply": "2025-04-16T20:41:41.717031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects in train: 80\n",
      "number of subjects in val: 10\n",
      "number of subjects in test: 10\n",
      "number of subjects in train: 24\n",
      "number of subjects in val: 3\n",
      "number of subjects in test: 3\n"
     ]
    }
   ],
   "source": [
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "# overwrite with smaller dataset for development (20% of original)\n",
    "fraction = 0.3\n",
    "subjects_train = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059ce4b",
   "metadata": {},
   "source": [
    "### Non-windowed dataset class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba2f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:41.718986Z",
     "iopub.status.busy": "2025-04-16T20:41:41.718797Z",
     "iopub.status.idle": "2025-04-16T20:41:41.728283Z",
     "shell.execute_reply": "2025-04-16T20:41:41.727910Z"
    }
   },
   "outputs": [],
   "source": [
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor. If x is 1D (shape [T]),\n",
    "    it's temporarily unsqueezed to [T, 1] and then processed.\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "    \n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        # Optionally, handle the first element if it's NaN\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0  # or choose another default value\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    \n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, max_length, downsample_freq=64, debug=False):\n",
    "        self.subjects = [{} for _ in range(len(subjects_list))]\n",
    "        self.downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "        self.max_length = int(max_length // self.downsample)\n",
    "\n",
    "        for subjectNo, SID in enumerate(subjects_list):\n",
    "            # Load the data for each subject\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    dtype={'Sleep_Stage': 'category'},\n",
    "                    converters=converters,\n",
    "                    low_memory=True\n",
    "                )\n",
    "                if debug:\n",
    "                    print(f\"loaded data for {SID}:\")\n",
    "\n",
    "                # Downsample the data if needed\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling by factor {self.downsample}, rows: {len(df)}\")\n",
    "                \n",
    "                df = df[df['Sleep_Stage'] != 'P'] # remove data before PSG start\n",
    "                for col in ['ACC_X', 'ACC_Y', 'ACC_Z','BVP', 'TEMP', 'TIMESTAMP']:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                ACC = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2) # assuming its unlikely each acc channel really carries important information\n",
    "                df_X = df[['TIMESTAMP', 'BVP', 'TEMP']].copy()\n",
    "                df_X['ACC'] = ACC\n",
    "                # Normalize the features (z-score normalization per subject)\n",
    "                TEMP_norm = (df_X['TEMP'] - df_X['TEMP'].mean()) / df_X['TEMP'].std()\n",
    "                df_X['TEMP'] = TEMP_norm\n",
    "                BVP_norm = (df_X['BVP'] - df_X['BVP'].mean()) / df_X['BVP'].std()\n",
    "                df_X['BVP'] = BVP_norm\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "                \n",
    "                # Pad/truncate the data to the downsampled max_length\n",
    "                if len(df_X) > self.max_length:\n",
    "                    if debug:\n",
    "                        print(f\"Truncating data for {SID} from {len(df_X)} to {self.max_length} samples.\")\n",
    "                    df_X = df_X.iloc[:self.max_length]\n",
    "                    df_Y = df_Y.iloc[:self.max_length]\n",
    "                else:\n",
    "                    padding_length = self.max_length - len(df_X)\n",
    "                    padding = pd.DataFrame(np.nan, index=np.arange(padding_length), columns=df_X.columns)\n",
    "                    df_X = pd.concat([df_X, padding], ignore_index=True)\n",
    "                    df_Y = pd.concat([df_Y, pd.Series([-1] * padding_length)], ignore_index=True)\n",
    "                self.subjects[subjectNo] = {\n",
    "                    'data': df_X.values.astype(np.float32),  # shape: [T, C]\n",
    "                    'labels': df_Y.to_numpy(),                 # shape: [T]\n",
    "                    'SID': SID\n",
    "                }\n",
    "                if debug:\n",
    "                    print(f\"Data shape for {SID}: {df_X.shape}, Labels shape: {df_Y.shape}\")\n",
    "            else:\n",
    "                warning(f\"File {file_path} does not exist. Skipping subject {SID}.\")\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "        data = torch.tensor(subject['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(subject['labels'], dtype=torch.long)\n",
    "\n",
    "        data = forward_fill(data) # fill NaNs with previous values\n",
    "        return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415af8c0",
   "metadata": {},
   "source": [
    "### Mixed Frequency Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666c0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7bda52",
   "metadata": {},
   "source": [
    "### Chunked Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010b522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:41.729777Z",
     "iopub.status.busy": "2025-04-16T20:41:41.729634Z",
     "iopub.status.idle": "2025-04-16T20:41:41.739864Z",
     "shell.execute_reply": "2025-04-16T20:41:41.739490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sleep stage mapping as before\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor.\n",
    "    If x is 1D (shape [T]), it is temporarily unsqueezed to [T, 1].\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "class SleepChunkDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, chunk_duration=600, chunk_stride=300, \n",
    "                 downsample_freq=64, feature_columns=None, debug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            subjects_list (list): List of subject IDs, e.g. [\"SID1\", \"SID2\", ...].\n",
    "            data_dir (str): Directory containing files like \"SID_whole_df.csv\".\n",
    "            chunk_duration (int): Chunk length in seconds.\n",
    "            chunk_stride (int): Stride between chunks in seconds.\n",
    "            downsample_freq (int): Target frequency after downsampling (from 64 Hz).\n",
    "            debug (bool): Whether to print debugging information.\n",
    "            feature_columns (list or None): List of columns to keep (e.g. ['TIMESTAMP', 'BVP', 'ACC', 'TEMP']).\n",
    "                                          If None, a default list is used.\n",
    "        \"\"\"\n",
    "        # Default features; note \"ACC\" is computed from the accelerometer axes.\n",
    "        if feature_columns is None:\n",
    "            self.feature_columns = ['ACC','TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI']\n",
    "        else:\n",
    "            self.feature_columns = feature_columns\n",
    "\n",
    "        self.chunks = []\n",
    "        self.downsample = int(64 // downsample_freq)\n",
    "        self.chunk_length = int(chunk_duration * downsample_freq)\n",
    "        self.stride = int(chunk_stride * downsample_freq)\n",
    "\n",
    "        for SID in subjects_list:\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                # Load the data. The converters dict can be kept from before if you use it for other columns.\n",
    "                df = pd.read_csv(file_path, dtype={'Sleep_Stage': 'category'},\n",
    "                                 converters=converters, low_memory=True)\n",
    "                if debug:\n",
    "                    print(f\"Loaded data for subject {SID}\")\n",
    "\n",
    "                # Downsample: take every self.downsample-th row.\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling (factor {self.downsample}), rows: {len(df)}\")\n",
    "\n",
    "                # Remove rows in the \"Preparation\" phase labeled as 'P'.\n",
    "                df = df[df['Sleep_Stage'] != 'P']\n",
    "\n",
    "                # Convert to numeric for any columns we plan to use (except the computed ones)\n",
    "                for col in df.columns:\n",
    "                    if col in self.feature_columns and col != 'ACC':\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "                # If 'ACC' is requested, compute it from the three accelerometer axes.\n",
    "                if 'ACC' in self.feature_columns:\n",
    "                    df['ACC'] = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "\n",
    "                # Filter the dataframe to the columns of interest.\n",
    "                df_X = df[self.feature_columns].copy()\n",
    "\n",
    "                # Process sleep stage labels: trim whitespace and map to integer.\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = ( df['Sleep_Stage']\n",
    "                    .map(SLEEP_STAGE_MAPPING)\n",
    "                    .fillna(-1)          # everything unknown → “ignore”\n",
    "                    .astype(int) )\n",
    "\n",
    "                # Convert features and labels to numpy arrays.\n",
    "                data_arr = df_X.values.astype(np.float32)\n",
    "                labels_arr = df_Y.to_numpy()\n",
    "                T = data_arr.shape[0]\n",
    "\n",
    "                # If the record is shorter than one chunk, pad it.\n",
    "                if T < self.chunk_length:\n",
    "                    pad_size = self.chunk_length - T\n",
    "                    padding_data = np.full((pad_size, data_arr.shape[1]), np.nan, dtype=np.float32)\n",
    "                    data_arr = np.concatenate([data_arr, padding_data], axis=0)\n",
    "                    padding_labels = np.full((pad_size,), -1)\n",
    "                    labels_arr = np.concatenate([labels_arr, padding_labels], axis=0)\n",
    "                    T = self.chunk_length\n",
    "\n",
    "                # Create overlapping chunks using a sliding window.\n",
    "                for start in range(0, T - self.chunk_length + 1, self.stride):\n",
    "                    end = start + self.chunk_length\n",
    "                    chunk_data = data_arr[start:end, :]\n",
    "                    chunk_labels = labels_arr[start:end]\n",
    "                    self.chunks.append({\n",
    "                        'data': chunk_data,\n",
    "                        'labels': chunk_labels,\n",
    "                        'SID': SID\n",
    "                    })\n",
    "                if debug:\n",
    "                    num_chunks = (T - self.chunk_length) // self.stride + 1\n",
    "                    print(f\"Subject {SID}: {T} samples processed, generated {num_chunks} chunks\")\n",
    "            else:\n",
    "                print(f\"File {file_path} does not exist. Skipping subject {SID}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        data = torch.tensor(chunk['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(chunk['labels'], dtype=torch.long)\n",
    "        # Forward fill to replace any NaN values with the previous valid value.\n",
    "        data = forward_fill(data)\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb17bf",
   "metadata": {},
   "source": [
    "### Construct train, val, and test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d268017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:41:41.741388Z",
     "iopub.status.busy": "2025-04-16T20:41:41.741198Z",
     "iopub.status.idle": "2025-04-16T20:42:18.060637Z",
     "shell.execute_reply": "2025-04-16T20:42:18.060175Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_dataset_windowed = SleepDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 seconds overlap\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "val_dataset_windowed = SleepDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 seconds overlap\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "test_dataset_windowed = SleepDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 second stride\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "'''\n",
    "target_freq = 0.2\n",
    "train_dataset = SleepDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=target_freq, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train dataset: {len(train_dataset)}\")\n",
    "val_dataset = SleepDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=target_freq, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val dataset: {len(val_dataset)}\")                                 \n",
    "test_dataset = SleepDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=target_freq, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test dataset: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ab676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:42:18.062252Z",
     "iopub.status.busy": "2025-04-16T20:42:18.062051Z",
     "iopub.status.idle": "2025-04-16T20:42:55.194699Z",
     "shell.execute_reply": "2025-04-16T20:42:55.194227Z"
    }
   },
   "outputs": [],
   "source": [
    "target_freq = 16\n",
    "train_chunk_dataset = SleepChunkDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=6000,  # 100 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=target_freq,  \n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI', 'ACC'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train chunk dataset: {len(train_chunk_dataset)}\")\n",
    "val_chunk_dataset = SleepChunkDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=6000,  # 100 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=target_freq, \n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI', 'ACC'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val chunk dataset: {len(val_chunk_dataset)}\")\n",
    "test_chunk_dataset = SleepChunkDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=6000,  # 100 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=target_freq, \n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI', 'ACC'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test chunk dataset: {len(test_chunk_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f119ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:42:55.196223Z",
     "iopub.status.busy": "2025-04-16T20:42:55.196029Z",
     "iopub.status.idle": "2025-04-16T20:42:56.614772Z",
     "shell.execute_reply": "2025-04-16T20:42:56.614411Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_chunk_dataset, batch_size=1):\n",
    "    labels = batch[1].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.unique(valid_labels)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "# Class weights: [0.82251347 5.00621272 0.49379841 1.78780618]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f8d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:42:56.616257Z",
     "iopub.status.busy": "2025-04-16T20:42:56.616078Z",
     "iopub.status.idle": "2025-04-16T20:42:56.618139Z",
     "shell.execute_reply": "2025-04-16T20:42:56.617818Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN to downsample acceleration vector by a factor of 320\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036b8a4",
   "metadata": {},
   "source": [
    "## CNN downsampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfebfa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:42:56.619567Z",
     "iopub.status.busy": "2025-04-16T20:42:56.619414Z",
     "iopub.status.idle": "2025-04-16T20:42:56.641969Z",
     "shell.execute_reply": "2025-04-16T20:42:56.641603Z"
    }
   },
   "outputs": [],
   "source": [
    "# sequence length x input channels -> CNN -> shortened sequence length x num hidden channels -> LSTM -> shortened sequence length x num sleep stages\n",
    "\n",
    "class FeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4, cnn_output_channels=128):\n",
    "        super(FeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv5 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool5 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv6 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool6 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv7 = nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool7 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.convx = nn.Conv1d(64, cnn_output_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.bn = nn.BatchNorm1d(cnn_output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Global average pooling to collapse \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # Rearrange to (batch, channels, epoch_samples)\n",
    "        #print(f\"Input shape after permutation: {x.shape}\")\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        #print(f\"Shape after conv1 and pool1: {x.shape}\")\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #print(f\"Shape after conv2 and pool2: {x.shape}\")\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        #print(f\"Shape after conv3 and pool3: {x.shape}\")\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        #print(f\"Shape after conv4 and pool4: {x.shape}\")\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        #print(f\"Shape after conv5 and pool5: {x.shape}\")\n",
    "        #x = self.relu(self.conv6(x))\n",
    "        #x = self.pool6(x)\n",
    "        #print(f\"Shape after conv6 and pool6: {x.shape}\")\n",
    "        #x = self.relu(self.conv7(x))\n",
    "        #x = self.pool7(x)\n",
    "        #print(f\"Shape after conv8 and pool8: {x.shape}\")\n",
    "        x = self.relu(self.convx(x))\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class SleepStageLSTM(nn.Module):\n",
    "    def __init__(self, cnn_output_channels=128, hidden_size=64, num_layers=2, num_sleep_stages=5):\n",
    "        super(SleepStageLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=cnn_output_channels,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_sleep_stages)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in LSTM input\"\n",
    "        # x is of shape (batch, cnn_output_channels, samples)\n",
    "        # LSTM expects input shape of (samples, batch, cnn_output_channels)\n",
    "        x = x.permute(2, 0, 1) # (batch, cnn_output_channels, samples) -> (samples, batch, cnn_output_channels)\n",
    "        #print(f\"Input shape after permutation: {x.shape}\")\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        #print(f\"Shape after LSTM: {lstm_out.shape}\")\n",
    "        # Option 1: produce a prediction for every epoch (each time step)\n",
    "        out = self.fc(lstm_out)   # shape: (batch, num_epochs, num_sleep_stages)\n",
    "        #print(f\"Shape after fully connected layer: {out.shape}\")\n",
    "        \n",
    "        # Option 2: if you want a prediction only for the current epoch,\n",
    "        # you may take the output of the last time step:\n",
    "        #predictions = self.fc(lstm_out[:, -1, :])  # shape: (batch, num_sleep_stages)\n",
    "        return out\n",
    "\n",
    "class OnlineSleepStagingModel(pl.LightningModule):\n",
    "    def __init__(self, in_channels, cnn_output_channels, lstm_hidden_size, num_layers=2, num_sleep_stages=5, learning_rate=0.001, class_weights=None):\n",
    "        super(OnlineSleepStagingModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.feature_extractor = FeatureExtractorCNN(in_channels=in_channels, cnn_output_channels=cnn_output_channels)\n",
    "        self.lstm_model = SleepStageLSTM(cnn_output_channels=cnn_output_channels, hidden_size=lstm_hidden_size, num_layers=num_layers, num_sleep_stages=num_sleep_stages)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore the \"Missing\" label (-1)\n",
    "        if class_weights is not None:\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32), ignore_index=-1)\n",
    "        self.num_sleep_stages = num_sleep_stages\n",
    "        self.cnn_output_channels = cnn_output_channels\n",
    "\n",
    "        self.val_class_counts = Counter()\n",
    "        self.pred_class_counts = Counter()\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=self.num_sleep_stages)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.lstm_model(x) # (samples, batch_size, num_sleep_stages)\n",
    "        assert x.shape[2] == self.num_sleep_stages, \"LSTM output shape != num_sleep_stages\"\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # y shape: [batch_size, T]\n",
    "        y_hat = self(x)  # y_hat shape: [output_length, batch_size, num_sleep_stages]\n",
    "        # Check for NaNs in the network output\n",
    "        assert not torch.isnan(y).any(), \"NaN detected in labels\"\n",
    "        assert not torch.isnan(y_hat).any(), \"NaN detected in network output\"\n",
    "    \n",
    "        # Permute to batch first\n",
    "        y_hat = y_hat.permute(1, 0, 2)\n",
    "        output_length = y_hat.shape[1]\n",
    "        y_expanded = y.unsqueeze(1)\n",
    "        # Downsample y to match y_hat\n",
    "        y_resampled = torch.nn.functional.interpolate(\n",
    "            y_expanded.float(),\n",
    "            size = (output_length,),\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        y_resampled = y_resampled.squeeze(1).long()\n",
    "\n",
    "        # Flatten y_hat and y_resampled for loss calculation\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        y_resampled_flat = y_resampled.reshape(batch_size * output_length)\n",
    "\n",
    "        unique_labels = torch.unique(y_resampled_flat)\n",
    "        assert ((unique_labels >= -1) & (unique_labels < self.num_sleep_stages)).all(), \\\n",
    "       \"Found a label outside valid range!\"\n",
    "\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(y_hat_flat, y_resampled_flat)\n",
    "        # Check loss for finiteness\n",
    "        assert torch.isfinite(loss), \"Loss is not finite\"\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch  # y shape: [batch_size, T]\n",
    "        y_hat = self(x)  # y_hat shape: [output_length, batch_size, num_sleep_stages]\n",
    "        # Permute to batch first\n",
    "        y_hat = y_hat.permute(1, 0, 2)\n",
    "        output_length = y_hat.shape[1]\n",
    "        y_expanded = y.unsqueeze(1)\n",
    "        # Downsample y to match y_hat\n",
    "        y_resampled = torch.nn.functional.interpolate(\n",
    "            y_expanded.float(),\n",
    "            size = (output_length,),\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        y_resampled = y_resampled.squeeze(1).long()\n",
    "\n",
    "        # Flatten y_hat and y_resampled for loss calculation\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        y_resampled_flat = y_resampled.reshape(batch_size * output_length)\n",
    "        predictions = torch.argmax(y_hat_flat, dim=1)\n",
    "        # Calculate Cohen's Kappa\n",
    "        assert predictions.shape[0] == y_resampled_flat.shape[0], f\"Predictions and labels have different shapes (dim 0) {predictions.shape[0]} vs {y_resampled_flat.shape[0]}\"\n",
    "        cohen_kappa_score = self.kappa(predictions, y_resampled_flat)\n",
    "        self.log(\"val_cohen_kappa\", cohen_kappa_score, prog_bar=True)\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(y_hat_flat, y_resampled_flat)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "\n",
    "        # Update class counts\n",
    "        # y_resampled_flat: [batch_size * output_length]\n",
    "        # predictions: [batch_size * output_length]\n",
    "\n",
    "        mask = y_resampled_flat != 0\n",
    "        y_valid = y_resampled_flat[mask]\n",
    "        preds_valid = predictions[mask]\n",
    "\n",
    "        if y_valid.numel() > 0:\n",
    "            self.kappa.update(preds_valid, y_valid)\n",
    "            self.val_class_counts.update(y_valid.cpu().tolist())\n",
    "            self.pred_class_counts.update(preds_valid.cpu().tolist())\n",
    "\n",
    "        return loss\n",
    "  \n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Log Cohen's Kappa\n",
    "        if self.kappa.confmat.sum() > 0:\n",
    "            cohen_kappa_score = self.kappa.compute()\n",
    "            self.log(\"val_cohen_kappa\", cohen_kappa_score, prog_bar=True)\n",
    "            self.kappa.reset()\n",
    "        else:\n",
    "            self.log(\"val_cohen_kappa\", 0.0, prog_bar=True)\n",
    "\n",
    "        # W&B class distribution bar plots\n",
    "        class_labels = list(range(self.num_sleep_stages))\n",
    "        val_counts = [self.val_class_counts.get(c, 0) for c in class_labels]\n",
    "        pred_counts = [self.pred_class_counts.get(c, 0) for c in class_labels]\n",
    "\n",
    "        for c in range(self.num_sleep_stages):\n",
    "            self.log(f\"class_count_true/{c}\", self.val_class_counts.get(c, 0), on_epoch=True, prog_bar=False)\n",
    "            self.log(f\"class_count_pred/{c}\", self.pred_class_counts.get(c, 0), on_epoch=True, prog_bar=False)\n",
    "\n",
    "        self.val_class_counts.clear()\n",
    "        self.pred_class_counts.clear()\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "class CNNClassifier(pl.LightningModule):\n",
    "    def __init__(self, in_channels, cnn_output_channels, lstm_hidden_size, num_layers=2, num_sleep_stages=5, learning_rate=0.001):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.feature_extractor = FeatureExtractorCNN(in_channels=in_channels, cnn_output_channels=cnn_output_channels)\n",
    "        self.classifier = nn.Linear(cnn_output_channels, num_sleep_stages)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore the \"Missing\" label (-1)\n",
    "        self.num_sleep_stages = num_sleep_stages\n",
    "        self.cnn_output_channels = cnn_output_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        assert x.shape[2] == self.num_sleep_stages, \"CNN output shape != num_sleep_stages\"\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df131758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:42:56.643838Z",
     "iopub.status.busy": "2025-04-16T20:42:56.643653Z",
     "iopub.status.idle": "2025-04-16T20:43:01.554544Z",
     "shell.execute_reply": "2025-04-16T20:43:01.553996Z"
    }
   },
   "outputs": [],
   "source": [
    "# demo of model elements\n",
    "temp_input = train_chunk_dataset[0][0]\n",
    "print(f\"Input shape: {temp_input.shape} (epoch_samples, channels)\")\n",
    "CNN_model = FeatureExtractorCNN(in_channels=6, cnn_output_channels=128)\n",
    "CNN_model.eval()\n",
    "cnn_output = CNN_model(temp_input.unsqueeze(0))\n",
    "print(f\"Output shape: {cnn_output.shape} (batch_size, cnn_output_channels, epoch_samples)\")\n",
    "LSTM_model = SleepStageLSTM(cnn_output_channels=128, hidden_size=64, num_layers=2, num_sleep_stages=5)\n",
    "LSTM_output = LSTM_model(cnn_output)\n",
    "\n",
    "# demo of combined model\n",
    "combined_model = OnlineSleepStagingModel(in_channels=6, cnn_output_channels=128, lstm_hidden_size=64, num_layers=2, num_sleep_stages=5)\n",
    "combined_model.eval()\n",
    "combined_output = combined_model(temp_input.unsqueeze(0))\n",
    "print(f\"Combined model output shape: {combined_output.shape} (samples, batch_size, num_sleep_stages)\")\n",
    "print(combined_output.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171e2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:43:01.556215Z",
     "iopub.status.busy": "2025-04-16T20:43:01.556023Z",
     "iopub.status.idle": "2025-04-16T20:43:01.558642Z",
     "shell.execute_reply": "2025-04-16T20:43:01.558317Z"
    }
   },
   "outputs": [],
   "source": [
    "print(temp_input.shape[0] / combined_output.shape[0])\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdddd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T20:43:01.559950Z",
     "iopub.status.busy": "2025-04-16T20:43:01.559751Z",
     "iopub.status.idle": "2025-04-16T23:58:30.909126Z",
     "shell.execute_reply": "2025-04-16T23:58:30.908723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the combined model\n",
    "wandb_logger = WandbLogger(project=\"sleep_stage_classification\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    #fast_dev_run=True,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    ")\n",
    "model = OnlineSleepStagingModel(in_channels=6, cnn_output_channels=32, lstm_hidden_size=128, num_layers=2, num_sleep_stages=5, learning_rate=1e-3, class_weights=weight_tensor) #no class weights for now\n",
    "train_loader = DataLoader(train_chunk_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_chunk_dataset, batch_size=8, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()\n",
    "# Load the best model\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "best_model = OnlineSleepStagingModel.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b731ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:58:30.911586Z",
     "iopub.status.busy": "2025-04-16T23:58:30.911456Z",
     "iopub.status.idle": "2025-04-16T23:58:30.916366Z",
     "shell.execute_reply": "2025-04-16T23:58:30.916049Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128])\n",
    "    num_layers = 2\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "\n",
    "    wandb_logger = WandbLogger(name=f\"CNN{cnn_output_channels}_hs{lstm_hidden_size}_lr{learning_rate}\", project=\"optuna_sleep_stage_classification\")\n",
    "    # DataLoaders (resample based on batch size)\n",
    "    train_loader = DataLoader(train_chunk_dataset, batch_size=16, num_workers=8, shuffle=True)\n",
    "    val_loader = DataLoader(val_chunk_dataset, batch_size=16, num_workers=8, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = OnlineSleepStagingModel(\n",
    "        in_channels=6,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        num_sleep_stages=5,\n",
    "        learning_rate=learning_rate,\n",
    "        class_weights=class_weights\n",
    "    )\n",
    "\n",
    "    # Trainer with pruning callback\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        devices=1,\n",
    "        accelerator=\"gpu\",\n",
    "        logger=wandb_logger,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988a5280",
   "metadata": {},
   "source": [
    "## CNN To Sleep Transformer approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3067a",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd221abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:58:30.917719Z",
     "iopub.status.busy": "2025-04-16T23:58:30.917564Z",
     "iopub.status.idle": "2025-04-16T23:59:08.594911Z",
     "shell.execute_reply": "2025-04-16T23:59:08.594331Z"
    }
   },
   "outputs": [],
   "source": [
    "downsample_freq = 64\n",
    "train_chunk_dataset_noacc = SleepChunkDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=1800,  # 30 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=downsample_freq,   # freq to downsample to\n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train chunk dataset: {len(train_chunk_dataset)}\")\n",
    "val_chunk_dataset_noacc = SleepChunkDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=1800,\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=downsample_freq,   # freq to downsample to\n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val chunk dataset: {len(val_chunk_dataset)}\")\n",
    "test_chunk_dataset_noacc = SleepChunkDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=1800,\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=downsample_freq,   # freq to downsample to\n",
    "                                 feature_columns=['TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI'],\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test chunk dataset: {len(test_chunk_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8cf03",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630b195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:59:08.596927Z",
     "iopub.status.busy": "2025-04-16T23:59:08.596696Z",
     "iopub.status.idle": "2025-04-16T23:59:08.617886Z",
     "shell.execute_reply": "2025-04-16T23:59:08.617554Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from x_transformers import Encoder, Decoder, ContinuousTransformerWrapper\n",
    "\n",
    "# Positional Encoding module.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # shape: [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, T, d_model]\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class Seq2SeqSleepStager(pl.LightningModule):\n",
    "    def __init__(self, input_dim, num_cnn_features, d_model, num_heads, num_enc_layers,\n",
    "                 num_dec_layers, d_ff, dropout, num_classes, max_length, lr=1e-4, weight_tensor=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): Number of continuous features per timestep.\n",
    "            d_model (int): Transformer model dimension.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            num_enc_layers (int): Number of encoder layers.\n",
    "            num_dec_layers (int): Number of decoder layers.\n",
    "            d_ff (int): Feed-forward dimension (e.g., 256).\n",
    "            dropout (float): Dropout rate.\n",
    "            num_classes (int): Number of sleep stage labels.\n",
    "            max_length (int): Maximum sequence length.\n",
    "            lr (float): Learning rate.\n",
    "            weight_tensor (Tensor or None): Optional tensor of shape [vocab_size] for weighted loss.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['weight_tensor'])\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "        self.cnn = FeatureExtractorCNN(in_channels=input_dim, cnn_output_channels=num_cnn_features)\n",
    "        # Continuous encoder: embeds continuous input.\n",
    "        self.encoder = ContinuousTransformerWrapper(\n",
    "            attn_layers=Encoder(\n",
    "                dim=d_model,\n",
    "                depth=num_enc_layers,\n",
    "                heads=num_heads,\n",
    "                ff_mult=d_ff // d_model,\n",
    "                attn_dropout=dropout\n",
    "            ),\n",
    "            dim_in=num_cnn_features,\n",
    "            max_seq_len=max_length\n",
    "        )\n",
    "        \n",
    "        # For the decoder, assume sleep stage labels are discrete tokens.\n",
    "        # E.g., if you have 5 sleep stages plus a special SOS token.\n",
    "        vocab_size = num_classes + 1\n",
    "        self.vocab_size = vocab_size\n",
    "        self.decoder_embed = nn.Embedding(vocab_size, d_model)\n",
    "        \n",
    "        # Standard decoder with cross-attention enabled.\n",
    "        self.decoder = Decoder(\n",
    "            dim=d_model,\n",
    "            depth=num_dec_layers,\n",
    "            heads=num_heads,\n",
    "            ff_mult=d_ff // d_model,\n",
    "            attn_dropout=dropout,\n",
    "            cross_attend=True\n",
    "        )\n",
    "        \n",
    "        # Positional encoding for the decoder.\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len=max_length)\n",
    "        \n",
    "        # Linear projection to convert decoder output to vocab logits.\n",
    "        self.out_proj = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # Use cross-entropy loss; pass weight_tensor if provided.\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=0)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (Tensor): Continuous input tensor of shape [B, src_len, input_dim].\n",
    "            tgt (Tensor): Target token sequence [B, tgt_len]. For training, this should be teacher-forced (shifted right).\n",
    "        Returns:\n",
    "            logits (Tensor): Output logits of shape [B, tgt_len, vocab_size].\n",
    "        \"\"\"\n",
    "        unique_vals = torch.unique(tgt)\n",
    "        #print(f\"Unique target token indices: {unique_vals}\")\n",
    "        assert torch.all(tgt >= 0) and torch.all(tgt < self.vocab_size), \"Target indices out of range!\"\n",
    "\n",
    "        # Encode the continuous source data.\n",
    "        memory = self.encoder(src)  # [B, src_len, d_model]\n",
    "        \n",
    "        # Embed target tokens and add positional encodings.\n",
    "        dec_inp = self.decoder_embed(tgt)  # [B, tgt_len, d_model]\n",
    "        dec_inp = self.positional_encoding(dec_inp)\n",
    "        \n",
    "        # Decode using memory as context.\n",
    "        dec_out = self.decoder(dec_inp, context=memory)  # [B, tgt_len, d_model]\n",
    "        logits = self.out_proj(dec_out)  # [B, tgt_len, vocab_size]\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Expect batch to be a tuple: (src, tgt).\n",
    "        src, tgt = batch\n",
    "        # Teacher forcing: decoder input is tgt[:, :-1], target is tgt[:, 1:].\n",
    "        logits = self(src, tgt[:, :-1])\n",
    "        target = tgt[:, 1:]\n",
    "        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), target.reshape(-1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, tgt = batch\n",
    "        logits = self(src, tgt[:, :-1])\n",
    "        target = tgt[:, 1:]\n",
    "        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), target.reshape(-1))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f123e3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:59:08.619424Z",
     "iopub.status.busy": "2025-04-16T23:59:08.619262Z",
     "iopub.status.idle": "2025-04-16T23:59:45.609071Z",
     "shell.execute_reply": "2025-04-16T23:59:45.608753Z"
    }
   },
   "outputs": [],
   "source": [
    "src,tgt = next(iter(DataLoader(train_chunk_dataset_noacc, batch_size=8)))\n",
    "print(f\"Source shape: {src.shape} (batch_size, epoch_samples, channels)\")\n",
    "print(f\"Target shape: {tgt.shape} (batch_size, epoch_samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa3323",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaec113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:59:45.613470Z",
     "iopub.status.busy": "2025-04-16T23:59:45.613275Z",
     "iopub.status.idle": "2025-04-16T23:59:45.615846Z",
     "shell.execute_reply": "2025-04-16T23:59:45.615529Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Max length: {max_length}\")\n",
    "print(f\"Max length after downsampling: {int(max_length // (64 // 0.2))}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d99b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:59:45.617094Z",
     "iopub.status.busy": "2025-04-16T23:59:45.616939Z",
     "iopub.status.idle": "2025-04-16T23:59:45.622124Z",
     "shell.execute_reply": "2025-04-16T23:59:45.621838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the transformer\n",
    "wandb_logger = WandbLogger(name=\"online_sleep_staging_model\", project=\"sleep_stage_transformer\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    precision=16,\n",
    "    gradient_clip_val=1.0,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    ")\n",
    "model = Seq2SeqSleepStager(\n",
    "    input_dim=5,\n",
    "    num_cnn_features = 32\n",
    "    d_model=128,\n",
    "    num_heads=4, \n",
    "    num_enc_layers=2, \n",
    "    num_dec_layers=2, \n",
    "    d_ff=256, \n",
    "    dropout=0.1, \n",
    "    num_classes=5, \n",
    "    max_length= int(max_length // (64 // 64)),  # Adjusted for downsampling\n",
    "    lr=1e-3,\n",
    "    #weight_tensor=torch.tensor(class_weights, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_chunk_dataset_noacc, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_chunk_dataset_noacc, batch_size=16, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()\n",
    "# Load the best model\n",
    "best_model_path = checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d3983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:59:45.623304Z",
     "iopub.status.busy": "2025-04-16T23:59:45.623164Z",
     "iopub.status.idle": "2025-04-16T23:59:45.626163Z",
     "shell.execute_reply": "2025-04-16T23:59:45.625873Z"
    }
   },
   "outputs": [],
   "source": [
    "# project overview\n",
    "# construct dataset class\n",
    "# - train CNN -> LSTM sleep staging model with causal conv and unidirectional LSTM\n",
    "# - train CNN -> LSTM sleep staging model with non-causal conv and bidirectional LSTM\n",
    "# - compare performance at 64Hz\n",
    "# - compare performance and computational cost at lower sampling rates\n",
    "\n",
    "# unstructured notes\n",
    "# - likely best to combine ACC columns into a single variable. Can't imagine they offer much additional information\n",
    "# - CNN model should use 2D CNNs to extract features across both channels and short-term time windows\n",
    "# - will need to pad data on both sides to ensure input and output sequences for the CNN are the same length\n",
    "\n",
    "\n",
    "# CNN model - input: seq_len x num_channels -> output: seq_len x hidden_size\n",
    "\n",
    "\n",
    "# LSTM model - input: seq_len x hidden_size -> output: seq_len x num_classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3816d5a8",
   "metadata": {},
   "source": [
    "## ACC aware CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799ef11",
   "metadata": {},
   "source": [
    "### Mixed Frequency Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to safely convert strings to floats\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Mapping sleep-stage labels to integers\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label → ignore\n",
    "}\n",
    "\n",
    "# Forward‑fill NaNs in each channel\n",
    "def forward_fill(x: torch.Tensor) -> torch.Tensor:\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x\n",
    "\n",
    "# Numeric columns for the CSV reader\n",
    "numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "\n",
    "class MixedFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 downsample_freq: int = 64,\n",
    "                 acc_freq: int = 64,\n",
    "                 feature_columns=None,\n",
    "                 debug: bool = False):\n",
    "        \"\"\"\n",
    "        Returns for each chunk:\n",
    "          - non-acceleration features at `downsample_freq`\n",
    "          - acceleration at `acc_freq`\n",
    "          - labels at `downsample_freq`\n",
    "        \"\"\"\n",
    "        # choose features (ACC will be computed)\n",
    "        if feature_columns is None:\n",
    "            self.feature_columns = ['ACC', 'TIMESTAMP', 'BVP', 'TEMP', 'HR', 'IBI']\n",
    "        else:\n",
    "            self.feature_columns = feature_columns\n",
    "\n",
    "        # factors and lengths\n",
    "        self.downsample     = int(64 // downsample_freq)\n",
    "        self.downsample_acc = int(64 // acc_freq)\n",
    "        self.chunk_length      = int(chunk_duration * downsample_freq)\n",
    "        self.chunk_length_acc  = int(chunk_duration * acc_freq)\n",
    "        self.stride            = int(chunk_stride * downsample_freq)\n",
    "        # to align non‐acc → acc indices\n",
    "        self.ratio = acc_freq / downsample_freq\n",
    "        # which columns to keep *besides* ACC\n",
    "        self.non_acc_idxs = [\n",
    "            i for i, c in enumerate(self.feature_columns)\n",
    "            if c != 'ACC'\n",
    "        ]\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                if debug:\n",
    "                    print(f\"[WARN] Missing file for {SID}, skipping\")\n",
    "                continue\n",
    "\n",
    "            # 1) load\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            if debug:\n",
    "                print(f\"[INFO] {SID}: {len(df)} rows loaded\")\n",
    "\n",
    "            # 2) compute & downsample ACC\n",
    "            df['ACC'] = np.sqrt(\n",
    "                df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2\n",
    "            )\n",
    "            if self.downsample_acc != 1:\n",
    "                df = df.iloc[::self.downsample_acc].reset_index(drop=True)\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] {SID}: ACC ↓ to {int(64/self.downsample_acc)} Hz → {len(df)} rows\")\n",
    "            acc_arr = df['ACC'].values.astype(np.float32)\n",
    "\n",
    "            # 3) downsample *all* channels for non‐acc view\n",
    "            df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] {SID}: non-ACC ↓ to {int(64/self.downsample)} Hz → {len(df)} rows\")\n",
    "\n",
    "            # 4) drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # 5) assemble feature matrix\n",
    "            data_arr = df[self.feature_columns].values.astype(np.float32)\n",
    "\n",
    "            # 6) pad short records\n",
    "            T = data_arr.shape[0]\n",
    "            if T < self.chunk_length:\n",
    "                pad = self.chunk_length - T\n",
    "                data_arr   = np.vstack([data_arr,\n",
    "                                        np.full((pad, data_arr.shape[1]), np.nan,\n",
    "                                                dtype=np.float32)])\n",
    "                labels_arr = np.concatenate(\n",
    "                    [labels_arr, np.full((pad,), -1, dtype=int)]\n",
    "                )\n",
    "                T = self.chunk_length\n",
    "\n",
    "            # 7) slice into overlapping chunks\n",
    "            for start in range(0, T - self.chunk_length + 1, self.stride):\n",
    "                end       = start + self.chunk_length\n",
    "                start_acc = int(start * self.ratio)\n",
    "                end_acc   = start_acc + self.chunk_length_acc\n",
    "\n",
    "                non_acc_chunk = data_arr[start:end, self.non_acc_idxs]\n",
    "                acc_chunk     = acc_arr[start_acc:end_acc]\n",
    "                label_chunk   = labels_arr[start:end]\n",
    "\n",
    "                self.chunks.append({\n",
    "                    'non_acc': non_acc_chunk,\n",
    "                    'acc':     acc_chunk,\n",
    "                    'labels':  label_chunk\n",
    "                })\n",
    "\n",
    "        if debug:\n",
    "            print(f\"[INFO] Built {len(self.chunks)} total chunks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        c = self.chunks[idx]\n",
    "        non_acc = torch.tensor(c['non_acc'], dtype=torch.float32)\n",
    "        acc     = torch.tensor(c['acc'],     dtype=torch.float32)\n",
    "        labels  = torch.tensor(c['labels'],  dtype=torch.long)\n",
    "\n",
    "        # forward‑fill each\n",
    "        non_acc = forward_fill(non_acc)\n",
    "        acc     = forward_fill(acc.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        return non_acc, acc, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2654737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train dataset: 24\n",
      "Total samples in val dataset: 3\n",
      "Total samples in test dataset: 3\n"
     ]
    }
   ],
   "source": [
    "non_acc_freq = 0.2\n",
    "acc_freq = 32\n",
    "chunk_duration = 12000\n",
    "chunk_stride = 6000\n",
    "train_dataset_mixed = MixedFreqDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train dataset: {len(train_dataset_mixed)}\")\n",
    "val_dataset_mixed = MixedFreqDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in val dataset: {len(val_dataset_mixed)}\")\n",
    "test_dataset_mixed = MixedFreqDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=chunk_duration,\n",
    "                                 chunk_stride=chunk_stride,\n",
    "                                 downsample_freq=non_acc_freq, # downsample to 8Hz\n",
    "                                 acc_freq=acc_freq,\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in test dataset: {len(test_dataset_mixed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91237e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACCFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, output_channels=16):\n",
    "        super(ACCFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=16, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ACCAwareSleepStager(pl.LightningModule):\n",
    "    def __init__(self, non_acc_dim: int,\n",
    "                 cnn_output_channels: int = 16,\n",
    "                 lstm_hidden_size:   int = 64,\n",
    "                 lstm_layers:        int = 2,\n",
    "                 num_sleep_stages:   int = 5,\n",
    "                 lr:                  float = 1e-3,\n",
    "                 weight_tensor:      torch.Tensor = None,\n",
    "                 debug:            bool = False,):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.acc_cnn = ACCFeatureExtractorCNN(cnn_output_channels)\n",
    "\n",
    "        self.lstm_input_size = cnn_output_channels + non_acc_dim\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_input_size,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_layers,\n",
    "                            batch_first=False)\n",
    "        self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "        self.lr        = lr\n",
    "        self.debug      = debug\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "\n",
    "    \n",
    "    def forward(self, non_acc, acc):\n",
    "        \"\"\"\n",
    "        non_acc: (batch, non_acc_length, non_acc_dim)\n",
    "        acc:     (batch, acc_length)  or  (batch, acc_length, 1)\n",
    "        returns:\n",
    "          y_hat (output_length, batch, num_sleep_stages)\n",
    "        \"\"\"\n",
    "        # ensure ACC has a channel dim\n",
    "        if acc.dim() == 2:\n",
    "            acc = acc.unsqueeze(-1)          # now (batch, T, 1)\n",
    "\n",
    "        # 1) ACC → CNN → (batch, num_cnn_feats, cnn_output_length)\n",
    "        acc_feats = self.acc_cnn(acc)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] ACC CNN output shape: {acc_feats.shape}\") # (batch, num_cnn_feats, cnn_output_length)\n",
    "            print(f\"[DEBUG] NON_ACC input shape: {non_acc.shape}\") # (batch, non_acc_length, non_acc_dim)\n",
    "\n",
    "\n",
    "        # 2) downsample whichever sequence is longer\n",
    "        cnn_output_length = acc_feats.shape[2]\n",
    "        non_acc_output_length = non_acc.shape[1]\n",
    "        if cnn_output_length > non_acc_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] Downsampling ACC features from {cnn_output_length} to {non_acc_output_length}\")\n",
    "            acc_feats = F.interpolate(\n",
    "                acc_feats,\n",
    "                size=non_acc_output_length)\n",
    "        else:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] Downsampling non-ACC features from {non_acc_output_length} to {cnn_output_length}\")\n",
    "            non_acc = F.interpolate(\n",
    "                non_acc.permute(0,2,1),  # (batch, non_acc_dim, non_acc_length) (for interpolate function syntax)\n",
    "                size=cnn_output_length)\n",
    "            non_acc = non_acc.permute(0,2,1)  # (batch, non_acc_length, non_acc_dim) (switching back)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] ACC features shape: {acc_feats.shape}\")\n",
    "            print(f\"[DEBUG] non-ACC features shape: {non_acc.shape}\")\n",
    "\n",
    "        # 3) build LSTM input: (T', batch, feature_dim)\n",
    "        a = acc_feats.permute(2, 0, 1)        # (lstm_seq_len, batch, cnn_output_features)\n",
    "        b = non_acc.permute(1, 0, 2)       # (lstm_seq_len, batch, non_acc_dim)\n",
    "        lstm_in = torch.cat([a, b], dim=2)    # (lstm_seq_len, batch, C_cnn + D_nonacc)\n",
    "        # without batch_first = true, LSTM input shape is (seq_len, batch_size, features)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] LSTM input shape: {lstm_in.shape}\")\n",
    "\n",
    "        # 4) LSTM + classifier\n",
    "        lstm_out, _ = self.lstm(lstm_in)      # (lstm_seq_len, batch, lstm_hidden_size)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] LSTM output shape: {lstm_out.shape}\")\n",
    "        y_hat = self.classifier(lstm_out)     # (lstm_seq_len, batch, num_sleep_stages)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] Classifier output shape: {y_hat.shape}\")\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        non_acc, acc, labels = batch\n",
    "        '''\n",
    "        non_acc: (batch, non_acc_length, non_acc_dim)\n",
    "        acc:     (batch, acc_length)  or  (batch, acc_length, 1)\n",
    "        labels:  (batch, non_acc_length)\n",
    "        '''\n",
    "        y_hat = self(non_acc, acc)            # (lstm_seq_len, batch, num_sleep_stages)\n",
    "        y_hat = y_hat.permute(1, 0, 2)        # (batch, lstm_seq_len, num_sleep_stages)\n",
    "\n",
    "\n",
    "        # flatten\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        labels_flat  = labels.reshape(batch_size * output_length)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = self.criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        non_acc, acc, labels = batch\n",
    "        '''\n",
    "        non_acc: (batch, non_acc_length, non_acc_dim)\n",
    "        acc:     (batch, acc_length)  or  (batch, acc_length, 1)\n",
    "        labels:  (batch, non_acc_length)\n",
    "        '''\n",
    "        y_hat = self(non_acc, acc)            # (lstm_seq_len, batch, num_sleep_stages)\n",
    "        y_hat = y_hat.permute(1, 0, 2)        # (batch, lstm_seq_len, num_sleep_stages)\n",
    "\n",
    "        # flatten\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        labels_flat  = labels.reshape(batch_size * output_length)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = self.criterion(y_hat_flat, labels_flat)\n",
    "\n",
    "        # calculate accuracy\n",
    "        predictions = torch.argmax(y_hat_flat, dim=1)\n",
    "        correct = (predictions == labels_flat).sum().item()\n",
    "        total = labels_flat.numel()\n",
    "        acc = correct / total if total > 0 else 0\n",
    "\n",
    "        # calculate cohen's kappa\n",
    "        mask = labels_flat != -1\n",
    "        y_valid = labels_flat[mask]\n",
    "        preds_valid = predictions[mask]\n",
    "        ckappa = self.kappa(preds_valid, y_valid)\n",
    "        # log metrics\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\",  acc,  prog_bar=True)\n",
    "        self.log(\"val_cohen_kappa\", ckappa, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8dea11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-acc shape: torch.Size([2400, 5])\n",
      "ACC shape: torch.Size([384000])\n",
      "Labels shape: torch.Size([2400])\n",
      "Output shape: torch.Size([1, 16, 5929]) (batch_size, cnn_output_channels, epoch_samples)\n",
      "CNN downsampling factor: 64.7664024287401\n",
      "[DEBUG] ACC CNN output shape: torch.Size([1, 16, 5929])\n",
      "[DEBUG] NON_ACC input shape: torch.Size([1, 2400, 5])\n",
      "[DEBUG] Downsampling ACC features from 5929 to 2400\n",
      "[DEBUG] ACC features shape: torch.Size([1, 16, 2400])\n",
      "[DEBUG] non-ACC features shape: torch.Size([1, 2400, 5])\n",
      "[DEBUG] LSTM input shape: torch.Size([2400, 1, 21])\n",
      "[DEBUG] LSTM output shape: torch.Size([2400, 1, 64])\n",
      "[DEBUG] Classifier output shape: torch.Size([2400, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "temp_non_acc, temp_acc, temp_labels = train_dataset_mixed[0]\n",
    "print(f\"Non-acc shape: {temp_non_acc.shape}\")\n",
    "print(f\"ACC shape: {temp_acc.shape}\")\n",
    "print(f\"Labels shape: {temp_labels.shape}\")\n",
    "\n",
    "CNN_model = ACCFeatureExtractorCNN(output_channels=16)\n",
    "CNN_model.eval()\n",
    "cnn_output = CNN_model(temp_acc.unsqueeze(0).unsqueeze(2)) # add batch and channel dimensions\n",
    "print(f\"Output shape: {cnn_output.shape} (batch_size, cnn_output_channels, epoch_samples)\")\n",
    "print(f\"CNN downsampling factor: {temp_acc.shape[0] / cnn_output.shape[2]}\")\n",
    "\n",
    "model = ACCAwareSleepStager(\n",
    "    non_acc_dim=temp_non_acc.shape[1],\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_layers=2,\n",
    "    num_sleep_stages=5,\n",
    "    lr=1e-3,\n",
    "    debug=True\n",
    ")\n",
    "out = model(temp_non_acc.unsqueeze(0), temp_acc.unsqueeze(0).unsqueeze(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ff6f2",
   "metadata": {},
   "source": [
    "### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "549e36cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(2): 30008, np.int64(0): 12604, np.int64(1): 6380, np.int64(4): 5983, np.int64(3): 1688})\n",
      "Class weights: [0.89912726 1.77626959 0.37765263 6.71362559 1.89413338]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset_mixed, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.unique(valid_labels)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the acc aware model\n",
    "wandb_logger = WandbLogger(project=\"acc_aware_model\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    ")\n",
    "model = ACCAwareSleepStager(\n",
    "    non_acc_dim=5,\n",
    "    cnn_output_channels=32,\n",
    "    lstm_hidden_size=128,\n",
    "    lstm_layers=2,\n",
    "    num_sleep_stages=5,\n",
    "    lr=1e-4,\n",
    "    weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset_mixed, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_mixed, batch_size=4, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()\n",
    "# Load the best model\n",
    "best_model_path = checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ba62208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 14:08:04,867] A new study created in memory with name: no-name-da89fa29-b272-4cef-a178-03b35b42bd13\n",
      "/tmp/ipykernel_2675438/562570545.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                   | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | acc_cnn    | ACCFeatureExtractorCNN | 143 K  | train\n",
      "1 | lstm       | LSTM                   | 53.5 K | train\n",
      "2 | classifier | Linear                 | 325    | train\n",
      "3 | criterion  | CrossEntropyLoss       | 0      | train\n",
      "4 | kappa      | MulticlassCohenKappa   | 0      | train\n",
      "--------------------------------------------------------------\n",
      "197 K     Trainable params\n",
      "0         Non-trainable params\n",
      "197 K     Total params\n",
      "0.789     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0036935806274414062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24cb808686c4ede8ef9b95b2355b36d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028028488159179688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822de46ba04843cca70aeeab57e3d4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003129720687866211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f8cc0936ce4585a4cf8e6da55e0464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.545\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031576156616210938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02295a7a2ce4cd3ace0a983d3cee1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003417491912841797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6690a78764ea46418a5c5efc9d25aaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031991004943847656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcdc325b8164bf6b4108b353cce9ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 1.545. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▃▃▆▆██</td></tr><tr><td>train_loss_epoch</td><td>█▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▃▃▆▆██</td></tr><tr><td>val_acc</td><td>▃█▁▁</td></tr><tr><td>val_cohen_kappa</td><td>█▁▁▁</td></tr><tr><td>val_loss</td><td>▁▆█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_loss_epoch</td><td>1.61082</td></tr><tr><td>trainer/global_step</td><td>23</td></tr><tr><td>val_acc</td><td>0.13014</td></tr><tr><td>val_cohen_kappa</td><td>-0.00066</td></tr><tr><td>val_loss</td><td>1.59476</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-flower-7</strong> at: <a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model/runs/2nqcu2sc' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model/runs/2nqcu2sc</a><br> View project at: <a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250417_140249-2nqcu2sc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 14:13:08,105] Trial 0 finished with value: 1.5947610139846802 and parameters: {'cnn_output_channels': 8, 'lstm_hidden_size': 64, 'learning_rate': 0.007126922599516551}. Best is trial 0 with value: 1.5947610139846802.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250417_141308-xdubx9gy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model/runs/xdubx9gy' target=\"_blank\">nf_32hs_128lr_0.0003765617930403359</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model/runs/xdubx9gy' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/acc_aware_model/runs/xdubx9gy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                   | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | acc_cnn    | ACCFeatureExtractorCNN | 155 K  | train\n",
      "1 | lstm       | LSTM                   | 217 K  | train\n",
      "2 | classifier | Linear                 | 645    | train\n",
      "3 | criterion  | CrossEntropyLoss       | 0      | train\n",
      "4 | kappa      | MulticlassCohenKappa   | 0      | train\n",
      "--------------------------------------------------------------\n",
      "374 K     Trainable params\n",
      "0         Non-trainable params\n",
      "374 K     Total params\n",
      "1.497     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0053904056549072266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16c133505be4423a1cc2156d260b11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002758502960205078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbdef455ac7484b870aefa06a23a9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "[W 2025-04-17 14:13:55,843] Trial 1 failed with parameters: {'cnn_output_channels': 32, 'lstm_hidden_size': 128, 'learning_rate': 0.0003765617930403359} because of the following error: NameError(\"name 'exit' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
      "    self.advance()\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 282, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 134, in __next__\n",
      "    batch = super().__next__()\n",
      "            ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py\", line 61, in __next__\n",
      "    batch = next(self.iterator)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 764, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/tmp/ipykernel_2675438/1584747656.py\", line 160, in __getitem__\n",
      "    acc     = forward_fill(acc.unsqueeze(1)).squeeze(1)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2675438/1584747656.py\", line 29, in forward_fill\n",
      "    if torch.isnan(x[t, c]):\n",
      "       ^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2675438/562570545.py\", line 43, in objective\n",
      "    trainer.fit(model, train_loader, val_loader)\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 65, in _call_and_handle_interrupt\n",
      "    exit(1)\n",
      "    ^^^^\n",
      "NameError: name 'exit' is not defined\n",
      "[W 2025-04-17 14:13:55,855] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:282\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    281\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m batch, _, __ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py:134\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/loops/fetchers.py:61\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/utilities/combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators[i])\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    763\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[59], line 160\u001b[0m, in \u001b[0;36mMixedFreqDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    159\u001b[0m non_acc \u001b[38;5;241m=\u001b[39m forward_fill(non_acc)\n\u001b[0;32m--> 160\u001b[0m acc     \u001b[38;5;241m=\u001b[39m \u001b[43mforward_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    161\u001b[0m labels  \u001b[38;5;241m=\u001b[39m forward_fill(labels\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mlong()\n",
      "Cell \u001b[0;32mIn[59], line 29\u001b[0m, in \u001b[0;36mforward_fill\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     30\u001b[0m         x[t, c] \u001b[38;5;241m=\u001b[39m x[t \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, c]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[73], line 43\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset_mixed, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset_mixed, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128])\n",
    "    num_layers = 2\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "\n",
    "    wandb_logger = WandbLogger(name=f\"nf_{cnn_output_channels}hs_{lstm_hidden_size}lr_{learning_rate}\", project=\"acc_aware_model\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    "    )\n",
    "    model = ACCAwareSleepStager(\n",
    "    non_acc_dim=5,\n",
    "    cnn_output_channels=cnn_output_channels,\n",
    "    lstm_hidden_size=lstm_hidden_size,\n",
    "    lstm_layers=2,\n",
    "    num_sleep_stages=5,\n",
    "    lr=learning_rate,\n",
    "    weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset_mixed, batch_size=4, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset_mixed, batch_size=4, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "best_trial = study.best_trial\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {best_trial.value}\")\n",
    "print(\"  Params:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "061f8bcd290e4f398370fa68ae3ecb6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "084459fc345842f49a022b646a4fecb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_19c8a5b8703c459d9678af21025e3d99",
        "IPY_MODEL_5d324b91ae264c97a2385112f3d6ecdc",
        "IPY_MODEL_9c0f4e6b32d344e0a93a65d20d8992d2"
       ],
       "layout": "IPY_MODEL_17d86b8d91d740af9143e3dba23e50e7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "08e3520c6f134f789dd7138bc5dbaed3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b67e2d2ef1b4762a170546a78536cd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0bdc3e162f614c4287a4e470c55612b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "121f38cf2cf3400eaf0a2617e12cbb1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_447dfde265ea48afb5cb1534ff0c96a7",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4c00b748f92c4a5abc131a84fb68085c",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "13f8f7ead5bd4a85b4393822b4bb242d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7be0100d75e5434c8d23515cb7d73810",
       "placeholder": "​",
       "style": "IPY_MODEL_17578430096f4f56a86abb18128579de",
       "tabbable": null,
       "tooltip": null,
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "1549cddb9ed4479bad6afa734ee0a5e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "17578430096f4f56a86abb18128579de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "17d86b8d91d740af9143e3dba23e50e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "18890ce9afb841baaa49bcdbbcdc8409": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0bdc3e162f614c4287a4e470c55612b6",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f96962d7753a47fa8e64ee866e7d9a67",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "19c8a5b8703c459d9678af21025e3d99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_55af6077ca48456aac7c08f5aea41f88",
       "placeholder": "​",
       "style": "IPY_MODEL_62d1df3691334ca4ae14c4b7f650f2ec",
       "tabbable": null,
       "tooltip": null,
       "value": "Epoch 6: 100%"
      }
     },
     "19f4927ce9364232afc8365379ea7e0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b170ae218b44bd398366c25de55e713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b7bf58769fc4bddbe2788c20cea1b60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f71884a7703542e0b12afce8b6eba7f6",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_676450048ef145e4ac4360f01de40249",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "1d0433d0b8fa4395bbc09a37537c23ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1dbc4e4f7d2041e18b43313ed6049522": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1e2a79888f474c0e9050ab5ec110903d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20605bd804644da382704e892a76f1a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e14f8cc9c4fe4e04b79c085fb1f2bed7",
       "placeholder": "​",
       "style": "IPY_MODEL_da1fbeee0359423a95b0fb3ccd18a6a9",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:55&lt;00:00,  0.03it/s]"
      }
     },
     "2132932d1db1424e8ba6951d37cae38a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4fce4508477145ab867126b054da1fa6",
       "placeholder": "​",
       "style": "IPY_MODEL_6901fd18f3fa43b084e8f7f8972fe6ad",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "2743d56bcd294f90b23074c1620e3bcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "28a31db9fbe34e6488cfd66e517670f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a8f2eaab0cb417aad0f35e2309bded2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "2b8cd765361a48e2bf6d75e4abdcc944": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b170ae218b44bd398366c25de55e713",
       "placeholder": "​",
       "style": "IPY_MODEL_b1c4cbad5a2c4e808add7049612d8ed0",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:54&lt;00:00,  0.03it/s]"
      }
     },
     "2c0b554436994196b6c2bdbfcb013fdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c3f60ff0635d4960ad52b7d71037add5",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3f03c6b693304eb2b2e6369eca95d27d",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "2c8a8fb208574e0f85b43acda8662bfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2dfb81af41c34b0d920ad19f652941d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e2a79888f474c0e9050ab5ec110903d",
       "placeholder": "​",
       "style": "IPY_MODEL_d088ac4d375e41d8af576b742835411a",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:58&lt;00:00,  0.03it/s]"
      }
     },
     "2fd8a1f9146e42b2a570d7f5abc28420": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78f8c5e08a9f4038887f8a5669b2266b",
       "placeholder": "​",
       "style": "IPY_MODEL_d019ce9f7d554430b3d8adc7b119d8d2",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "37b44acd99744074b1cd7eb10ca52e6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "3ab985df2c054bdfad7751396cfee06f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "3f03c6b693304eb2b2e6369eca95d27d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "447dfde265ea48afb5cb1534ff0c96a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4881576512c348be846651f3da7e4414": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ab7ca3ef9d44139b5cb9b9b01de97e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b3b14091df148d38a10c9386dbbefe9",
       "placeholder": "​",
       "style": "IPY_MODEL_2743d56bcd294f90b23074c1620e3bcf",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:39&lt;00:00,  0.05it/s]"
      }
     },
     "4c00b748f92c4a5abc131a84fb68085c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d210800952c446b8bf4dc5fe59a9ac2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fce4508477145ab867126b054da1fa6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54d98856f294498dbe3b59e1b3d7e28c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a20018fe35c4ff8ab043f220bddfbfb",
       "placeholder": "​",
       "style": "IPY_MODEL_4881576512c348be846651f3da7e4414",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "54e27a2887524e92bb6b40593d936735": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "55af6077ca48456aac7c08f5aea41f88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b81090610cf4b3b80d4f79726c9cb48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_13f8f7ead5bd4a85b4393822b4bb242d",
        "IPY_MODEL_ecc9bf21f18b4edfb3a9e087f54babf4",
        "IPY_MODEL_4ab7ca3ef9d44139b5cb9b9b01de97e3"
       ],
       "layout": "IPY_MODEL_2a8f2eaab0cb417aad0f35e2309bded2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5cd26e03da0445aaad45034bdd0f3fee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5d324b91ae264c97a2385112f3d6ecdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28a31db9fbe34e6488cfd66e517670f6",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0b67e2d2ef1b4762a170546a78536cd2",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "5ecea160f4f14f20b0ac0a47f31e9724": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d0433d0b8fa4395bbc09a37537c23ea",
       "placeholder": "​",
       "style": "IPY_MODEL_5cd26e03da0445aaad45034bdd0f3fee",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "62d1df3691334ca4ae14c4b7f650f2ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "64de1b79576e4a06b6c11cebd33ab642": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_86681839c28d41f799333d5df2be58c2",
        "IPY_MODEL_ef7f84f6ab834097b5b5b6a558db3716",
        "IPY_MODEL_7ef3352173c042d7b78d7ca987c1ecff"
       ],
       "layout": "IPY_MODEL_37b44acd99744074b1cd7eb10ca52e6c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "676450048ef145e4ac4360f01de40249": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6901fd18f3fa43b084e8f7f8972fe6ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "730fcfd1d6854d1b8da00b6ced116ca6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74b5d4e9654a4bec95d204b2359cfdaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "765461b3d9aa4fbfad09707ff9b5d581": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_54d98856f294498dbe3b59e1b3d7e28c",
        "IPY_MODEL_18890ce9afb841baaa49bcdbbcdc8409",
        "IPY_MODEL_2b8cd765361a48e2bf6d75e4abdcc944"
       ],
       "layout": "IPY_MODEL_b95b6c911b2b4752b03a0cbb09b2a9b3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "78f8c5e08a9f4038887f8a5669b2266b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7be0100d75e5434c8d23515cb7d73810": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c2a58c3e82d43b2bd1bd1fc1ed7accd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2fd8a1f9146e42b2a570d7f5abc28420",
        "IPY_MODEL_c7d8984444f1452a84c0dd741c0e3dd6",
        "IPY_MODEL_d15b41b283d34973a35fbffc1382ae3b"
       ],
       "layout": "IPY_MODEL_74b5d4e9654a4bec95d204b2359cfdaa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7ef3352173c042d7b78d7ca987c1ecff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ace62d3de1ac45999369f8cdcaff851e",
       "placeholder": "​",
       "style": "IPY_MODEL_87acace8819c4d448f225df4534556f0",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:57&lt;00:00,  0.03it/s]"
      }
     },
     "86681839c28d41f799333d5df2be58c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_730fcfd1d6854d1b8da00b6ced116ca6",
       "placeholder": "​",
       "style": "IPY_MODEL_061f8bcd290e4f398370fa68ae3ecb6f",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "87acace8819c4d448f225df4534556f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a20018fe35c4ff8ab043f220bddfbfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ebf1ff90a914027962a566fd1a14486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d210800952c446b8bf4dc5fe59a9ac2",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dc9add1d3b4a4ae6933a75424b2d4aec",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "8f7bd523fe17468ba8b35e80e216427b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_94ae712665db48a180d68ca766952dd4",
       "placeholder": "​",
       "style": "IPY_MODEL_1dbc4e4f7d2041e18b43313ed6049522",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:55&lt;00:00,  0.03it/s]"
      }
     },
     "900ecebc6deb4f7b8c8e2436161366aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90290004a5c448ad8d803ff32a79e339": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "94ae712665db48a180d68ca766952dd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b3b14091df148d38a10c9386dbbefe9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c0f4e6b32d344e0a93a65d20d8992d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2c8a8fb208574e0f85b43acda8662bfd",
       "placeholder": "​",
       "style": "IPY_MODEL_900ecebc6deb4f7b8c8e2436161366aa",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [27:41&lt;00:00,  0.02it/s, v_num=mguf, train_loss_step=1.130, val_cohen_kappa=0.000, val_loss=1.230, train_loss_epoch=1.060]"
      }
     },
     "9d67e1b1d63842f28c9718f217be937b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6092fe65cf14654909281bf8f86c3a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ace62d3de1ac45999369f8cdcaff851e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0ed92806cfe4f49b0c1e65ca738a235": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "b1c4cbad5a2c4e808add7049612d8ed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b8a02756a55e4c42a7069f7b6a05e182": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d67e1b1d63842f28c9718f217be937b",
       "placeholder": "​",
       "style": "IPY_MODEL_db81ccdffdc6400b91fb8ff0cc6ace6f",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "b95b6c911b2b4752b03a0cbb09b2a9b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "be098d69a5cf425e887f6313b1042e06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "be8636885f7b4f498169a01396cc545b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3a5ed741adf4c92aa5128cf5b09bdf1",
        "IPY_MODEL_121f38cf2cf3400eaf0a2617e12cbb1d",
        "IPY_MODEL_c23beb5497c9402ab59485c018bc2d4b"
       ],
       "layout": "IPY_MODEL_3ab985df2c054bdfad7751396cfee06f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c05ea6faf9d14d09bd24b97b22a978c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0c88ff7f551497dafcf41a8a7e75f30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c23beb5497c9402ab59485c018bc2d4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca5027f1c66a4d59bf4b763226340c6e",
       "placeholder": "​",
       "style": "IPY_MODEL_90290004a5c448ad8d803ff32a79e339",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:56&lt;00:00,  0.03it/s]"
      }
     },
     "c3f60ff0635d4960ad52b7d71037add5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4663707afe64b82b0a2198669ce2559": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "c5bd9456411548cebca3a3953be278ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b8a02756a55e4c42a7069f7b6a05e182",
        "IPY_MODEL_8ebf1ff90a914027962a566fd1a14486",
        "IPY_MODEL_2dfb81af41c34b0d920ad19f652941d7"
       ],
       "layout": "IPY_MODEL_b0ed92806cfe4f49b0c1e65ca738a235",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c7d8984444f1452a84c0dd741c0e3dd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_be098d69a5cf425e887f6313b1042e06",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_19f4927ce9364232afc8365379ea7e0c",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "ca5027f1c66a4d59bf4b763226340c6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d019ce9f7d554430b3d8adc7b119d8d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d088ac4d375e41d8af576b742835411a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d15b41b283d34973a35fbffc1382ae3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_54e27a2887524e92bb6b40593d936735",
       "placeholder": "​",
       "style": "IPY_MODEL_eb4e7c4d61844a8f8690e36a96c6e425",
       "tabbable": null,
       "tooltip": null,
       "value": " 15/15 [07:56&lt;00:00,  0.03it/s]"
      }
     },
     "d3a5ed741adf4c92aa5128cf5b09bdf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c05ea6faf9d14d09bd24b97b22a978c0",
       "placeholder": "​",
       "style": "IPY_MODEL_a6092fe65cf14654909281bf8f86c3a0",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "da1fbeee0359423a95b0fb3ccd18a6a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da426793356b44eaaf9f62285af1d568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2132932d1db1424e8ba6951d37cae38a",
        "IPY_MODEL_2c0b554436994196b6c2bdbfcb013fdb",
        "IPY_MODEL_8f7bd523fe17468ba8b35e80e216427b"
       ],
       "layout": "IPY_MODEL_1549cddb9ed4479bad6afa734ee0a5e8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "db81ccdffdc6400b91fb8ff0cc6ace6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc9add1d3b4a4ae6933a75424b2d4aec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e14f8cc9c4fe4e04b79c085fb1f2bed7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e79aeb5aba66440abe9fe9d94d3e8a5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5ecea160f4f14f20b0ac0a47f31e9724",
        "IPY_MODEL_1b7bf58769fc4bddbe2788c20cea1b60",
        "IPY_MODEL_20605bd804644da382704e892a76f1a8"
       ],
       "layout": "IPY_MODEL_c4663707afe64b82b0a2198669ce2559",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e8bf38e27b0b42938566bc1eded6187c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eb4e7c4d61844a8f8690e36a96c6e425": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ecc9bf21f18b4edfb3a9e087f54babf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c0c88ff7f551497dafcf41a8a7e75f30",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8bf38e27b0b42938566bc1eded6187c",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "ef7f84f6ab834097b5b5b6a558db3716": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_08e3520c6f134f789dd7138bc5dbaed3",
       "max": 15,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f947e83000be45c2aa12a4761de8e4f3",
       "tabbable": null,
       "tooltip": null,
       "value": 15
      }
     },
     "f71884a7703542e0b12afce8b6eba7f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f947e83000be45c2aa12a4761de8e4f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f96962d7753a47fa8e64ee866e7d9a67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
