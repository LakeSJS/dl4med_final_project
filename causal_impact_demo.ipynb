{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b171763c",
   "metadata": {},
   "source": [
    "# Investigation of the impact of causality constraints on a CNN-LSTM sleep staging model\n",
    "\n",
    "### Project goals:\n",
    "##### Classify sleep stages using multi-modal sensor data (BVP, accelerometer, timestamps, temperature).\n",
    "##### Compare model performance and computation between non-causal versus causal architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402878f",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da426bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dc944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2298590/190206057.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  demo_df = pd.read_csv(demo_csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR',\n",
      "       'IBI', 'Sleep_Stage', 'Obstructive_Apnea', 'Central_Apnea', 'Hypopnea',\n",
      "       'Multiple_Events'],\n",
      "      dtype='object')\n",
      "TIMESTAMP            float64\n",
      "BVP                  float64\n",
      "ACC_X                float64\n",
      "ACC_Y                 object\n",
      "ACC_Z                float64\n",
      "TEMP                 float64\n",
      "EDA                  float64\n",
      "HR                   float64\n",
      "IBI                  float64\n",
      "Sleep_Stage           object\n",
      "Obstructive_Apnea    float64\n",
      "Central_Apnea        float64\n",
      "Hypopnea             float64\n",
      "Multiple_Events      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# demo csv, get columns\n",
    "demo_csv_path = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/S016_whole_df.csv'\n",
    "demo_df = pd.read_csv(demo_csv_path)\n",
    "print(demo_df.columns)\n",
    "col_dtypes = demo_df.dtypes\n",
    "print(col_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d51dae",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38a702b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI', 'Sleep_Stage', 'Obstructive_Apnea', 'Central_Apnea', 'Hypopnea', 'Multiple_Events']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2298590/2468003919.py:23: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(datadir_64Hz, file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP            float64\n",
      "BVP                  float64\n",
      "ACC_X                 object\n",
      "ACC_Y                float64\n",
      "ACC_Z                float64\n",
      "TEMP                 float64\n",
      "EDA                  float64\n",
      "HR                   float64\n",
      "IBI                  float64\n",
      "Sleep_Stage           object\n",
      "Obstructive_Apnea    float64\n",
      "Central_Apnea        float64\n",
      "Hypopnea             float64\n",
      "Multiple_Events      float64\n",
      "dtype: object\n",
      "❌ Column ACC_X failed: Unable to parse string \"R\" at position 1979585\n",
      "❌ Column Sleep_Stage failed: Unable to parse string \"P\" at position 0\n"
     ]
    }
   ],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "\n",
    "dtype_dict = {\n",
    "    'TIMESTAMP': np.float32,\n",
    "    'BVP': np.float32,\n",
    "    'ACC_X': np.float32,\n",
    "    'ACC_Y': np.float32,\n",
    "    'ACC_Z': np.float32,\n",
    "    'TEMP': np.float32,\n",
    "    'EDA': np.float32,\n",
    "    'HR': np.float32,\n",
    "    'IBI': np.float32,  # <-- missing but important\n",
    "    'Sleep_Stage': 'category',\n",
    "    'Obstructive_Apnea': 'Int64',  # Nullable integer\n",
    "    'Central_Apnea': 'Int64',\n",
    "    'Hypopnea': 'Int64',\n",
    "    'Multiple_Events': 'Int64'\n",
    "}\n",
    "\n",
    "df_head = pd.read_csv(os.path.join(datadir_64Hz, file), nrows=5)\n",
    "print(df_head.columns.tolist())\n",
    "\n",
    "df = pd.read_csv(os.path.join(datadir_64Hz, file))\n",
    "print(df.dtypes)\n",
    "\n",
    "df = pd.read_csv(os.path.join(datadir_64Hz, file), low_memory=False)\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        pd.to_numeric(df[col], errors='raise')\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Column {col} failed: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a23638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 2493810\n"
     ]
    }
   ],
   "source": [
    "# get max sequence length\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "max_length = 0\n",
    "for file in os.listdir(datadir_64Hz):\n",
    "    if file.endswith('_whole_df.csv'):\n",
    "        df = pd.read_csv(\n",
    "            os.path.join(datadir_64Hz, file),\n",
    "            dtype={'Sleep_Stage': 'category'},\n",
    "            converters=converters,\n",
    "            low_memory=True\n",
    "        )\n",
    "        max_length = max(max_length, len(df))\n",
    "print(f\"Max sequence length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcf3ce",
   "metadata": {},
   "source": [
    "### Split subjects into train, val, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a0a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subjects in train: 80\n",
      "number of subjects in val: 10\n",
      "number of subjects in test: 10\n"
     ]
    }
   ],
   "source": [
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d98905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: torch.Size([32, 4]) (channels, epoch_samples), Label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), Subject ID: S002\n",
      "Sample shape: torch.Size([32, 4]) (channels, epoch_samples), Label: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), Subject ID: S002\n",
      "Sample shape: torch.Size([32, 4]) (channels, epoch_samples), Label: tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2]), Subject ID: S002\n"
     ]
    }
   ],
   "source": [
    "sample, label, sid1 = demo_dataset[3]\n",
    "print(f\"Sample shape: {sample.shape} (channels, epoch_samples), Label: {label}, Subject ID: {sid1}\")\n",
    "\n",
    "sample, label, sid2 = demo_dataset[3071]\n",
    "print(f\"Sample shape: {sample.shape} (channels, epoch_samples), Label: {label}, Subject ID: {sid2}\")\n",
    "\n",
    "sample, label, sid3 = demo_dataset[12000]\n",
    "print(f\"Sample shape: {sample.shape} (channels, epoch_samples), Label: {label}, Subject ID: {sid3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059ce4b",
   "metadata": {},
   "source": [
    "### Non-windowed dataset class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor. If x is 1D (shape [T]),\n",
    "    it's temporarily unsqueezed to [T, 1] and then processed.\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "    \n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        # Optionally, handle the first element if it's NaN\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0  # or choose another default value\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    \n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "\n",
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, max_length, downsample_freq=64, debug=False):\n",
    "        self.subjects = [{} for _ in range(len(subjects_list))]\n",
    "        self.downsample = int(64 // downsample_freq)  # Downsample factor\n",
    "        self.max_length = int(max_length // self.downsample)\n",
    "\n",
    "        for subjectNo, SID in enumerate(subjects_list):\n",
    "            # Load the data for each subject\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    dtype={'Sleep_Stage': 'category'},\n",
    "                    converters=converters,\n",
    "                    low_memory=True\n",
    "                )\n",
    "                if debug:\n",
    "                    print(f\"loaded data for {SID}:\")\n",
    "\n",
    "                # Downsample the data if needed\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling by factor {self.downsample}, rows: {len(df)}\")\n",
    "                \n",
    "                df = df[df['Sleep_Stage'] != 'P'] # remove data before PSG start\n",
    "                for col in ['ACC_X', 'ACC_Y', 'ACC_Z','BVP', 'TEMP', 'TIMESTAMP']:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                ACC = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2) # assuming its unlikely each acc channel really carries important information\n",
    "                df_X = df[['TIMESTAMP', 'BVP', 'TEMP']].copy()\n",
    "                df_X['ACC'] = ACC\n",
    "                # Normalize the features (z-score normalization per subject)\n",
    "                TEMP_norm = (df_X['TEMP'] - df_X['TEMP'].mean()) / df_X['TEMP'].std()\n",
    "                df_X['TEMP'] = TEMP_norm\n",
    "                BVP_norm = (df_X['BVP'] - df_X['BVP'].mean()) / df_X['BVP'].std()\n",
    "                df_X['BVP'] = BVP_norm\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "                \n",
    "                # Pad/truncate the data to the downsampled max_length\n",
    "                if len(df_X) > max_length:\n",
    "                    if debug:\n",
    "                        print(f\"Truncating data for {SID} from {len(df_X)} to {max_length} samples.\")\n",
    "                    df_X = df_X.iloc[:max_length]\n",
    "                    df_Y = df_Y.iloc[:max_length]\n",
    "                else:\n",
    "                    padding_length = max_length - len(df_X)\n",
    "                    padding = pd.DataFrame(np.nan, index=np.arange(padding_length), columns=df_X.columns)\n",
    "                    df_X = pd.concat([df_X, padding], ignore_index=True)\n",
    "                    df_Y = pd.concat([df_Y, pd.Series([-1] * padding_length)], ignore_index=True)\n",
    "                self.subjects[subjectNo] = {\n",
    "                    'data': df_X.values.astype(np.float32),  # shape: [T, C]\n",
    "                    'labels': df_Y.to_numpy(),                 # shape: [T]\n",
    "                    'SID': SID\n",
    "                }\n",
    "                if debug:\n",
    "                    print(f\"Data shape for {SID}: {df_X.shape}, Labels shape: {df_Y.shape}\")\n",
    "            else:\n",
    "                warning(f\"File {file_path} does not exist. Skipping subject {SID}.\")\n",
    "    def __len__(self):\n",
    "        return len(self.subjects)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject = self.subjects[idx]\n",
    "        data = torch.tensor(subject['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(subject['labels'], dtype=torch.long)\n",
    "\n",
    "        data = forward_fill(data) # fill NaNs with previous values\n",
    "        labels = forward_fill(labels) # fill NaNs with previous values\n",
    "        return data, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c010b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep stage mapping as before\n",
    "SLEEP_STAGE_MAPPING = {\n",
    "    \"W\": 0,    # Wake\n",
    "    \"N1\": 1,   # non-REM stage 1\n",
    "    \"N2\": 2,   # non-REM stage 2\n",
    "    \"N3\": 3,   # non-REM stage 3\n",
    "    \"R\": 4,    # REM\n",
    "    \"Missing\": -1  # Missing label\n",
    "}\n",
    "\n",
    "def forward_fill(x):\n",
    "    \"\"\"\n",
    "    Performs forward fill on a tensor.\n",
    "    If x is 1D (shape [T]), it is temporarily unsqueezed to [T, 1].\n",
    "    Assumes the first value is valid, or fills it with zero if needed.\n",
    "    \"\"\"\n",
    "    single_channel = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single_channel = True\n",
    "\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    if single_channel:\n",
    "        x = x.squeeze(1)\n",
    "    return x\n",
    "\n",
    "numeric_columns = [\n",
    "    'TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP',\n",
    "    'EDA', 'HR', 'IBI'\n",
    "]\n",
    "converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "class SleepChunkDataset(Dataset):\n",
    "    def __init__(self, subjects_list, data_dir, chunk_duration=600, chunk_stride=300, downsample_freq=64, debug=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            subjects_list (list): List of subject IDs, e.g. [\"SID1\", \"SID2\", ...].\n",
    "            data_dir (str): Directory where files like \"SID_whole_df.csv\" are stored.\n",
    "            chunk_duration (int): Chunk length in seconds (default 600 s for 10 minutes).\n",
    "            chunk_stride (int): Time in seconds to step forward between chunks (default 300 s, for 50% overlap).\n",
    "            downsample_freq (int): Desired sampling frequency after downsampling (original data are at 64 Hz).\n",
    "            debug (bool): If True, print status messages.\n",
    "        \"\"\"\n",
    "        self.chunks = []  # List to store each generated chunk (with its corresponding data, labels, and SID)\n",
    "        # Compute downsample factor (original sampling rate is 64 Hz)\n",
    "        self.downsample = int(64 // downsample_freq)\n",
    "        # Effective sampling rate after downsampling becomes downsample_freq Hz.\n",
    "        self.chunk_length = int(chunk_duration * downsample_freq)\n",
    "        self.stride = int(chunk_stride * downsample_freq)\n",
    "\n",
    "        for SID in subjects_list:\n",
    "            file_path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if os.path.exists(file_path):\n",
    "                df = pd.read_csv(file_path, dtype={'Sleep_Stage': 'category'}, converters=converters, low_memory=True)\n",
    "                if debug:\n",
    "                    print(f\"Loaded data for subject {SID}\")\n",
    "                \n",
    "                # Downsample: every self.downsample-th row\n",
    "                if self.downsample != 1:\n",
    "                    df = df.iloc[::self.downsample].reset_index(drop=True)\n",
    "                    if debug:\n",
    "                        print(f\"After downsampling (factor {self.downsample}), rows: {len(df)}\")\n",
    "                \n",
    "                # Remove rows with \"Preparation\" phase if labeled 'P'\n",
    "                df = df[df['Sleep_Stage'] != 'P']\n",
    "\n",
    "                # Ensure numeric conversion for required columns\n",
    "                for col in ['ACC_X', 'ACC_Y', 'ACC_Z', 'BVP', 'TEMP', 'TIMESTAMP']:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                \n",
    "                # Compute accelerometer magnitude from three axes\n",
    "                ACC = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "                \n",
    "                # Prepare the features: TIMESTAMP, BVP, TEMP and the computed ACC\n",
    "                df_X = df[['TIMESTAMP', 'BVP', 'TEMP']].copy()\n",
    "                df_X['ACC'] = ACC\n",
    "                # Normalize the features (z-score normalization per subject)\n",
    "                TEMP_norm = (df_X['TEMP'] - df_X['TEMP'].mean()) / df_X['TEMP'].std()\n",
    "                df_X['TEMP'] = TEMP_norm\n",
    "                BVP_norm = (df_X['BVP'] - df_X['BVP'].mean()) / df_X['BVP'].std()\n",
    "                df_X['BVP'] = BVP_norm\n",
    "                \n",
    "                # Process sleep stage labels: trim whitespace and map to integer\n",
    "                df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "                df_Y = df['Sleep_Stage'].map(SLEEP_STAGE_MAPPING)\n",
    "                \n",
    "                # Convert features and labels to numpy arrays\n",
    "                data_arr = df_X.values.astype(np.float32)  # shape: [T, C]\n",
    "                labels_arr = df_Y.to_numpy()                # shape: [T]\n",
    "                T = data_arr.shape[0]\n",
    "\n",
    "                # If the record is too short (less than one chunk), pad it with NaNs (-1 for labels)\n",
    "                if T < self.chunk_length:\n",
    "                    pad_size = self.chunk_length - T\n",
    "                    padding_data = np.full((pad_size, data_arr.shape[1]), np.nan, dtype=np.float32)\n",
    "                    data_arr = np.concatenate([data_arr, padding_data], axis=0)\n",
    "                    padding_labels = np.full((pad_size,), -1)\n",
    "                    labels_arr = np.concatenate([labels_arr, padding_labels], axis=0)\n",
    "                    T = self.chunk_length  # update length\n",
    "\n",
    "                # Slide a window over the data with the defined stride to create overlapping chunks\n",
    "                for start in range(0, T - self.chunk_length + 1, self.stride):\n",
    "                    end = start + self.chunk_length\n",
    "                    chunk_data = data_arr[start:end, :]\n",
    "                    chunk_labels = labels_arr[start:end]\n",
    "                    self.chunks.append({\n",
    "                        'data': chunk_data,\n",
    "                        'labels': chunk_labels,\n",
    "                        'SID': SID\n",
    "                    })\n",
    "                if debug:\n",
    "                    num_chunks = (T - self.chunk_length) // self.stride + 1\n",
    "                    print(f\"Subject {SID}: {T} samples processed, generated {num_chunks} chunks\")\n",
    "            else:\n",
    "                print(f\"File {file_path} does not exist. Skipping subject {SID}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        data = torch.tensor(chunk['data'], dtype=torch.float32)\n",
    "        labels = torch.tensor(chunk['labels'], dtype=torch.long)\n",
    "        # Use forward_fill to replace any NaNs with previous values.\n",
    "        data = forward_fill(data)\n",
    "        labels = forward_fill(labels)\n",
    "        return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb17bf",
   "metadata": {},
   "source": [
    "### Construct train, val, and test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d268017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train dataset: 80\n",
      "Total samples in val dataset: 10\n",
      "Total samples in test dataset: 10\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train_dataset_windowed = SleepDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 seconds overlap\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "val_dataset_windowed = SleepDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 seconds overlap\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "test_dataset_windowed = SleepDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 window_size_ms= 20000, # 20 seconds of data\n",
    "                                 stride_ms=5000,        # 5 second stride\n",
    "                                 downsample_freq=8, # downsample to 16Hz\n",
    "                                 debug=False)\n",
    "'''\n",
    "\n",
    "train_dataset = SleepDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=8, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "\n",
    "val_dataset = SleepDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=8, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "test_dataset = SleepDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 max_length=max_length,\n",
    "                                 downsample_freq=8, # downsample to 8Hz\n",
    "                                 debug=False)\n",
    "\n",
    "print(f\"Total samples in train dataset: {len(train_dataset)}\")\n",
    "print(f\"Total samples in val dataset: {len(val_dataset)}\")\n",
    "print(f\"Total samples in test dataset: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc8ab676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in train chunk dataset: 6547\n",
      "Total samples in val chunk dataset: 821\n",
      "Total samples in test chunk dataset: 845\n"
     ]
    }
   ],
   "source": [
    "train_chunk_dataset = SleepChunkDataset(subjects_list=subjects_train,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=600,  # 10 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=0.2,   # downsample to 0.2 Hz\n",
    "                                 debug=False)\n",
    "val_chunk_dataset = SleepChunkDataset(subjects_list=subjects_val,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=600,  # 10 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=0.2,   # downsample to 0.2 Hz\n",
    "                                 debug=False)\n",
    "test_chunk_dataset = SleepChunkDataset(subjects_list=subjects_test,\n",
    "                                 data_dir=datadir_64Hz,\n",
    "                                 chunk_duration=600,  # 10 minutes\n",
    "                                 chunk_stride=300,    # 5 minutes\n",
    "                                 downsample_freq=0.2,   # downsample to 0.2 Hz\n",
    "                                 debug=False)\n",
    "print(f\"Total samples in train chunk dataset: {len(train_chunk_dataset)}\")\n",
    "print(f\"Total samples in val chunk dataset: {len(val_chunk_dataset)}\")\n",
    "print(f\"Total samples in test chunk dataset: {len(test_chunk_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036b8a4",
   "metadata": {},
   "source": [
    "## CNN downsampling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfebfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length x input channels -> CNN -> shortened sequence length x num hidden channels -> LSTM -> shortened sequence length x num sleep stages\n",
    "\n",
    "class FeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4, cnn_output_channels=128):\n",
    "        super(FeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=5, stride=2, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv1d(64, cnn_output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(cnn_output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Global average pooling to collapse \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # Rearrange to (batch, channels, epoch_samples)\n",
    "        #print(f\"Input shape after permutation: {x.shape}\")\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        #print(f\"Shape after conv1 and pool1: {x.shape}\")\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #print(f\"Shape after conv2 and pool2: {x.shape}\")\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        #print(f\"Shape after conv3 and pool3: {x.shape}\")\n",
    "        x = self.relu(self.conv4(x))\n",
    "        #print(f\"Shape after conv4: {x.shape}\")\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SleepStageLSTM(nn.Module):\n",
    "    def __init__(self, cnn_output_channels=128, hidden_size=64, num_layers=2, num_sleep_stages=5):\n",
    "        super(SleepStageLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=cnn_output_channels,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_sleep_stages)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in LSTM input\"\n",
    "        # x is of shape (batch, cnn_output_channels, samples)\n",
    "        # LSTM expects input shape of (samples, batch, cnn_output_channels)\n",
    "        x = x.permute(2, 0, 1) # (batch, cnn_output_channels, samples) -> (samples, batch, cnn_output_channels)\n",
    "        #print(f\"Input shape after permutation: {x.shape}\")\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        #print(f\"Shape after LSTM: {lstm_out.shape}\")\n",
    "        # Option 1: produce a prediction for every epoch (each time step)\n",
    "        out = self.fc(lstm_out)   # shape: (batch, num_epochs, num_sleep_stages)\n",
    "        #print(f\"Shape after fully connected layer: {out.shape}\")\n",
    "        \n",
    "        # Option 2: if you want a prediction only for the current epoch,\n",
    "        # you may take the output of the last time step:\n",
    "        #predictions = self.fc(lstm_out[:, -1, :])  # shape: (batch, num_sleep_stages)\n",
    "        return out\n",
    "\n",
    "class OnlineSleepStagingModel(pl.LightningModule):\n",
    "    def __init__(self, in_channels, cnn_output_channels, lstm_hidden_size, num_layers=2, num_sleep_stages=5, learning_rate=0.001):\n",
    "        super(OnlineSleepStagingModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.feature_extractor = FeatureExtractorCNN(in_channels=4, cnn_output_channels=cnn_output_channels)\n",
    "        self.lstm_model = SleepStageLSTM(cnn_output_channels=cnn_output_channels, hidden_size=lstm_hidden_size, num_layers=num_layers, num_sleep_stages=num_sleep_stages)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore the \"Missing\" label (-1)\n",
    "        self.num_sleep_stages = num_sleep_stages\n",
    "        self.cnn_output_channels = cnn_output_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.lstm_model(x) # (samples, batch_size, num_sleep_stages)\n",
    "        assert x.shape[2] == self.num_sleep_stages, \"LSTM output shape != num_sleep_stages\"\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # y shape: [batch_size, T]\n",
    "        y_hat = self(x)  # y_hat shape: [output_length, batch_size, num_sleep_stages]\n",
    "        # Check for NaNs in the network output\n",
    "        assert not torch.isnan(y).any(), \"NaN detected in labels\"\n",
    "        assert not torch.isnan(y_hat).any(), \"NaN detected in network output\"\n",
    "    \n",
    "        # Permute to batch first\n",
    "        y_hat = y_hat.permute(1, 0, 2)\n",
    "        output_length = y_hat.shape[1]\n",
    "        y_expanded = y.unsqueeze(1)\n",
    "        # Downsample y to match y_hat\n",
    "        y_resampled = torch.nn.functional.interpolate(\n",
    "            y_expanded.float(),\n",
    "            size = (output_length,),\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        y_resampled = y_resampled.squeeze(1).long()\n",
    "\n",
    "        # Flatten y_hat and y_resampled for loss calculation\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        y_resampled_flat = y_resampled.reshape(batch_size * output_length)\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(y_hat_flat, y_resampled_flat)\n",
    "        # Check loss for finiteness\n",
    "        assert torch.isfinite(loss), \"Loss is not finite\"\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch  # y shape: [batch_size, T]\n",
    "        y_hat = self(x)  # y_hat shape: [output_length, batch_size, num_sleep_stages]\n",
    "        # Permute to batch first\n",
    "        y_hat = y_hat.permute(1, 0, 2)\n",
    "        output_length = y_hat.shape[1]\n",
    "        y_expanded = y.unsqueeze(1)\n",
    "        # Downsample y to match y_hat\n",
    "        y_resampled = torch.nn.functional.interpolate(\n",
    "            y_expanded.float(),\n",
    "            size = (output_length,),\n",
    "            mode = 'nearest'\n",
    "        )\n",
    "        y_resampled = y_resampled.squeeze(1).long()\n",
    "\n",
    "        # Flatten y_hat and y_resampled for loss calculation\n",
    "        batch_size, output_length, num_sleep_stages = y_hat.shape\n",
    "        y_hat_flat = y_hat.reshape(batch_size * output_length, num_sleep_stages)\n",
    "        y_resampled_flat = y_resampled.reshape(batch_size * output_length)\n",
    "        predictions = torch.argmax(y_hat_flat, dim=1)\n",
    "        # Calculate Cohen's Kappa\n",
    "        #kappa = MulticlassCohenKappa(num_classes=self.num_sleep_stages)\n",
    "        #cohen_kappa_score = kappa(predictions, y_resampled_flat)\n",
    "        #self.log(\"val_cohen_kappa\", cohen_kappa_score, prog_bar=True)\n",
    "        # Calculate loss\n",
    "        loss = self.criterion(y_hat_flat, y_resampled_flat)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "class CNNClassifier(pl.LightningModule):\n",
    "    def __init__(self, in_channels, cnn_output_channels, lstm_hidden_size, num_layers=2, num_sleep_stages=5, learning_rate=0.001):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.feature_extractor = FeatureExtractorCNN(in_channels=4, cnn_output_channels=cnn_output_channels)\n",
    "        self.lstm_model = SleepStageLSTM(cnn_output_channels=cnn_output_channels, hidden_size=lstm_hidden_size, num_layers=num_layers, num_sleep_stages=num_sleep_stages)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)  # Ignore the \"Missing\" label (-1)\n",
    "        self.num_sleep_stages = num_sleep_stages\n",
    "        self.cnn_output_channels = cnn_output_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.lstm_model(x) # (samples, batch_size, num_sleep_stages)\n",
    "        assert x.shape[2] == self.num_sleep_stages, \"LSTM output shape != num_sleep_stages\"\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df131758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2493810, 4]) (epoch_samples, channels)\n",
      "Output shape: torch.Size([1, 128, 38965]) (batch_size, cnn_output_channels, epoch_samples)\n",
      "Combined model output shape: torch.Size([38965, 1, 5]) (samples, batch_size, num_sleep_stages)\n",
      "38965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined model output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (samples, batch_size, num_sleep_stages)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m temp_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_labels\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (epoch_samples)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 98\u001b[0m, in \u001b[0;36mSleepDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(subject[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     96\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(subject[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 98\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mforward_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# fill NaNs with previous values\u001b[39;00m\n\u001b[1;32m     99\u001b[0m labels \u001b[38;5;241m=\u001b[39m forward_fill(labels) \u001b[38;5;66;03m# fill NaNs with previous values\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels\n",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m, in \u001b[0;36mforward_fill\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         x[\u001b[38;5;241m0\u001b[39m, c] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# or choose another default value\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     28\u001b[0m             x[t, c] \u001b[38;5;241m=\u001b[39m x[t \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, c]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_channel:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# demo of model elements\n",
    "temp_input = train_dataset[0][0]\n",
    "print(f\"Input shape: {temp_input.shape} (epoch_samples, channels)\")\n",
    "CNN_model = FeatureExtractorCNN(in_channels=4, cnn_output_channels=128)\n",
    "cnn_output = CNN_model(temp_input.unsqueeze(0))\n",
    "print(f\"Output shape: {cnn_output.shape} (batch_size, cnn_output_channels, epoch_samples)\")\n",
    "LSTM_model = SleepStageLSTM(cnn_output_channels=128, hidden_size=64, num_layers=2, num_sleep_stages=5)\n",
    "LSTM_output = LSTM_model(cnn_output)\n",
    "\n",
    "# demo of combined model\n",
    "combined_model = OnlineSleepStagingModel(in_channels=4, cnn_output_channels=128, lstm_hidden_size=64, num_layers=2, num_sleep_stages=5)\n",
    "combined_output = combined_model(temp_input.unsqueeze(0))\n",
    "print(f\"Combined model output shape: {combined_output.shape} (samples, batch_size, num_sleep_stages)\")\n",
    "print(combined_output.shape[0])\n",
    "\n",
    "temp_labels = train_dataset[0][1]\n",
    "print(f\"Labels shape: {temp_labels.shape} (epoch_samples)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a171e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.00128320287438\n"
     ]
    }
   ],
   "source": [
    "print(temp_input.shape[0] / combined_output.shape[0])\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3cdddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250414_161127-bp9g4692</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification/runs/bp9g4692' target=\"_blank\">online_sleep_staging_model</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification/runs/bp9g4692' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification/runs/bp9g4692</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_25/dl4med_final_project/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractorCNN | 34.6 K | train\n",
      "1 | lstm_model        | SleepStageLSTM      | 54.6 K | train\n",
      "2 | criterion         | CrossEntropyLoss    | 0      | train\n",
      "------------------------------------------------------------------\n",
      "89.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.2 K    Total params\n",
      "0.357     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002918720245361328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb03321925dd48fcb67c462f66b52ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002937793731689453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fd6d2ecdd04eb0ad9484c6a9996ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003246307373046875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c03edc8247b489e802f5ed179c90eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.359\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031173229217529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35c83f2b7974a67a55f8154a03cf19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 1.342\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031042098999023438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b720384358b446beac353d4e2b4a3715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.341\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003077268600463867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4ac5134a0544c3ad4c356348d58500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 1.336\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003078937530517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89ae636c53d4d1a82e2ac81e5125401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031325817108154297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8416daac6656400ab67680e326db64cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030956268310546875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8640b220e5354418917d647fd8506b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 1.336. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▅▅▅▅▆▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▄▃▃▄▂▂▃█▄▄▄▂▄▅▄▂▃▂▃▄▄▃▅▃▃▃▆▃▄▄▄▁▂▃▃▂▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▇▃▂▁▂▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>6</td></tr><tr><td>train_loss_epoch</td><td>1.24735</td></tr><tr><td>train_loss_step</td><td>1.0131</td></tr><tr><td>trainer/global_step</td><td>5732</td></tr><tr><td>val_loss</td><td>1.36093</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">online_sleep_staging_model</strong> at: <a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification/runs/bp9g4692' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification/runs/bp9g4692</a><br> View project at: <a href='https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/sleep_stage_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_161127-bp9g4692/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the combined model\n",
    "wandb_logger = WandbLogger(name=\"online_sleep_staging_model\", project=\"sleep_stage_classification\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback]\n",
    ")\n",
    "model = OnlineSleepStagingModel(in_channels=4, cnn_output_channels=16, lstm_hidden_size=64, num_layers=2, num_sleep_stages=5, learning_rate=1e-4)\n",
    "train_loader = DataLoader(train_chunk_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_chunk_dataset, batch_size=8, shuffle=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "wandb.finish()\n",
    "# Load the best model\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "best_model = OnlineSleepStagingModel.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b731ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 16:17:15,889] A new study created in memory with name: no-name-7ca2f822-327a-4fcb-857f-0c56425d76e2\n",
      "/tmp/ipykernel_2298590/1061032611.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250414_161715-lwkis1sx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification/runs/lwkis1sx' target=\"_blank\">CNN32_hs128_lr0.00023731732209598467</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification/runs/lwkis1sx' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/optuna_sleep_stage_classification/runs/lwkis1sx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractorCNN | 37.8 K | train\n",
      "1 | lstm_model        | SleepStageLSTM      | 215 K  | train\n",
      "2 | criterion         | CrossEntropyLoss    | 0      | train\n",
      "------------------------------------------------------------------\n",
      "253 K     Trainable params\n",
      "0         Non-trainable params\n",
      "253 K     Total params\n",
      "1.014     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.002957582473754883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c3b00c5d347818c8db107802a9458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0030586719512939453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3108117253b84718a603c49b01055cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003304719924926758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9083a388a8046c8918bc803859ff1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003139972686767578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0303d849849943ba8068cec5e77d690e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.003151416778564453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fc94a3b79540e79ee0d0ca7fa6dff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0032014846801757812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ff71a7c22948f6848a57574a2efc6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128])\n",
    "    num_layers = 2\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "\n",
    "    wandb_logger = WandbLogger(name=f\"CNN{cnn_output_channels}_hs{lstm_hidden_size}_lr{learning_rate}\", project=\"optuna_sleep_stage_classification\")\n",
    "    # DataLoaders (resample based on batch size)\n",
    "    train_loader = DataLoader(train_chunk_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_chunk_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # Model\n",
    "    model = OnlineSleepStagingModel(\n",
    "        in_channels=4,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        num_sleep_stages=5,\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "\n",
    "    # Trainer with pruning callback\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        devices=1,\n",
    "        accelerator=\"gpu\",\n",
    "        logger=wandb_logger,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project overview\n",
    "# construct dataset class\n",
    "# - train CNN -> LSTM sleep staging model with causal conv and unidirectional LSTM\n",
    "# - train CNN -> LSTM sleep staging model with non-causal conv and bidirectional LSTM\n",
    "# - compare performance at 64Hz\n",
    "# - compare performance and computational cost at lower sampling rates\n",
    "\n",
    "# unstructured notes\n",
    "# - likely best to combine ACC columns into a single variable. Can't imagine they offer much additional information\n",
    "# - CNN model should use 2D CNNs to extract features across both channels and short-term time windows\n",
    "# - will need to pad data on both sides to ensure input and output sequences for the CNN are the same length\n",
    "\n",
    "\n",
    "# CNN model - input: seq_len x num_channels -> output: seq_len x hidden_size\n",
    "\n",
    "\n",
    "# LSTM model - input: seq_len x hidden_size -> output: seq_len x num_classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc4f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data into train val and test by subject\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subject_ids = participant_info_df['subject_id'].unique()\n",
    "train_subjects = subject_ids[:int(len(subject_ids)*0.8)]\n",
    "val_subjects = subject_ids[int(len(subject_ids)*0.8):int(len(subject_ids)*0.9)]\n",
    "test_subjects = subject_ids[int(len(subject_ids)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(demo_df.columns)\n",
    "print(demo_df['Sleep_Stage'].unique())\n",
    "print(demo_df['TIMESTAMP'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680457e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "sleep_stage_labels = le.fit_transform(demo_df['Sleep_Stage'])\n",
    "plt.plot(sleep_stage_labels)\n",
    "plt.title('Sleep Stage Labels')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sleep Stage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cols_X = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP']\n",
    "cols_Y = ['Sleep_Stage']\n",
    "\n",
    "class DreamtDataset(Dataset):\n",
    "    def __init__(self, data_dir, subject_ids, cols_X, cols_Y):\n",
    "        self.data_dir = data_dir\n",
    "        self.subject_ids = subject_ids\n",
    "        self.cols_X = cols_X\n",
    "        self.cols_Y = cols_Y\n",
    "        self.data = []\n",
    "        for subject_id in subject_ids:\n",
    "            df = pd.read_csv(data_dir + f'S{subject_id:03d}_whole_df.csv')\n",
    "            df = df[cols_X + cols_Y]\n",
    "            df['subject_id'] = subject_id\n",
    "            self.data.append(df)\n",
    "        self.data = pd.concat(self.data, ignore_index=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        X = torch.tensor(row[self.cols_X].values, dtype=torch.float32)\n",
    "        y = torch.tensor(row[self.cols_Y].values, dtype=torch.long)\n",
    "        return X, y\n",
    "\n",
    "# CNN model with 4 2D conv layers, relu activation, dropout of 0.2, and 2 fully connected layers, first one has size 4096, second with 1500, both fc layers have dropout of 0.5\n",
    "# last fc layer has output size of 5, the number of channels to feed into the LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input shape: (batch_size, 1, num_channels, time_window)\n",
    "# Example: 6 EEG channels, 128-sample time windows → (batch, 1, 6, 128)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sliding_windows(x, window_size, stride=1):\n",
    "    # x: (batch, channels, time)\n",
    "    batch, channels, total_len = x.shape\n",
    "\n",
    "    # Pad on both sides: same number of windows as original time length\n",
    "    pad = (window_size - 1) // 2\n",
    "    x_padded = F.pad(x, pad=(pad, pad), mode='replicate')\n",
    "\n",
    "    # Now generate sliding windows\n",
    "    windows = x_padded.unfold(dimension=2, size=window_size, step=stride)  # (batch, channels, time, window_size)\n",
    "    windows = windows.permute(0, 2, 1, 3)  # (batch, time, channels, window_size)\n",
    "    return windows  # shape: (batch, time, channels, window_size)\n",
    "\n",
    "\n",
    "\n",
    "class DreamtCNN(nn.Module):\n",
    "    def __init__(self, input_shape, num_chans_out):\n",
    "        super(DreamtCNN, self).__init__()\n",
    "        c, t = input_shape  # c = number of channels (e.g. 6), t = time_window size (e.g. 128)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 5), stride=1, padding=(1, 2))\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 5), stride=1, padding=(1, 2))\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 5), stride=1, padding=(1, 2))\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3, 5), stride=1, padding=(1, 2))\n",
    "\n",
    "        self.conv_dropout = nn.Dropout(0.2)\n",
    "        self.ff_dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Output dims after conv layers will be (batch, 256, c, t)\n",
    "        self.fc1 = nn.Linear(256 * c * t, 4096)\n",
    "        self.fc2 = nn.Linear(4096, num_chans_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 1, channels, time_window)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv_dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv_dropout(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.conv_dropout(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.conv_dropout(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.ff_dropout(x)\n",
    "        x = self.fc2(x)  # output shape: (batch_size, num_chans_out)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define test parameters\n",
    "batch_size = 4\n",
    "num_channels = 6\n",
    "time_window = 128\n",
    "seq_len = 1000  # e.g., length of the sequence to be fed into the LSTM\n",
    "num_chans_out = 5  # e.g., number of channels to feed into the LSTM\n",
    "\n",
    "# create dummy imput \n",
    "x = torch.randn(batch_size, 1, num_channels, time_window)  # (batch_size, 1, num_channels, time_window)\n",
    "\n",
    "# window input\n",
    "x = x.squeeze(1)  # (batch_size, num_channels, time_window)\n",
    "x = sliding_windows(x, window_size=time_window, stride=1)\n",
    "\n",
    "print(f\"Shape after sliding windows: {x.shape}\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = DreamtCNN(input_shape=(num_channels, time_window), num_chans_out=num_chans_out)\n",
    "\n",
    "# Forward pass\n",
    "# x shape: (batch, time, channels, window)\n",
    "x = x.unsqueeze(2)  # -> (batch, time, 1, channels, window)\n",
    "\n",
    "# Reshape for CNN: merge batch and time into one dim\n",
    "b, t, one, c, w = x.shape\n",
    "x = x.view(b * t, 1, c, w)  # (b * t, 1, channels, window)\n",
    "\n",
    "# Feed into CNN\n",
    "out = model(x)  # shape: (b * t, output_dim)\n",
    "\n",
    "# Restore sequence shape\n",
    "out = out.view(b, t, -1)  # (batch, time, output_dim)\n",
    "\n",
    "\n",
    "# Print shape\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
