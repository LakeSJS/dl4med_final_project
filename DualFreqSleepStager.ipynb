{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1306768",
   "metadata": {},
   "source": [
    "# Title and overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94600e31",
   "metadata": {},
   "source": [
    "# Imports and Defintions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59be11",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf64d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import MulticlassCohenKappa\n",
    "from IPython.display import clear_output\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, roc_auc_score\n",
    "from collections import Counter\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger\n",
    "import wandb\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8184e68",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada5da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_float(x): # Helper to safely convert strings to floats\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def forward_fill(x: torch.Tensor): # Forward‑fill NaNs in each channel\n",
    "    single = False\n",
    "    if x.dim() == 1:\n",
    "        x = x.unsqueeze(1)\n",
    "        single = True\n",
    "    T, C = x.shape\n",
    "    for c in range(C):\n",
    "        if torch.isnan(x[0, c]):\n",
    "            x[0, c] = 0.0\n",
    "        for t in range(1, T):\n",
    "            if torch.isnan(x[t, c]):\n",
    "                x[t, c] = x[t - 1, c]\n",
    "    return x.squeeze(1) if single else x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26f35c3",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58038a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 subjects_list,\n",
    "                 data_dir,\n",
    "                 chunk_duration: float = 600,\n",
    "                 chunk_stride: float = 300,\n",
    "                 high_freq: int = 32,\n",
    "                 low_freq: int = 8,\n",
    "                 hf_features: list = None,\n",
    "                 lf_features: list = None,\n",
    "                 debug: bool = False):\n",
    "        self.hf_downsample = int(64 // high_freq) # downsample factor for high frequency data\n",
    "        self.lf_downsample = int(64 // low_freq) # downsample factor for low frequency data\n",
    "\n",
    "        SLEEP_STAGE_MAPPING = {\n",
    "            \"W\": 0,    # Wake\n",
    "            \"N1\": 1,   # non-REM stage 1 (light sleep_)\n",
    "            \"N2\": 1,   # non-REM stage 2 (light sleep)\n",
    "            \"N3\": 2,   # non-REM stage 3 (deep sleep)\n",
    "            \"R\": 3,    # REM\n",
    "            \"Missing\": -1  # Missing label → ignore\n",
    "        }\n",
    "        numeric_columns = ['TIMESTAMP', 'BVP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'TEMP', 'EDA', 'HR', 'IBI']\n",
    "        converters = {col: safe_float for col in numeric_columns}\n",
    "\n",
    "        self.chunks = []\n",
    "        for SID in subjects_list:\n",
    "            path = os.path.join(data_dir, f\"{SID}_whole_df.csv\")\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"File {path} does not exist.\")\n",
    "            # Load data for subject\n",
    "            df = pd.read_csv(path,\n",
    "                             dtype={'Sleep_Stage': 'category'},\n",
    "                             converters=converters,\n",
    "                             low_memory=True)\n",
    "            \n",
    "            # drop preparation phase, map labels\n",
    "            df = df[df['Sleep_Stage'] != 'P']\n",
    "            df['Sleep_Stage'] = df['Sleep_Stage'].astype(str).str.strip()\n",
    "            labels_arr = (\n",
    "                df['Sleep_Stage']\n",
    "                  .map(SLEEP_STAGE_MAPPING)\n",
    "                  .fillna(-1)\n",
    "                  .astype(int)\n",
    "                  .to_numpy()\n",
    "            )\n",
    "            # combine ACC_X, ACC_Y, ACC_Z into a single feature\n",
    "            df['ACC'] = np.sqrt(df['ACC_X']**2 + df['ACC_Y']**2 + df['ACC_Z']**2)\n",
    "            # separate high and low frequency data\n",
    "            df_high = df[hf_features].copy()\n",
    "            df_low = df[lf_features].copy()\n",
    "            # downsample data and labels\n",
    "            df_high = df_high.iloc[::self.hf_downsample, :].reset_index(drop=True)\n",
    "            df_low = df_low.iloc[::self.lf_downsample, :].reset_index(drop=True)\n",
    "            labels_arr = labels_arr[::self.lf_downsample]\n",
    "            # normalize data\n",
    "            df_high = (df_high - df_high.mean()) / (df_high.std().replace(0, 1e-6))\n",
    "            df_low = (df_low - df_low.mean()) / (df_low.std().replace(0, 1e-6))\n",
    "            # create chunks\n",
    "            total_time = int(len(df_high) / high_freq)\n",
    "            n_chunks = int((total_time - chunk_duration) // chunk_stride) + 1\n",
    "            for i in range(n_chunks):\n",
    "                start_time = i * chunk_stride\n",
    "                end_time = start_time + chunk_duration\n",
    "                \n",
    "                start_low = int(start_time * low_freq)\n",
    "                end_low = int(end_time * low_freq)\n",
    "                start_high = int(start_time * high_freq)\n",
    "                end_high = int(end_time * high_freq)\n",
    "\n",
    "                lf_chunk = df_low .iloc[start_low: end_low ].values.astype(np.float32)\n",
    "                hf_chunk = df_high.iloc[start_high:end_high].values.astype(np.float32)\n",
    "                labels_chunk = labels_arr[start_low: end_low]\n",
    "\n",
    "                lf_chunk = forward_fill(torch.tensor(lf_chunk, dtype=torch.float32))\n",
    "                hf_chunk = forward_fill(torch.tensor(hf_chunk, dtype=torch.float32))\n",
    "                labels_chunk = torch.tensor(labels_chunk, dtype=torch.long)\n",
    "                \n",
    "                if (labels_chunk != -1).any():\n",
    "                    self.chunks.append({\n",
    "                        'high': hf_chunk,\n",
    "                        'low': lf_chunk,\n",
    "                        'labels': labels_chunk,\n",
    "                    })\n",
    "        if debug:\n",
    "            print(f\"Loaded {len(self.chunks)} chunks from {len(subjects_list)} subjects.\")\n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.chunks[idx]\n",
    "        hf = chunk['high']\n",
    "        lf = chunk['low']\n",
    "        labels = chunk['labels']\n",
    "        return hf, lf, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d09d",
   "metadata": {},
   "source": [
    "## Optuna objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f1d69",
   "metadata": {},
   "source": [
    "### LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f037c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"lstm_num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7992759c",
   "metadata": {},
   "source": [
    "### TCN Only Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0912214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "    num_tcn_blocks = trial.suggest_int(\"num_tcn_blocks\", 3, 8)\n",
    "    tcn_kernel_size = trial.suggest_categorical(\"tcn_kernel_size\", [3, 5, 7])\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/TCN/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e844a",
   "metadata": {},
   "source": [
    "### TCN-LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d1a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"lstm_num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "    num_tcn_blocks = trial.suggest_int(\"num_tcn_blocks\", 3, 8)\n",
    "    tcn_kernel_size = trial.suggest_categorical(\"tcn_kernel_size\", [3, 5, 7])\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/TCN-LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e25929",
   "metadata": {},
   "source": [
    "### CNN-LSTM Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e4c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm_objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    hf_input_channels = len(hf_features)\n",
    "    lf_input_channels = len(lf_features)\n",
    "    cnn_output_channels = trial.suggest_categorical(\"cnn_output_channels\", [8, 16, 32, 64, 128])\n",
    "    lstm_hidden_size = trial.suggest_categorical(\"lstm_hidden_size\", [32, 64, 128, 256])\n",
    "    lstm_num_layers = trial.suggest_categorical(\"num_layers\",[2,4,6])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    num_sleep_stages = 4\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
    "    label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.3)\n",
    "\n",
    "    # create the logger and callbacks\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-LSTM-Sleep-Stager\",\n",
    "        name=f\"optuna-{trial.number}\",\n",
    "        log_model=True,\n",
    "        save_dir=\"wandb_logs\"\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/CNN-LSTM/Optuna',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    "    )\n",
    "    # Create the model\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=hf_input_channels,\n",
    "        lf_input_channels=lf_input_channels,\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=num_sleep_stages,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    precision=\"16-mixed\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # return best val loss\n",
    "    best_val_loss = checkpoint_callback.best_model_score.item()\n",
    "    \n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cea6ec",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12f4d2",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=2,\n",
    "                 lf_input_channels=5,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size= hf_input_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        hf_output_length = hf.shape[1]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf length {hf_output_length} > lf length {lf_output_length}, downsampling\")\n",
    "        hf = F.interpolate(\n",
    "                hf.permute(0, 2, 1), # (batch_size, hf_input_channels, sequence_length)\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        hf = hf.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = hf.permute(1,0,2) # (sequence_length, batch_size, hf_input_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029235b",
   "metadata": {},
   "source": [
    "### TCN\n",
    "As defined in Bai et al https://arxiv.org/pdf/1803.01271, TCN blocks are residual blocks, each containing two dilated convolutions with relu activation and batch normalization. Subsequent blocks have increasing dilations, allowing for the capture of patterns at increasing timescales. Often these are causally padded but for our use case, we decided to forego this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b9ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels, output_channels, kernel_size, dilation, stride=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        padding = (kernel_size - 1) * dilation // 2 # preserve sequence length\n",
    "        self.conv1 = nn.Conv1d(input_channels, output_channels, kernel_size,\n",
    "                               stride=stride, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm1d(output_channels)\n",
    "        self.conv2 = nn.Conv1d(output_channels, output_channels, kernel_size,\n",
    "                               stride=1, padding=padding,\n",
    "                               dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm1d(output_channels)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.dropout  = nn.Dropout(dropout)\n",
    "        # 1×1 conv to match channels/stride if needed\n",
    "        self.downsample = (nn.Conv1d(input_channels, output_channels, 1, stride=stride)\n",
    "                           if (stride!=1 or input_channels!=output_channels) else None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x arrives as (batch, channels, seq_len)\n",
    "        identity = x                     # save the original for the skip path\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)          \n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.dropout(out)\n",
    "        # downsampled if needed\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        # add & activate\n",
    "        return self.relu(out + identity)\n",
    "\n",
    "class HFFeatureExtractorTCN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_blocks=5,\n",
    "                 kernel_size=3,\n",
    "                 base_channels=16,\n",
    "                 final_down=64,     # match CNN’s total downsample factor (~64)\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        ch = in_channels\n",
    "        # build dilated residual blocks (no downsampling here)\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(\n",
    "                TemporalBlock(ch, base_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              dilation=2**i,\n",
    "                              stride=1,\n",
    "                              dropout=dropout)\n",
    "            )\n",
    "            ch = base_channels\n",
    "        # final 1×1 conv with stride=final_down to downsample by 64\n",
    "        layers.append(nn.Conv1d(ch, out_channels,\n",
    "                                kernel_size=1,\n",
    "                                stride=final_down,\n",
    "                                padding=0))\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, in_channels)\n",
    "        x = x.permute(0,2,1)  # to (batch, channels, seq_len)\n",
    "        y = self.tcn(x)       # returns (batch, out_channels, seq_len/64)\n",
    "        return y             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1eb51",
   "metadata": {},
   "source": [
    "### CNN\n",
    "As laid out in DeepActiNet paper - using a 1d CNN to extract features from acceleration and in this case BVP as well, this is done with a series of convolutions with very large kernels and no padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd029142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self,\n",
    "     input_channels,\n",
    "     output_channels,\n",
    "     dropout=0.1):\n",
    "        super(HFFeatureExtractorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=output_channels, kernel_size=512, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=256, stride=2)\n",
    "        self.conv4 = nn.Conv1d(in_channels=output_channels, out_channels=output_channels, kernel_size=32, stride=2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(output_channels)\n",
    "        self.bn4 = nn.BatchNorm1d(output_channels)\n",
    "\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert not torch.isnan(x).any(), \"NaN detected in CNN input\"\n",
    "        # Expect x of shape (batch, epoch_samples, channels)\n",
    "        x = x.permute(0, 2, 1)  # (batch, channels (1), epoch_samples)\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff37f4",
   "metadata": {},
   "source": [
    "### Convolution Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31019482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 num_tcn_blocks=5,\n",
    "                 tcn_kernel_size=3,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels + lf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels + lf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=num_tcn_blocks,\n",
    "                                            kernel_size=tcn_kernel_size,\n",
    "                                            base_channels=cnn_output_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "        self.classifier = nn.Linear(cnn_output_channels, num_sleep_stages)\n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # upsample shorter sequence\n",
    "        hf_output_length = hf.shape[1]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf output length {hf_output_length} < lf output length {lf_output_length}, upsampling\")\n",
    "        lf = F.interpolate(\n",
    "                lf.permute(0, 2, 1), # (batch_size, hf_input_channels, sequence_length)\n",
    "                size=hf_output_length,\n",
    "            )\n",
    "        hf = hf.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        x = torch.cat((hf, lf), dim=1)\n",
    "        x = x.permute(0, 2, 1) # (batch_size, sequence_length, hf_input_channels + lf_input_channels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] conv input shape: {x.shape}\")\n",
    "\n",
    "        # pass through cnn\n",
    "        x = self.cnn(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] conv output shape: {x.shape}\")\n",
    "\n",
    "        # downsample to match original sequence length\n",
    "        x = F.interpolate(\n",
    "            x,\n",
    "            size=lf_output_length,\n",
    "        )\n",
    "\n",
    "        # pass through classifier\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = x.permute(1, 0, 2) # (batch_size, num_classes, sequence_length)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b678a",
   "metadata": {},
   "source": [
    "### Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70393b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualFreqSleepStager(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 hf_input_channels=5,\n",
    "                 lf_input_channels=5,\n",
    "                 cnn_output_channels=16,\n",
    "                 lstm_hidden_size=64,\n",
    "                 lstm_num_layers=2,\n",
    "                 lstm_bidirectional=True,\n",
    "                 dropout=0.1,\n",
    "                 num_sleep_stages=5,\n",
    "                 learning_rate=1e-3,\n",
    "                 weight_decay=1e-5,\n",
    "                 label_smoothing=0.0,\n",
    "                 weight_tensor=None,\n",
    "                 convnet='CNN',\n",
    "                 num_tcn_blocks=5,\n",
    "                 tcn_kernel_size=3,\n",
    "                 debug=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if convnet == 'CNN':\n",
    "            self.cnn = HFFeatureExtractorCNN(input_channels=hf_input_channels,\n",
    "                                        output_channels=cnn_output_channels,\n",
    "                                        dropout=dropout)\n",
    "        elif convnet == 'TCN':\n",
    "            self.cnn = HFFeatureExtractorTCN(in_channels=hf_input_channels,\n",
    "                                            out_channels=cnn_output_channels,\n",
    "                                            num_blocks=num_tcn_blocks,\n",
    "                                            kernel_size=tcn_kernel_size,\n",
    "                                            base_channels=cnn_output_channels,\n",
    "                                            final_down=64,     # match CNN’s total downsample factor\n",
    "                                            dropout=dropout)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown convnet type: {convnet}\")\n",
    "        self.lstm = nn.LSTM(\n",
    "                            input_size=cnn_output_channels + lf_input_channels,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        if lstm_bidirectional:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size * 2, num_sleep_stages, )\n",
    "        else:\n",
    "            self.classifier = nn.Linear(lstm_hidden_size, num_sleep_stages)\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.kappa = MulticlassCohenKappa(num_classes=num_sleep_stages)\n",
    "        self.debug = debug\n",
    "        \n",
    "\n",
    "        if weight_tensor is not None:\n",
    "            assert weight_tensor.shape[0] == num_sleep_stages, \\\n",
    "                f\"Weight tensor shape {weight_tensor.shape[0]} does not match number of sleep stages {num_sleep_stages}\"\n",
    "        self.train_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1,label_smoothing=label_smoothing)\n",
    "        self.val_criterion = nn.CrossEntropyLoss(weight=weight_tensor, ignore_index=-1)\n",
    "\n",
    "    def forward(self, hf, lf):\n",
    "        # assert no nan values in input\n",
    "        assert not torch.isnan(hf).any(), \"NaN detected in CNN input\"\n",
    "        assert not torch.isnan(lf).any(), \"NaN detected in LSTM input\"\n",
    "        if self.debug:\n",
    "            print(f\"HF input shape: {hf.shape}\")\n",
    "            print(f\"LF input shape: {lf.shape}\")\n",
    "        \n",
    "        # pass high frequency data through CNN    \n",
    "        cnn_features = self.cnn(hf)\n",
    "        if self.debug:\n",
    "            print(f\"cnn output shape: {cnn_features.shape}\")\n",
    "\n",
    "        # downsample longer sequence\n",
    "        cnn_output_length = cnn_features.shape[2]\n",
    "        lf_output_length = lf.shape[1]\n",
    "        if cnn_output_length > lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} > lf output length {lf_output_length}, downsampling\")\n",
    "            cnn_features = F.interpolate(\n",
    "                cnn_features,\n",
    "                size=lf_output_length,\n",
    "            )\n",
    "        elif cnn_output_length < lf_output_length:\n",
    "            if self.debug:\n",
    "                print(f\"[DEBUG] cnn output length {cnn_output_length} < lf output length {lf_output_length}, downsampling\")\n",
    "            lf = F.interpolate(\n",
    "                lf,\n",
    "                size=cnn_output_length,\n",
    "            )\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] hf features shape: {cnn_features.shape}\")\n",
    "            print(f\"[DEBUG] lf features shape: {lf.shape}\")\n",
    "        \n",
    "        # concatenate high and low frequency features\n",
    "        a = cnn_features.permute(2,0,1) # (sequence_length, batch_size, cnn_output_channels)\n",
    "        b = lf.permute(1,0,2) # (sequence_length, batch_size, lf_input_channels)\n",
    "        x = torch.cat((a, b), dim=2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm input shape: {x.shape}\")\n",
    "        \n",
    "        # pass through LSTM + classifier\n",
    "        x, _ = self.lstm(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] lstm output shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] classifier output shape: {x.shape}\")\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] training step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "        \n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2) # should be (batch_size, seq_len, num_classes)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = self.train_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] loss: {loss.item()}\")\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        hf, lf, labels = batch\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation step batch {batch_idx}\")\n",
    "            print(f\"[DEBUG] hf shape: {hf.shape}\")\n",
    "            print(f\"[DEBUG] lf shape: {lf.shape}\")\n",
    "            print(f\"[DEBUG] labels shape: {labels.shape}\")\n",
    "\n",
    "        logits = self(hf, lf)\n",
    "        logits = logits.permute(1, 0, 2)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits shape after permute: {logits.shape}\")\n",
    "        # flatten\n",
    "        batch_size, seq_len, num_classes = logits.shape\n",
    "        logits_flat = logits.reshape(batch_size * seq_len, num_classes)\n",
    "        labels_flat = labels.reshape(batch_size * seq_len)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] logits_flat shape: {logits_flat.shape}\")\n",
    "            print(f\"[DEBUG] labels_flat shape: {labels_flat.shape}\")\n",
    "        # calculate loss\n",
    "        loss = self.val_criterion(logits_flat, labels_flat)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation loss: {loss.item()}\")\n",
    "        # calculate accuracy\n",
    "        preds = torch.argmax(logits_flat, dim=1)\n",
    "        mask = labels_flat != -1\n",
    "        masked_preds = preds[mask]\n",
    "        masked_labels = labels_flat[mask]\n",
    "        if masked_labels.numel() > 0:\n",
    "            acc = (masked_preds == masked_labels).float().mean().item()\n",
    "        else:\n",
    "            acc = 0.0\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation accuracy: {acc}\")\n",
    "        # calculate kappa\n",
    "        kappa = self.kappa.update(masked_preds, masked_labels)\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] validation kappa: {kappa}\")\n",
    "\n",
    "        # log metrics\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "        return {\n",
    "            'val_loss': loss,\n",
    "            'val_acc': acc\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        kappa = self.kappa.compute()\n",
    "        self.log('val_cohen_kappa', torch.nan_to_num(kappa,0.0), prog_bar=True)\n",
    "        self.kappa.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        '''\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "                'interval': 'epoch',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ea401",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4676a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    # figure out where the model lives (cpu or cuda)\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    all_probs  = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for non_acc, acc, labels in dataloader:\n",
    "            # move inputs to model's device\n",
    "            non_acc = non_acc.to(device)\n",
    "            acc     = acc.to(device)\n",
    "\n",
    "            # forward\n",
    "            y_hat = model(non_acc, acc)           # (seq_len, batch, C)\n",
    "            y_hat = y_hat.permute(1, 0, 2)        # (batch, seq_len, C)\n",
    "            B, T, C = y_hat.shape\n",
    "\n",
    "            # flatten\n",
    "            logits = y_hat.reshape(B*T, C)\n",
    "            probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "            preds  = probs.argmax(axis=1)\n",
    "            labs   = labels.reshape(-1).numpy()\n",
    "\n",
    "            # filter out padding (-1)\n",
    "            mask = (labs != -1)\n",
    "            all_labels.extend(labs[mask])\n",
    "            all_preds.extend(preds[mask])\n",
    "            all_probs.append(probs[mask])\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    acc   = accuracy_score(all_labels, all_preds)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "    auroc = roc_auc_score(all_labels, all_probs, multi_class='ovo', average='macro')\n",
    "    cm    = confusion_matrix(all_labels, all_preds,normalize='true')\n",
    "    return acc, kappa, auroc, cm\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, classes: list[str]):\n",
    "    \"\"\"\n",
    "    cm:          square confusion matrix of counts or floats\n",
    "    classes:     list of class‐label strings, length == cm.shape[0]\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm)           # default colormap, channels-last format\n",
    "    fig.colorbar(im, ax=ax)      # add a colorbar\n",
    "\n",
    "    # Tick labels\n",
    "    ax.set_xticks(np.arange(len(classes)))\n",
    "    ax.set_yticks(np.arange(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    # Annotate each cell with its value\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f\"{val:.4f}\", ha='center', va='center')\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"True label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix_with_metrics(cm, class_mapping):\n",
    "    class_vals = [i for i in class_mapping.keys()]\n",
    "    class_names = [class_mapping[i] for i in range(len(class_vals))]\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100  # row-wise percentage (sensitivity)\n",
    "\n",
    "    # Calculate Sensitivity (Recall) and PPV (Precision)\n",
    "    sensitivity = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    ppv = np.diag(cm) / np.sum(cm, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=False, fmt='g', cmap='Blues', cbar=False, ax=ax)\n",
    "\n",
    "    # Labels inside the boxes\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            count = cm[i, j]\n",
    "            perc = cm_perc[i, j]\n",
    "            ax.text(j + 0.5, i + 0.3, f\"{count:.4f}\", \n",
    "                    ha='center', va='center', color='black', fontsize=10)\n",
    "            ax.text(j + 0.5, i + 0.7, f\"{perc:.0f}%\", \n",
    "                    ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "    # Set axis labels\n",
    "    ax.set_xlabel('Prediction', fontsize=12)\n",
    "    ax.set_ylabel('Reference', fontsize=12)\n",
    "\n",
    "    # Set ticks\n",
    "    ax.set_xticks(np.arange(len(class_vals)) + 0.5)\n",
    "    ax.set_yticks(np.arange(len(class_vals)) + 0.5)\n",
    "\n",
    "    ax.set_xticklabels(class_names, rotation=0, ha=\"center\")\n",
    "    ax.set_yticklabels(class_names, rotation=0)\n",
    "\n",
    "    # Plot PPV (precision) on top\n",
    "    for j, p in enumerate(ppv):\n",
    "        ax.text(j + 0.5, -0.2, f\"{int(p*100) if not np.isnan(p) else 0}%\", \n",
    "                ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Plot Sensitivity (recall) on right\n",
    "    for i, s in enumerate(sensitivity):\n",
    "        ax.text(len(class_names) + 0.1, i + 0.5, f\"{int(s*100) if not np.isnan(s) else 0}%\", \n",
    "                ha='left', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Center \"PPV\" label on top\n",
    "    ax.text(len(class_vals) / 2, -0.5, \"PPV\", fontsize=14, ha='center', va='center')\n",
    "\n",
    "    # Center \"Sensitivity\" label on the right\n",
    "    ax.text(len(class_vals) + 0.5, len(class_vals) / 2, \"Sensitivity\", fontsize=14, ha='center', va='center', rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5286811",
   "metadata": {},
   "source": [
    "# Dataset creation / loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7387c",
   "metadata": {},
   "source": [
    "### Separate subjects into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d632ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_64Hz = '/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/data_64Hz/' # working with 64Hz data\n",
    "max_length = 2493810 # found experimentally, takes a while to compute\n",
    "\n",
    "participant_info_df = pd.read_csv('/gpfs/data/oermannlab/users/slj9342/dl4med_25/data/physionet.org/files/dreamt/2.0.0/participant_info.csv')\n",
    "subjects_all = participant_info_df['SID']\n",
    "\n",
    "subjects_all_shuffled = participant_info_df['SID'].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "subjects_train = subjects_all_shuffled[:int(len(subjects_all_shuffled)*0.8)]\n",
    "subjects_val = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.8):int(len(subjects_all_shuffled)*0.9)]\n",
    "subjects_test = subjects_all_shuffled[int(len(subjects_all_shuffled)*0.9):]\n",
    "print(f\"number of subjects in train: {len(subjects_train)}\")\n",
    "print(f\"number of subjects in val: {len(subjects_val)}\")\n",
    "print(f\"number of subjects in test: {len(subjects_test)}\")\n",
    "\n",
    "fraction = 0.3\n",
    "subjects_train_small = subjects_train[:int(len(subjects_train)*fraction)]\n",
    "subjects_val_small = subjects_val[:int(len(subjects_val)*fraction)]\n",
    "subjects_test_small = subjects_test[:int(len(subjects_test)*fraction)]\n",
    "print(f\"number of subjects in small train: {len(subjects_train_small)}\")\n",
    "print(f\"number of subjects in small val: {len(subjects_val_small)}\")\n",
    "print(f\"number of subjects in small test: {len(subjects_test_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a9d4",
   "metadata": {},
   "source": [
    "### Construct train, val, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 6000s = 100 minutes\n",
    "chunk_stride = 3000 # 3000s = 50 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=subjects_train,\n",
    "                                data_dir=datadir_64Hz,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "print(f\"number of chunks in train: {len(train_dataset)}\")\n",
    "val_dataset = DualFreqDataset(subjects_list=subjects_val,\n",
    "                              data_dir=datadir_64Hz,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "print(f\"number of chunks in val: {len(val_dataset)}\")\n",
    "test_dataset = DualFreqDataset(subjects_list=subjects_test,\n",
    "                               data_dir=datadir_64Hz,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "print(f\"number of chunks in test: {len(test_dataset)}\")\n",
    "train_dataset_small = DualFreqDataset(subjects_list=subjects_train_small,\n",
    "                                       data_dir=datadir_64Hz,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "print(f\"number of chunks in small train: {len(train_dataset_small)}\")\n",
    "val_dataset_small = DualFreqDataset(subjects_list=subjects_val_small,\n",
    "                                     data_dir=datadir_64Hz,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "print(f\"number of chunks in small val: {len(val_dataset_small)}\")\n",
    "test_dataset_small = DualFreqDataset(subjects_list=subjects_test_small,\n",
    "                                      data_dir=datadir_64Hz,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "print(f\"number of chunks in small test: {len(test_dataset_small)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ec509",
   "metadata": {},
   "source": [
    "### Save Dataset Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceba77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset chunks\n",
    "torch.save(train_dataset.chunks, 'DualFreqDatasets/train_dataset_chunks.pt')\n",
    "torch.save(val_dataset.chunks, 'DualFreqDatasets/val_dataset_chunks.pt')\n",
    "torch.save(test_dataset.chunks, 'DualFreqDatasets/test_dataset_chunks.pt')\n",
    "torch.save(train_dataset_small.chunks, 'DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "torch.save(val_dataset_small.chunks, 'DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "torch.save(test_dataset_small.chunks, 'DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e4c60",
   "metadata": {},
   "source": [
    "### Load Saved Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f596d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved datasets\n",
    "hf_features = ['BVP','ACC']\n",
    "lf_features = ['TIMESTAMP','TEMP','EDA','HR','IBI']\n",
    "hf_freq = 32\n",
    "lf_freq = 0.2\n",
    "chunk_duration = 6000 # 10 minutes\n",
    "chunk_stride = 3000 # 2.5 minutes\n",
    "train_dataset = DualFreqDataset(subjects_list=[],\n",
    "                                data_dir=None,\n",
    "                                chunk_duration=chunk_duration,\n",
    "                                chunk_stride=chunk_stride,\n",
    "                                high_freq=hf_freq,\n",
    "                                low_freq=lf_freq,\n",
    "                                hf_features=hf_features,\n",
    "                                lf_features=lf_features)\n",
    "train_dataset.chunks = torch.load('DualFreqDatasets/train_dataset_chunks.pt')\n",
    "val_dataset = DualFreqDataset(subjects_list=[],\n",
    "                              data_dir=None,\n",
    "                              chunk_duration=chunk_duration,\n",
    "                              chunk_stride=chunk_stride,\n",
    "                              high_freq=hf_freq,\n",
    "                              low_freq=lf_freq,\n",
    "                              hf_features=hf_features,\n",
    "                              lf_features=lf_features)\n",
    "val_dataset.chunks = torch.load('DualFreqDatasets/val_dataset_chunks.pt')\n",
    "test_dataset = DualFreqDataset(subjects_list=[],\n",
    "                               data_dir=None,\n",
    "                               chunk_duration=chunk_duration,\n",
    "                               chunk_stride=chunk_stride,\n",
    "                               high_freq=hf_freq,\n",
    "                               low_freq=lf_freq,\n",
    "                               hf_features=hf_features,\n",
    "                               lf_features=lf_features)\n",
    "test_dataset.chunks = torch.load('DualFreqDatasets/test_dataset_chunks.pt')\n",
    "train_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                       data_dir=None,\n",
    "                                       chunk_duration=chunk_duration,\n",
    "                                       chunk_stride=chunk_stride,\n",
    "                                       high_freq=hf_freq,\n",
    "                                       low_freq=lf_freq,\n",
    "                                       hf_features=hf_features,\n",
    "                                       lf_features=lf_features)\n",
    "train_dataset_small.chunks = torch.load('DualFreqDatasets/train_dataset_small_chunks.pt')\n",
    "val_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                     data_dir=None,\n",
    "                                     chunk_duration=chunk_duration,\n",
    "                                     chunk_stride=chunk_stride,\n",
    "                                     high_freq=hf_freq,\n",
    "                                     low_freq=lf_freq,\n",
    "                                     hf_features=hf_features,\n",
    "                                     lf_features=lf_features)\n",
    "val_dataset_small.chunks = torch.load('DualFreqDatasets/val_dataset_small_chunks.pt')\n",
    "test_dataset_small = DualFreqDataset(subjects_list=[],\n",
    "                                      data_dir=None,\n",
    "                                      chunk_duration=chunk_duration,\n",
    "                                      chunk_stride=chunk_stride,\n",
    "                                      high_freq=hf_freq,\n",
    "                                      low_freq=lf_freq,\n",
    "                                      hf_features=hf_features,\n",
    "                                      lf_features=lf_features)\n",
    "test_dataset_small.chunks = torch.load('DualFreqDatasets/test_dataset_small_chunks.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149adfa",
   "metadata": {},
   "source": [
    "# Model Demos (shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e842ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 2])\n",
      "temp_lf shape: torch.Size([1200, 5])\n",
      "temp_labels shape: torch.Size([1200])\n"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "temp_hf = temp_hf.unsqueeze(0)\n",
    "temp_lf = temp_lf.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259a6ea",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e253126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] hf length 192000 > lf length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 1200, 2])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 7])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-5,\n",
    "    label_smoothing=0.0,\n",
    "    weight_tensor=None,\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee45c8",
   "metadata": {},
   "source": [
    "### TCN Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35798002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] hf output length 192000 < lf output length 1200, upsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 2, 192000])\n",
      "[DEBUG] lf features shape: torch.Size([1, 5, 192000])\n",
      "[DEBUG] conv input shape: torch.Size([1, 192000, 7])\n",
      "[DEBUG] conv output shape: torch.Size([1, 16, 3000])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = ConvSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a56e3",
   "metadata": {},
   "source": [
    "### CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e30d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_hf shape: torch.Size([192000, 2])\n",
      "temp_lf shape: torch.Size([1200, 5])\n",
      "temp_labels shape: torch.Size([1200])\n",
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 2929])\n",
      "[DEBUG] cnn output length 2929 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n",
      "output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "print(f\"temp_hf shape: {temp_hf.shape}\")\n",
    "print(f\"temp_lf shape: {temp_lf.shape}\")\n",
    "print(f\"temp_labels shape: {temp_labels.shape}\")\n",
    "temp_hf = temp_hf.unsqueeze(0)\n",
    "temp_lf = temp_lf.unsqueeze(0)\n",
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='CNN',\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)\n",
    "print(f\"output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fbdfa",
   "metadata": {},
   "source": [
    "### TCN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f783493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF input shape: torch.Size([1, 192000, 2])\n",
      "LF input shape: torch.Size([1, 1200, 5])\n",
      "cnn output shape: torch.Size([1, 16, 3000])\n",
      "[DEBUG] cnn output length 3000 > lf output length 1200, downsampling\n",
      "[DEBUG] hf features shape: torch.Size([1, 16, 1200])\n",
      "[DEBUG] lf features shape: torch.Size([1, 1200, 5])\n",
      "[DEBUG] lstm input shape: torch.Size([1200, 1, 21])\n",
      "[DEBUG] lstm output shape: torch.Size([1200, 1, 128])\n",
      "[DEBUG] classifier output shape: torch.Size([1200, 1, 4])\n",
      "output shape: torch.Size([1200, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "model = DualFreqSleepStager(\n",
    "    hf_input_channels=len(hf_features),\n",
    "    lf_input_channels=len(lf_features),\n",
    "    cnn_output_channels=16,\n",
    "    lstm_hidden_size=64,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_bidirectional=True,\n",
    "    dropout=0.1,\n",
    "    num_sleep_stages=4,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=5e-5,\n",
    "    weight_tensor=None,\n",
    "    convnet='TCN',\n",
    "    num_tcn_blocks=5,\n",
    "    tcn_kernel_size=3,\n",
    "    debug=True\n",
    ")\n",
    "output = model(temp_hf, temp_lf)\n",
    "print(f\"output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4c12b",
   "metadata": {},
   "source": [
    "# Get Class Weights\n",
    "We use these for weighted loss, this is to deal with the natural class imbalance in sleep staging data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f80a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: Counter({np.int64(1): 418966, np.int64(0): 144616, np.int64(3): 71508, np.int64(2): 24188})\n",
      "Class weights: [1.13970446 0.39339588 6.81410203 2.30490994]\n"
     ]
    }
   ],
   "source": [
    "# get class weights for weighted loss\n",
    "all_labels = []\n",
    "for batch in DataLoader(train_dataset, batch_size=1):\n",
    "    labels = batch[2].numpy()\n",
    "    all_labels.extend(labels.flatten())\n",
    "all_labels = np.array(all_labels)\n",
    "valid_labels = all_labels[all_labels != -1]\n",
    "classes = np.arange(4)\n",
    "class_counts = Counter(valid_labels)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=valid_labels\n",
    ")\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "print(f\"Class weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24370f",
   "metadata": {},
   "source": [
    "# LSTM Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96fb26",
   "metadata": {},
   "source": [
    "## LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8198b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 21:09:13,630] Trial 0 finished with value: 1.204933762550354 and parameters: {'lstm_hidden_size': 128, 'lstm_num_layers': 2, 'dropout': 0.3612554541294819, 'learning_rate': 0.005032721927277291, 'weight_decay': 0.00014932062185434237, 'label_smoothing': 0.25156837321011644}. Best is trial 0 with value: 1.204933762550354.\n",
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4m ...\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20250429_210913-c44xcc23</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager/runs/c44xcc23' target=\"_blank\">optuna-1</a></strong> to <a href='https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager/runs/c44xcc23' target=\"_blank\">https://wandb.ai/lakej98-nyu-langone-health/LSTM-Sleep-Stager/runs/c44xcc23</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/data/oermannlab/users/slj9342/.conda/envs/dl4med_25/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /gpfs/data/oermannlab/users/slj9342/dl4med_final_project/checkpoints/LSTM/Optuna exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                 | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | lstm            | LSTM                 | 5.3 M  | train\n",
      "1 | classifier      | Linear               | 2.1 K  | train\n",
      "2 | kappa           | MulticlassCohenKappa | 0      | train\n",
      "3 | train_criterion | CrossEntropyLoss     | 0      | train\n",
      "4 | val_criterion   | CrossEntropyLoss     | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "5.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 M     Total params\n",
      "21.103    Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0029854774475097656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e43f1f2ce724aee948029c89d20e823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0028002262115478516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4dec778f84dc88cb03f429ce76415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.0031423568725585938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8e0060c0d045d1b61f4e6df9dab9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.328\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "colour": null,
       "elapsed": 0.00284576416015625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db69a5d14c64635a75e23e42d8a5825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.082 >= min_delta = 0.0. New best score: 1.246\n"
     ]
    }
   ],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lstm_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb74de4",
   "metadata": {},
   "source": [
    "## Train LSTM only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38022d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lstm_hidden_size = best_trial.params['lstm_hidden_size']\n",
    "lstm_num_layers = best_trial.params['lstm_num_layers']\n",
    "dropout = best_trial.params['dropout']\n",
    "learning_rate = best_trial.params['learning_rate']\n",
    "weight_decay = best_trial.params['weight_decay']\n",
    "label_smoothing = best_trial.params['label_smoothing']\n",
    "'''\n",
    "\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "dropout = 0.21312\n",
    "learning_rate = 0.0048844\n",
    "weight_decay = 0.0000078942\n",
    "label_smoothing = 0.0050416\n",
    "\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"LSTM-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/LSTM/',\n",
    "        filename=f'best-checkpoint-{runNo}',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = LSTMSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/LSTM/best_model_{runNo}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7637985",
   "metadata": {},
   "source": [
    "## Test LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce329211",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/LSTM/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "tcn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f5f67",
   "metadata": {},
   "source": [
    "# TCN Only Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ef141",
   "metadata": {},
   "source": [
    "## TCN Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce91a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 19:35:13,826] Trial 9 finished with value: 1.3281011581420898 and parameters: {'cnn_output_channels': 64, 'dropout': 0.39093657853294717, 'learning_rate': 0.00014063803154936257, 'weight_decay': 0.005690753997949817, 'label_smoothing': 0.25489474815383373, 'num_tcn_blocks': 7, 'tcn_kernel_size': 5}. Best is trial 3 with value: 1.191741704940796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 3\n",
      "Best trial value: 1.191741704940796\n",
      "Best trial params: {'cnn_output_channels': 32, 'dropout': 0.39934985869584716, 'learning_rate': 0.005493328811147731, 'weight_decay': 1.531009368432114e-05, 'label_smoothing': 0.13565532337133754, 'num_tcn_blocks': 8, 'tcn_kernel_size': 5}\n"
     ]
    }
   ],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(tcn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbab3a",
   "metadata": {},
   "source": [
    "## Train TCN Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "051f29bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "\n",
    "num_runs = 2\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/TCN/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = ConvSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/TCN/best_model_{runNo}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3ef7f",
   "metadata": {},
   "source": [
    "## Test TCN Only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75ac8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUROC: 0.6088 +/- 0.0083\n",
      "Test Accuracy: 0.3758 +/- 0.0247\n",
      "Test Kappa: 0.1357 +/- 0.0122\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_runs = 2\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = ConvSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/TCN/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572e156b",
   "metadata": {},
   "source": [
    "# TCN-LSTM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c533efb",
   "metadata": {},
   "source": [
    "## TCN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(tcn_lstm_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f98ed",
   "metadata": {},
   "source": [
    "## Train TCN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"TCN-LSTM-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint( # selected model hyperparams by best val loss, now selecting by best val kappa\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/TCN-LSTM/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/TCN-LSTM/best_model_{runNo}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f8f52",
   "metadata": {},
   "source": [
    "## Test TCN-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa34158",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/TCN-LSTM/best_model_{runNo}.pth'))\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "# print results\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "tcn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ee87e",
   "metadata": {},
   "source": [
    "# CNN-LSTM Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a786f0",
   "metadata": {},
   "source": [
    "## CNN-LSTM Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_optuna_trials = 100 # not enough to cover every combination, but should be enough to find a good one\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(cnn_objective, n_trials=num_optuna_trials)\n",
    "best_trial = study.best_trial\n",
    "clear_output()\n",
    "print(f\"Best trial: {best_trial.number}\")\n",
    "print(f\"Best trial value: {best_trial.value}\")\n",
    "print(f\"Best trial params: {best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ebffe",
   "metadata": {},
   "source": [
    "## Train and Test CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97e0bb",
   "metadata": {},
   "source": [
    "### Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cnn_output_channels = best_trial.params['cnn_output_channels']\n",
    "lstm_hidden_size = best_trial.params['lstm_hidden_size']\n",
    "num_layers = best_trial.params['num_layers']\n",
    "dropout = best_trial.params['dropout']\n",
    "learning_rate = best_trial.params['learning_rate']\n",
    "weight_decay = best_trial.params['weight_decay']\n",
    "label_smoothing = best_trial.params['label_smoothing']\n",
    "'''\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "num_runs = 10\n",
    "max_epochs = 50\n",
    "for runNo in range(num_runs):\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"CNN-LSTM-Dual-Freq-Sleep-Stager\",\n",
    "        name=f\"best-params-{runNo}\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_cohen_kappa',\n",
    "        dirpath='checkpoints/CNN-LSTM/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_cohen_kappa',\n",
    "        patience=10,\n",
    "        verbose=True,\n",
    "        mode='max'\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=wandb_logger,\n",
    "        log_every_n_steps=1,\n",
    "        precision=\"16-mixed\",\n",
    "        #callbacks=[checkpoint_callback, early_stop_callback]\n",
    "        callbacks=[checkpoint_callback] # not using early stopping for now\n",
    "    )\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    wandb.finish()\n",
    "    clear_output()\n",
    "    # load best model\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    best_model = DualFreqSleepStager.load_from_checkpoint(best_model_path)\n",
    "\n",
    "    # test the model\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(best_model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "    # save the model\n",
    "    torch.save(best_model.state_dict(), f'models/CNN-LSTM/best_model_{runNo}.pth')\n",
    "\n",
    "\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "cnn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display mean confusion matrix\n",
    "plot_confusion_matrix(cnn_mean_confusion, classes=['W','N1','N2','N3','R'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc13189",
   "metadata": {},
   "source": [
    "### Test CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "\n",
    "test_aurocs = []\n",
    "test_accuracies = []\n",
    "test_kappas = []\n",
    "test_confusions = []\n",
    "\n",
    "for runNo in range(num_runs):\n",
    "    model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "    model.load_state_dict(torch.load(f'models/CNN-LSTM/best_model_{runNo}.pth'))\n",
    "    test_acc, test_kappa, test_auroc, test_cm = evaluate_model(model, test_loader)\n",
    "    test_aurocs.append(test_auroc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    test_kappas.append(test_kappa)\n",
    "    test_confusions.append(test_cm)\n",
    "\n",
    "print(f\"Test AUROC: {np.mean(test_aurocs):.4f} +/- {np.std(test_aurocs):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} +/- {np.std(test_accuracies):.4f}\")\n",
    "print(f\"Test Kappa: {np.mean(test_kappas):.4f} +/- {np.std(test_kappas):.4f}\")\n",
    "\n",
    "# get mean confusion matrix\n",
    "cnn_mean_confusion = np.mean(test_confusions, axis=0)\n",
    "# display last confusion matrix\n",
    "#plot_confusion_matrix(test_confusions[-1,:,:], classes=['W','N1','N2','N3','R'])\n",
    "plot_confusion_matrix_with_metrics(test_confusions[-1], class_mapping={0:'W',1:'Light',2:'Deep',3:'REM'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02516e4a",
   "metadata": {},
   "source": [
    "# Compare Inference Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bac86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "temp_hf, temp_lf, temp_labels = train_dataset[0]\n",
    "temp_hf = temp_hf.unsqueeze(0).to(device)\n",
    "temp_lf = temp_lf.unsqueeze(0).to(device)\n",
    "# LSTM Only\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "dropout = 0.21312\n",
    "learning_rate = 0.0048844\n",
    "weight_decay = 0.0000078942\n",
    "label_smoothing = 0.0050416\n",
    "lstm_model = LSTMSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        debug=False\n",
    "    )\n",
    "lstm_model.eval()\n",
    "lstm_model.to(device)\n",
    "\n",
    "# CNN-LSTM\n",
    "cnn_output_channels = 64\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 6\n",
    "dropout = 0.3348076952070481\n",
    "learning_rate = 0.0010265829979403838\n",
    "weight_decay = 4.969225017183202e-06\n",
    "label_smoothing = 0.12009173751056051\n",
    "\n",
    "cnn_model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='CNN',\n",
    "        debug=False\n",
    "    )\n",
    "cnn_model.eval()\n",
    "cnn_model.to(device)\n",
    "\n",
    "# TCN-LSTM\n",
    "cnn_output_channels = 16\n",
    "dropout = 0.21312\n",
    "label_smoothing = 0.0050416\n",
    "learning_rate = 0.0048844\n",
    "lstm_hidden_size = 256\n",
    "lstm_num_layers = 2\n",
    "num_tcn_blocks = 7\n",
    "tcn_kernel_size = 5\n",
    "weight_decay = 0.0000078942\n",
    "\n",
    "tcn_model = DualFreqSleepStager(\n",
    "        hf_input_channels=len(hf_features),\n",
    "        lf_input_channels=len(lf_features),\n",
    "        cnn_output_channels=cnn_output_channels,\n",
    "        lstm_hidden_size=lstm_hidden_size,\n",
    "        lstm_num_layers=lstm_num_layers,\n",
    "        lstm_bidirectional=True,\n",
    "        dropout=dropout,\n",
    "        num_sleep_stages=4,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        label_smoothing=label_smoothing,\n",
    "        weight_tensor=torch.tensor(class_weights, dtype=torch.float32),\n",
    "        convnet='TCN',\n",
    "        num_tcn_blocks=num_tcn_blocks,\n",
    "        tcn_kernel_size=tcn_kernel_size,\n",
    "        debug=False\n",
    "    )\n",
    "tcn_model.eval()\n",
    "tcn_model.to(device)\n",
    "\n",
    "lstm_times = []\n",
    "cnn_times = []\n",
    "tcn_times = []\n",
    "num_trials = 100\n",
    "with torch.no_grad():\n",
    "    # warm up\n",
    "    for _ in range(10):\n",
    "        cnn_model(temp_hf, temp_lf)\n",
    "        tcn_model(temp_hf, temp_lf)\n",
    "    torch.cuda.synchronize()\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        cnn_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    cnn_times.append((end - start) / 100)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        tcn_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    tcn_times.append((end - start) / 100)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(num_trials):\n",
    "        lstm_model(temp_hf, temp_lf)\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    lstm_times.append((end - start) / 100)\n",
    "print(f\"cnn time: {np.mean(cnn_times):.4f} +/- {np.std(cnn_times):.4f}\")\n",
    "print(f\"tcn time: {np.mean(tcn_times):.4f} +/- {np.std(tcn_times):.4f}\")\n",
    "print(f\"lstm time: {np.mean(lstm_times):.4f} +/- {np.std(lstm_times):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl4med_25)",
   "language": "python",
   "name": "dl4med_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
